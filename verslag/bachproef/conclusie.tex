%%=============================================================================
%% Conclusie
%%=============================================================================

\chapter{Conclusie}%
\label{ch:conclusie}

% TODO: Trek een duidelijke conclusie, in de vorm van een antwoord op de
% onderzoeksvra(a)g(en). Wat was jouw bijdrage aan het onderzoeksdomein en
% hoe biedt dit meerwaarde aan het vakgebied/doelgroep? 
% Reflecteer kritisch over het resultaat. In Engelse teksten wordt deze sectie
% ``Discussion'' genoemd. Had je deze uitkomst verwacht? Zijn er zaken die nog
% niet duidelijk zijn?



% todo beantwoord vraag (manuele) tekstvereenvoudiging


% todo beantwoord vraag wetenschappelijke artikelen


% todo beantwoord vraag beschikbare tools

\subsubsection{Voldoet de huidige software aan de noden van scholieren met dyslexie in het middelbaar onderwijs?}

De huidige software uitgeleend aan scholieren met dyslexie in de derde graad van het middelbaar onderwijs voldoet niet aan de noden. De tekstvereenvoudiging -en samenvattingsfuncties gaan niet verder dan het markeren van zinnen, om deze later om te vormen naar een tekst die geen rekening houdt met de coherentie.

\subsubsection{Advies bij het gebruik van pre-trained taalmodellen bij automatische tekstvereenvoudiging.}

Bestaande taalmodellen vereenvoudigen de ontwikkeling voor een dergelijke toepassing. Het prototype wijst uit dat vrij beschikbare taalmodellen zoals BERT en verwante BERT-varianten een oplossing bieden voor semantische analyse, kernwoorden achterhalen en extraherende samenvatting. Complexere vereenvoudigingstechnieken zoals lexicale en syntactische vereenvoudiging en abstraherende samenvatting kunnen ontwikkeld worden met complexere taalmodellen, zoals GPT-3. Ontwikkelaars moeten bij deze keuze rekening houden met de schaal van de modellen. BERT is mogelijk om abstraherende samenvatting mogelijk te maken, maar zoals aangetoond staat deze in de schaduw van GPT-3 wat voor ontwikkelaars vrij beschikbaar is. Omgekeerd is GPT-3 een \textit{overkill} voor taken zoals het ophalen van kernwoorden of aanduiden van belangrijke zinnen, wat taken zijn die kost- en energiereducerend kunnen aangepakt worden.

Het GPT-3 model maakt complexe en granulaire NLP-transformaties op lexicaal en syntactisch niveau mogelijk voor geautomatiseerde tekstvereenvoudiging. Echter houdt het model geen rekening met referenties buiten de getrainde data, wat tot problemen bij de credibiliteit van data kan leiden. Bing AI daarentegen doet dit wel en vormt een goede fundering voor ontwikkelaars om meer referentiemateriaal aan te bieden in ondersteunende software binnen het onderwijs.

% Heeft het onderzoek geleid tot nieuwe vragen die uitnodigen tot verder 
%onderzoek?

\subsubsection{Nieuwe vragen tot verder onderzoek.}

Er is meer onderzoek nodig naar hoe de deployment van webtoepassingen en browserextensies die tekstvereenvoudiging in het onderwijs kan gebeuren. Met alsmaar grotere taalmodellen, zoals het opkomende GPT-4 en LLaMa moet er ook meer onderzoek zijn naar de verschillen op taalvlak ten opzichte van de toename in parameters. De overstap maken qua taalmodellen is kostelijk voor ontwikkelaars en het eerdere onderzoek van (..) wees uit dat de grootte van taalmodellen alsmaar minder relevant wordt.