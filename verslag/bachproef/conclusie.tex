%%=============================================================================
%% Conclusie
%%=============================================================================

\chapter{Conclusie}%
\label{ch:conclusie}

% TODO: Trek een duidelijke conclusie, in de vorm van een antwoord op de
% onderzoeksvra(a)g(en). Wat was jouw bijdrage aan het onderzoeksdomein en
% hoe biedt dit meerwaarde aan het vakgebied/doelgroep? 
% Reflecteer kritisch over het resultaat. In Engelse teksten wordt deze sectie
% ``Discussion'' genoemd. Had je deze uitkomst verwacht? Zijn er zaken die nog
% niet duidelijk zijn?

\subsubsection{Software ontwikkelen voor scholieren met dyslexie in de derde graad van het middelbaar onderwijs.}

De erkende software uitgeleend aan scholieren met dyslexie in de derde graad van het middelbaar onderwijs voldoet niet aan de noden. De software biedt ondersteunende functionaliteiten aan zoals het aanmaken van een woordenlijst, alsook het markeren van zinnen om deze later om te vormen naar een tekst. Syntactische vereenvoudiging of abstraherende samenvatting zijn niet tot de orde. Online toepassingen staan verder en reiken functionaliteiten aan die zowel hoogstaand als effectief te reproduceren zijn. Echter is er geen manusje-van-alles en er is nood aan een toepassing die alle functionaliteiten kan combineren. 

Het prototype wijst uit dat het combineren van functionaliteiten een haalbare zaak is voor zowel klein- als grootschalige softwareondernemingen. Met gebruik van kant-en-klare taalmodellen, API's en gekende programmeertalen zijn ontwikkelaars ertoe in staat om een webtoepassing te ontwikkelen die ondersteuning kan bieden aan scholieren met dyslexie in de derde graad van het middelbaar onderwijs. Dit prototype is gebouwd op eerder onderzochte visuele kenmerken en de impact van een vereenvoudigde tekst op de leessnelheid en -begrip bij een scholier met dyslexie tijdens het intensief lezen van een tekst. Het gebruik van het prototype moet verder onderzocht worden bij de doelgroep. 

\subsubsection{Het gebruik van taalmodellen bij geautomatiseerde tekstvereenvoudiging.}

Bestaande taalmodellen maken de ontwikkeling van toepassingen op het gebied van semantische analyse, kernwoordenidentificatie en het extraheren van samenvattingen veel eenvoudiger. Een prototype heeft aangetoond dat vrij beschikbare taalmodellen, zoals BERT en gerelateerde BERT-varianten, een oplossing bieden voor deze taken. Voor meer complexe vereenvoudigingstechnieken, zoals lexicale en syntactische vereenvoudiging en abstraherende samenvatting, zijn complexere taalmodellen zoals GPT-3 geschikt. 

Ontwikkelaars moeten echter rekening houden met de schaal van de modellen bij het maken van deze keuze. Hoewel vrij beschikbare modellen op HuggingFace in staat zijn om abstraherende samenvattingen of lexicale vereenvoudiging mogelijk te maken, staan ze in de schaduw van GPT-3, dat voor ontwikkelaars vrij beschikbaar is. Omgekeerd is GPT-3 echter een \textcite{overkill} voor taken zoals het identificeren van kernwoorden of het aanduiden van belangrijke zinnen, die kosteneffectief kunnen worden aangepakt zonder het gebruik van GPT-3. GPT-3 moet niet voor iedere functionaliteit worden ingezet om zo kostenbesparend te werken. Het GPT-3 model maakt complexe en granulaire NLP-transformaties op lexicaal en syntactisch niveau mogelijk voor geautomatiseerde tekstvereenvoudiging. Echter houdt het model geen rekening met referenties buiten de getrainde data, wat tot problemen bij de credibiliteit van data kan leiden. Bing AI daarentegen doet dit wel en vormt een goede fundering voor ontwikkelaars om meer referentiemateriaal aan te bieden in ondersteunende software binnen het onderwijs. Verder onderzoek op de toepassing van deze AI via een mogelijke API is zeker nodig en kan baanbrekend zijn voor de onderwijssector.

Tijdens dit onderzoek is er geen verdere finetuning uitgevoerd op zowel het GPT-3 model als de gebruikte taalmodellen, zoals BERT of Pegasus. Toch is er een licht effect waargenomen op de verschillen in lexicale complexiteit tussen de taalmodellen die wel getraind zijn op wetenschappelijke papers in vergelijking met taalmodellen die getraind zijn op algemene data of data die irrelevant is voor deze casus. Er is echter meer onderzoek nodig om de verschillen tussen deze taalmodellen binnen de context van wetenschappelijke papers te begrijpen. OpenAI's taalmodellen evolueren continu. Inmiddels wordt GPT-4 uitgerold en Bing AI is beschikbaar volgens een wachtlijst. Deze twee taalmodellen zijn nu nog niet in staat om in productie te worden gebruikt. Verder onderzoek naar het gebruik van deze twee modellen binnen het onderwijs is nodig.

Dit onderzoek beperkte zich tot de tekstinhoud van een vereenvoudigd artikel. Er is meer onderzoek nodig naar hoe de deployment van webtoepassingen en browserextensies die tekstvereenvoudiging in het onderwijs kan gebeuren. Met alsmaar grotere taalmodellen, zoals het opkomende GPT-4 en LLaMa moet er ook meer onderzoek zijn naar de verschillen op taalvlak ten opzichte van de toename in parameters. De overstap maken qua taalmodellen is kostelijk voor ontwikkelaars en eerder uitgewezen uit dat de grootte van taalmodellen alsmaar minder relevant wordt. De kwaliteit van de ge-extraheerde tekstinhoud uit een PDF- of Docx-bestand door de gebruikte Python-libraries. Er is meer onderzoek nodig naar robuuste oplossingen om PDF-inhoud uit een tekst te extraheren, met minimale invloed van het gebruikte softwarepakket.	