%%=============================================================================
%% Conclusie
%%=============================================================================

\chapter{Conclusie}%
\label{ch:conclusie}

Deze scriptie tracht een antwoord te bieden op de volgende onderzoeksvraag:

\begin{itemize}
	\item Hoe kan een wetenschappelijk artikel automatisch vereenvoudigd worden, gericht op de unieke noden van scholieren met dyslexie in de derde graad middelbaar onderwijs?
\end{itemize}

De requirementsanalyse bood nieuwe inzichten in de huidige toepassingen van ATS. Zo beschikken online tools te weinig over gepersonaliseerde ATS-functionaliteiten, zoals gebleken in sectie \ref{sec:requirementsanalyse}. Daarnaast maken weinig tools gebruik van gepersonaliseerde weergaveopties, die echter een bewezen effect hebben op het leesbegrip van een scholier met dyslexie in de derde graad van het middelbaar onderwijs.

\medspace

Uit de vergelijkende studie blijkt dat GPT-3 de leesbaarheid van een wetenschappelijke tekst kan bevorderen door gebruik te maken van eenvoudigere synoniemen en structurele aanpassingen, waaronder het schrijven van tekst als een opsomming. Andere geteste taalmodellen uit HuggingFace behalen zwakkere resultaten en vereisen een extra vertaalfase, die redundant is bij het aanspreken van de GPT-3 API.

\medspace

Uit de ontwikkeling van het prototype voor gepersonaliseerde ATS bleek dat \textit{open-source} AI en NLP-technologieÃ«n voldoende hoogstaand genoeg zijn om kwaliteitsvolle tekstvereenvoudigingssoftware te ontwikkelen. Zo kunnen ontwikkelaars gebruikmaken van PDFMiner om tekstinhoud uit wetenschappelijke artikelen te extraheren, van OpenAI's GPT-3 model via de API om gepersonaliseerde ATS mogelijk te maken en ten slotte van Pandoc om dynamische en gepersonaliseerde PDF-documenten automatisch te genereren. Binnen een webapplicatie kunnen eenduidige handelingen, gebouwd in JavaScript en HTML\&CSS, complexe commandlinehandelingen afhandelen.


\medspace


Ontwikkelaars hebben toegang tot T1, T2 en T3 via HuggingFace voor lexicale vereenvoudigingstaken. Deze taalmodellen zijn echter ontoereikend voor gepersonaliseerde tekstvereenvoudiging en daarom is T4 een geschikter model voor het vereenvoudigen van wetenschappelijke artikelen op maat. GPT-3 presteert goed op gepersonaliseerde vereenvoudigingstaken, maar het is belangrijk om op te merken dat geen enkel taalmodel de doelgroep altijd nauwkeurig kan inschatten. Extra trainingsdata, zoals leerstof of wetenschappelijke artikelen die wel op het niveau van een 16-18-jarige zijn geschreven, kan het model steunen bij de doelgroepsinschatting. Het gebruik van Engelstalige prompts met expliciete vermelding van de gewenste uitvoertaal, resulteert in coherentere teksten dan bij een Nederlandstalige prompt.