%%=============================================================================
%% Conclusie
%%=============================================================================

\chapter{Conclusie}%
\label{ch:conclusie}

In deze scriptie is gezocht naar een antwoord op de volgende onderzoeksvraag:

\begin{itemize}
	\item Hoe kan een wetenschappelijke artikel automatisch vereenvoudigd worden, gericht op de unieke noden van scholieren met dyslexie in de derde graad middelbaar onderwijs?
\end{itemize}

\medspace

Uit de requirementsanalyse werden nieuwe inzichten gegeven omtrent het bestaand toepassen van ATS. Zo beschikken online tools echter te weinig over gepersonaliseerde ATS-functionaliteiten, zoals gebleken in sectie \ref{sec:requirementsanalyse}. Daarnaast maken weinig tools gebruik van gepersonaliseerde weergaveopties, die echter een bewezen effect hebben op het leesbegrip van een scholier met dyslexie in de derde graad van het middelbaar onderwijs.

\medspace

Uit de vergelijkende studie blijkt dat GPT-3 de leesbaarheid van een wetenschappelijke tekst kan bevorderen door gebruik te maken van eenvoudigere synoniemen en structurele aanpassingen waaronder het schrijven van tekst als een opsomming. Andere geteste taalmodellen uit HuggingFace behalen zwakkere resultaten en vereisen een extra vertaalfase, die redundant is bij het aanspreken van de GPT-3 API.

\medspace

Uit de ontwikkeling van het prototype voor gepersonaliseerde ATS is gebleken dat \textit{open-source} AI en NLP-technologieÃ«n hoogstaand genoeg zijn om kwaliteitsvolle tekstvereenvoudigingssoftware te ontwikkelen. Zo kunnen ontwikkelaars gebruik maken van PDFMiner om tekstinhoud uit wetenschappelijke artikelen te extraheren, OpenAI's GPT-3 model via de API om gepersonaliseerde ATS mogelijk te maken en ten slotte Pandoc om dynamische en gepersonaliseerde PDF-documenten automatisch te genereren. Binnen een webapplicatie kunnen complexe commandline-handelingen afgehandeld worden door eenduidige handelingen gebouwd in Javascript en HTML\&CSS.


\medspace


Ontwikkelaars hebben toegang tot T1, T2 en T3 via HuggingFace voor lexicale vereenvoudigingstaken. Deze taalmodellen zijn echter ontoereikend voor gepersonaliseerde tekstvereenvoudiging en daarom is T4 een geschikter model voor het vereenvoudigen van wetenschappelijke artikelen op maat. GPT-3 presteert goed op gepersonaliseerde vereenvoudigingstaken, maar het is belangrijk om op te merken dat geen enkel taalmodel de doelgroep altijd nauwkeurig kan inschatten. Extra trainingsdata, zoals leerstof of wetenschappelijke artikelen die wel op het niveau van een 16-18-jarige is geschreven, kan het model steunen bij de doelgroepsinschatting. Het gebruik van Engelstalige prompts waarin expliciet de gewenste uitvoertaal wordt vermeld, resulteert in coherentere teksten dan bij een Nederlandstalige prompt.