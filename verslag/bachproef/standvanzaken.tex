\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}%
\label{ch:stand-van-zaken}


\section{Onderzoeken rond dyslexie}

Taal is een essentieel onderdeel van ons dagelijks leven en speelt een belangrijke rol in onze communicatie en begrip. Dyslexie kan deze basis aantasten en het leren en communiceren hinderen. Het begrijpen van de relatie tussen taal en dyslexie is van belang om mensen met deze aandoening te ondersteunen en hun kwaliteit van lezen te verbeteren. Deze sectie gaat dieper in op de relatie en bespreken hoe mensen met dyslexie kunnen worden geholpen bij het lezen.

\subsection{Centraal zicht op dyslexie}

Lezen is onnatuurlijk en volgens de geschiedenis van de mens een recent begrip. Pas 5000 jaar geleden werd de geschreven taal bedacht. Mensen worden niet geboren met de vaardigheid om te lezen. Het lezen wordt zelf aangeleerd en daarvoor moet het brein heringericht worden \autocite{Bonte2020, VanDerMeer2022}. De visuele cortex is een hersengebied dat instaat voor de aanschouwelijke waarneming en herkenning van objecten, zoals meubels of letters. Lezen traint dit gebied bij het herkennen van letters, maar dit is niet evident en vordering bij letterherkenning gebeurt pas na meerdere pogingen. Tijdens het leren schrijven worden letters regelmatig in spiegelbeeld geschreven. De visuele cortex moet het spiegelen van objecten onderdrukken door de rotatie van links naar rechts te negeren \autocite{Bonte2020, Romanovska2021}. Een d en een b wordt door elkaar gehaald. Het brein moet gemanipuleerd worden om deze spiegeling te onderdrukken. De visuele cortex moet gekoppeld worden aan de auditieve cortex, samen met verbindingen met het geheugen en de begrip van een tekst. Afzonderlijke klanken moeten ook worden aangeleerd. Het leren lezen vraagt volgens \textcite{Bonte2020} drie aanpassingen in het brein:

\begin{itemize}
	\item Het visuele gebied moet heringericht worden op het herkennen van letters.
	\item Het auditieve gebied moet afzonderlijk klanken aanleren.
	\item Deze twee gebieden moeten met elkaar verbonden worden, om de klanken te koppelen aan de letters die worden gelezen. De derde aanpassing gaat vaak fout bij mensen met dyslexie. 
\end{itemize}
 
Dyslexie betekent letterlijk 'beperkt lezen'. Het voorlezen verloopt radend, letter-voor-letter en langzaam. Lezen gaat niet soepel. Leesproblemen kunnen beperkend zijn. Elke zin verloopt langzamer. Dyslexie is genetisch en erfelijkheid speelt een rol. Goede woordenschat ontwikkeling of vaak voorlezen is een beschermende factor tegen dyslexie. Ten slotte noemen \textcite{Vellutino2004, Bonte2020} dyslexie een verborgen stoornis, want de diagnose kan niet gesteld worden met hersenscans en vereist daarmee een nauwe opvolging bij de diagnose. Onderzoeken halen drie verschillende types van dyslexie aan. Deze drie types hebben unieke kenmerken en symptomen, maar zijn geen afbakening bij het vaststellen van een diagnose. Dezelfde onderzoeken wijzen erop dat een overlap van kenmerken over de drie types heen mogelijk is \autocite{Rello2012, Vellutino2004}.

\begin{itemize}
	\item Fonologische dyslexie
	\item \textit{Surface dyslexia} en \textit{Deep dyslexia}
\end{itemize}

\subsection{Fonologische dyslexie}

% inleiding rond taal
% hoe zit taal in mekaar

In \textcite{Avontuur2015} worden getuigenissen van taalproblemen bij fonologie, morfologie, zinsbouw en semantiek aangehaald:

\begin{quote}
	André, een man van 45 jaar met een managementfunctie, betrapt zichzelf erop dat hij 'zijn' kan schrijven in plaats van zien en 'fliegende' in plaats van vliegende.
\end{quote}

\begin{quote}
	Koen, een jongeman van 20 jaar, heeft veel moeite met samengestelde woorden. Hij schrijft ze veelal los, bijvoorbeeld 'zee spiegel', 'uit wisseling', 'oogst maand'. Hij heeft dit zelf niet in de gaten. Voor hem zijn het twee aparte woorden.
\end{quote}

\begin{quote}
	Marc, een universitair student, mailt naar een vriend: 'Ik kan het weekend van de 20e september zou kunnen' en 'Ik mag vanaf heden ben ik bachelor of science.' Dit soort dingen schrijft hij herhaaldelijk, vertelt hij, en hij ziet het zelf niet, vult hij enigszins gefrustreerd aan. Hij geeft aan dat het eenvoudige zinnetjes zijn en zelfs die schrijft hij fout.
\end{quote}

\begin{quote}
	Myrthe studeert rechten. In werkcolleges kan ze goed meedoen en geeft ze blijk van voldoende kennis. Ze moet zich echter bovenmatig inspannen om de lesstof in de studieboeken te lezen en te verwerken. Het kost haar veel tijd en ze krijgt er hoofdpijn van.
\end{quote}

\subsection{Centraal zicht op de doelgroep}

\subsubsection{Statistieken rond prevalentie en comorbiditeit}

Vlaamse en Nederlandse onderzoeken van \textcite{Wentink2008, Desoete2017} wijzen uit dat gemiddeld 4\% van de Nederlandstalige bevolking de diagnose van dyslexie heeft. De transparantie van de taal beïnvloedt volgens \textcite{APA2013} de prevalentie van dyslexie in een taalgebied. Spaans, Italiaans en Chinees zijn transparant en hebben een sterkere grafeem-foneem en foneem-grafeem koppeling. Zo is bijvoorbeeld slechts 1\% van de Chinese sprekers dyslectisch. Engels is een minder transparante taal waar 
klanken op verschillende manieren geschreven kunnen worden, bijvoorbeeld \textit{eight} en \textit{late}. De prevalentie van dyslexie ligt met 20 \% dan ook hoger in Engelstalige landen. Het aantal scholieren met dyslexie in het lager en middelbaar onderwijs wereldwijd loopt op tot 15\% ingeschat \autocite{Bonte2020, VanDerMeer2022}.

% Zo is volgens  het percentage met mensen met dyslexie in China slechts ongeveer 1\% van de bevolking, terwijl dit cijfer bij het Engels, een opake taal\footnote{Talen met inconsistente klank-tekenkoppelingen. Bijvoorbeeld \textit{eight} en \textit{late}.}, drastisch hoger wordt geschat op ongeveer 15\% van de Engelstalige bevolking\footnote{Deze schatting is gebaseerd op bevraagden uit de Verenigde Staten en Groot-Britannië.}. % Verder wijst \textcite{Desoete2015} aan dat de prevalentie van gecombineerde reken- en leesstoornissen hoog ligt, geschat op een 25 tot 50\%. De prevalentie van het voorkomen van spraak- en taalstoornissen ligt volgens \textcite{Dirks2008, Desoete2017} op 50 tot 80\%. 

% todo grafiek https://dyslexiacompass.eu/wp-content/uploads/2022/02/Dyslexia-Compass-Report_compressed.pdf

\subsubsection{Scholieren met dyslexie in het derde graad middelbaar onderwijs}

Mensen met dyslexie ondervinden een last bij het technisch lezen van een tekst. Al zijn er onderzoeken naar adolescenten en volwassenen met dyslexie, onderzoeken rond dyslexie richten zich vaker op kinderen in het kleuter- en basisonderwijs. Volgens \textcite{Bonte2020} is dit om voldoende onderzoek te hebben voor de meest gepaste diagnose en ondersteuning op jonge leeftijd, dus in de kleuter- of kinderfase. Deze diagnose zo vroeg mogelijk vastleggen vereist voldoende onderzoek. Bonte haalt een sneeuwbaleffect aan wanneer kinderen met dyslexie een zwakke ondersteuning krijgen. Deze last wordt meegedragen naar volgende levensfases. Volgens \textcite{Lissens2020} zijn jongvolwassenen en ouderen een leeftijdsgroep die bij onderzoeken rond dyslexie over het hoofd word gezien.

Het onderzoek van \textcite{Lissens2020} benadrukt deze vaak over het hoofd geziene doelgroep. Mensen met dyslexie ervaren uitdagingen bij het lezen en schrijven. Op sociaal vlak worden deze mensen niet begrepen door anderen, omdat ze woorden vaak verkeerd uitspreken of verkeerd spellen. Het tempo van anderen bijhouden verloopt stroef en het verwerken van teksten vereist meer energie. Ondanks het vele oefenen blijft snel en veel lezen moeilijk. 

Spellingsregels toepassen hindert mensen met dyslexie. Dit kan leiden tot een onzeker gevoel en angst om fouten te maken, frustratie en stress. Daardoor waardoor het voor mensen met dyslexie moeilijker wordt om hun vaardigheden te verbeteren. Vooroordelen aan dyslexie zijn prevalent volgens \textcite{Diels2022}. Mensen met dyslexie worden in het bedrijfsleven en binnen de schoolmuren als minder intelligent of traag afgestempeld. Daarnaast proberen mensen met dyslexie deze leesstoornis te maskeren door bijvoorbeeld moeilijke woorden in afkortingen te schrijven. Toch motiveren onderzoeken zoals \textcite{Ghesquiere2018, Lissens2020, Bonte2020} deze doelgroep door het sterk doorzettingsvermogen, geduldig en luisterend karakter en probleemoplossend denkvermogen te benadrukken. Dit helpt hen om te blijven oefenen en hun vaardigheden te ontwikkelen, ondanks de uitdagingen.

\subsection{Diagnosecriteria}

Dyslexie is geen lijst van 'kwalen' waaraan een scholier moet voldoen om dit te bezitten. Zo halen \textcite{Kleijnen2008, Ghesquiere2018} samen drie beschrijvende criteria aan waarmee de diagnose van dyslexie wordt vastgesteld.

\begin{itemize}
	\item Het \textbf{achterstandscriterium} wijst aan dat een persoon ten opzichte van andere leeftijdsgenoten niet even hoog scoort op het vlak van lezen.
	\item Het \textbf{hardnekkigheidscriterium} houdt in dat de lees- of spellingsachterstand het gevolg is van een moeizame automatisering van het lees- en spellingsproces. % De leessnelheid vertraagt, terwijl het aantal lees- of spellingsfouten verhoogt terwijl een scholier complexe taken uitvoert.
	\item Het \textbf{exclusiviteitscriterium} volgens \textcite{Ghesquiere2018} wijst erop dat een persoon enkel de diagnose van dyslexie heeft, zonder bijhorende lees- of spellingsstoornissen. Hardnekkige problemen mogen niet volledig verklaard worden door condities in of buiten de leerling in kwestie.  % worden door andere condities, zoals verstandelijke beperkingen, emotionele moeilijkheden of zintuiglijke beperkingen.
\end{itemize}

% Het exclusiviteitscriterium benadrukt dat alle noden en obstakels van mensen met dyslexie verschillend zijn. Zo halen \textcite{VanVreckem2015, Ghesquiere2018} de volgende kenmerken aan die kunnen verschillen per individu.

Verder halen \textcite{VanVreckem2015, Ghesquiere2018} de volgende kenmerken aan die kunnen verschillen per individu.


\begin{itemize}
	\item De ernst of uitgebreidheid van een stoornis.
	\item De gevolgen van een stoornis, zoals faalangst.
	\item De mate waarin iemand al dan niet kan compenseren.
	\item De secundaire kenmerken zoals problemen met werkhouden en structuur.
\end{itemize}

Het onderzoek van \textcite{VanVreckem2015} achterhaalt of het groepsprofiel overeenkomt met de individuele profielen bij begrijpend lezen en spelling. De onderzoeksresultaten bij een experiment met zeventien kinderen wijst uit dat er een geïndividualiseerde analyse en effectieve behandeling op maat nodig is bij begrijpend lezen. Onvoldoende beheerste leerstof en leesstrategieën per kind moet achterhaald worden om zo specifieke begeleiding te kunnen bieden.

%\subsection{Groepsprofiel vergeleken met het individueel profiel}

%  onderzocht of kinderen met dyslexie als groep al dan niet problemen hebben met begrijpend lezen. 

% Verder wijst het onderzoek uit dat kinderen met dyslexie meer problemen hebben bij het spellen van pseudowoorden. Er werden geen significante verschillen geconstateerd bij comorbide of gecombineerde stoornissen.



\subsection{Moeilijkheden bij dyslexie}

Onderzoeken rond digitale toepassingen voor kinderen en scholieren met dyslexie reiken prevalente moeilijkheden en struikelblokken voor deze doelgroep aan. De onderzoeken beklemtonen de unieke noden en niet ieder struikelblok komt voor bij iedere persoon met dyslexie.

\begin{itemize}
	\item Langzame woordbenoeming
	\item Hardnekkig letter-voor-letter lezen
	\item Woordherkenning en -herinnering
	\item Visuele disfunctie
	\item Letter- en klankvorming
	\item Homofonische of pseudo-homofonische woordenschat
	\item Begripsproblemen
\end{itemize}

\subsubsection{Langzame woordbenoeming}

Het correct spellen van pseudowoorden en regelmatig gespelde woorden is mogelijk met beheerste letterklankkoppelingen. Echter verloopt het automatiseren van moeilijke en nieuwe woorden stroef, met een trage woordbenoeming tot gevolg. Lezers kunnen met dit leesprobleem veel woorden niet als één geheel herkennen. 

\textcite{Filipak2020} raadt aan om pseudowoorden en het identificeren te oefenen als mogelijke hulp. De meeste schrijffouten komen voor in onregelmatig gespelde woorden waardoor een fonologische route die wel tact is, leidt tot het schrijven van \textit{gedaan} als \textit{guhdaan}.

% todo oplossing

\subsubsection{Begripsproblemen}

% todo deep dyslexia vervangen

Typerende symptomen de verstoring van leesbegrip en het spreken in qua betekenis onbedoelde klanken, woorden en woordgroepen (parphasias). Bij fonologische dyslexie kan bos bijvoorbeeld gelezen worden als boom. Begripsproblemen bij het lezen kunnen goed visueel, met steun van film en afbeeldingen ondersteund worden, beter dan alleen via gedrukte woorden. Daarbij moet de lezer die het gedrukte woord wil ontcijferen, gebruik kunnen maken van bronnen van kennis op een hoger niveau: een grote woordenschat en een goed redeneervermogen. Schriftelijke expressie is uit den boze.

\subsubsection{Hardnekkig letter-voor-letter lezen}

\textcite{Bonte2020} haalt een minder optimale informatieverwerking in visuele gebieden aan bij scholieren met dyslexie, wat het gevolg is van een minder optimale lees ontwikkeling. Deze verwerking is belangrijk voor letter- en woordherkenning. Lezers zijn niet in staat woorden goed te lezen, zelfs niet met een langzame en spellende letter-klankroute. Lange woorden worden moeizaam gelezen en scholieren hebben de neiging om visueel gedesoriënteerde te raken. Er is verwarring over de richting van de letters.

\textcite{Rello2013} voerde onderzoek uit naar het gebruik van korte woorden bij mensen met dyslexie.

\subsubsection{Woordherkenning}

% oogfixatie



% todo welke onderzoeken?
% Onderzoeken zoals waarbij de oogbewegingen van lezers worden gevolgd tonen aan dat een geoefende lezer bij vijftig tot tachtig procent van de woorden pauzeert. Een persoon moet zich op woorden fixeren om ze te kunnen zien en dat gaat heel snel. Gedurende deze zogenoemde saccade, een snelle beweging van de ogen die tot doel heeft een nieuw fixatiepunt te vinden, wordt het woordbeeld van de vorige woordfixatie onderdrukt, voordat een volgende woord wordt gefixeerd. 



% Leesonderzoekers de Universiteit van Tel Aviv in Israël vonden in 2010 bijvoorbeeld een soort leesprobleem dat men ‘aandachts-dyslexie’ noemde, waarin kinderen letters correct identificeren, maar tijdens het lezen last hebben van verspringende letters tussen de woorden in de zinnen. Dit is minder bij het lezen van woorden in lijsten dan met woorden in lopende tekst. Denk aan het verschil in leesprestaties op de Drie-Minuten-Test (losse woorden lezen) en op de AVI-toets (tekstlezen). 

% TODO Oogfixatie
% https://www.sciencedirect.com/science/article/pii/S0042698905004864
% An experimental eye-tracking study of text adaptation for readers with dyslexia: effects of visual support and word frequency
% Investigating Efects of Typographic Variables on Webpage Reading Through Eye Movements

\textit{Top-down attention and serial reading}. In een WISC-afname kan blijken dat de organisatie van de ruimtelijke waarneming redelijk is, maar dat een leerling zwakker is met doolhoven, plaatjes ordenen, onvolledige tekeningen, substitutie-taken en vooral met symboolverwerking. Dan kan er sprake zijn van een visueel en/of neuropsychologische dysfunctie dat ten grondslag ligt aan de moeite met lezen. Dan gaat het dus , nogmaals, niet om een fonologische dysfunctie.

\subsubsection{Visuele disfunctie}

Het boek van \textcite{Bezem2016} maakt ouders en leerkrachten bewust rond de principes van visuele disfunctie. Mensen met visuele disfunctie observeren objecten anders dan de meeste mensen. Fixatie disparatie is een vorm van visuele disfunctie dat een onjuiste samenwerking van de ogen veroorzaakt. Ogen doen hun werk vanuit een verschillende positie en nemen zaken afzonderlijk waar. Deze afzonderlijke observaties moeten samengenomen worden. Als deze fixatie niet correct verloopt, dan wordt er van disparatie gesproken. Het gevolg is dat mensen met drie letters tegelijk zien en daardoor een woordbeeld missen of een zwakke spellingstijl gebruiken.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=5cm]{img/visuele-disfunctie.png}
	\end{center}
	\caption{Afbeelding uit \textcite{Bezem2016}. Deze afbeelding doet een poging tot het nabootsen van fixatie disparatie. }
\end{figure}

In het onderwijs worden er initiatieven ingezet. Zo krijgen scholieren in het lager en middelbaar onderwijs een vaste plaats. Deze scholieren worden niet geplaatst bij het raam, want het invallende licht in de ogen heeft een negatieve invloed op fixatie disparatie, waardoor het lastiger wordt om de ogen te laten samenwerken. \autocite{Bezem2016}

\subsubsection{Letter- en klankverwarring}

% TODO aanpassen!!!

% Verder gaat het om de verwisseling van de lettervolgorde, om letterweglatingen, letter-toevoegingen, letter-vervangingen, en het onherkenbaar verminken van woorden in dictees. En ook om de moeite met auditieve analyse en synthese. Veel kinderen kunnen deze leesfouten maken en dat is dan niet meteen fonologische dyslexie.

\subsection{Aandachtspunten bij ondersteuning}

Dyslexie kan zich op verschillende manieren uiten bij verschillende kinderen. Een app moet worden ontworpen met een individuele analyse van de specifieke behoeften en uitdagingen van elke leerling in gedachten \autocite{Uhry2008, Gooding2018}. Instructies moeten op een begrijpelijke en geïndividualiseerde manier worden gepresenteerd om de leerlingen te helpen bij het begrijpen en toepassen van de informatie. Het is belangrijk om te erkennen dat dyslexie zich bij verschillende kinderen op verschillende manieren kan uiten. Een bijkomende stoornis heeft bijvoorbeeld geen impact op de spellingprestaties van een kind. Het is daarom belangrijk om de app te ontwerpen met de diversiteit van dyslexie in gedachten.

\subsection{Bewezen voordelen van tekstvereenvoudiging bij scholieren met dyslexie}

\subsubsection{Kortere decodeertijd}

Het experiment van \textcite{Rello2013} wijst uit dat de decodeertijd of de tijd nodig om een woord te ontcijferen, drastisch vermindert bij mensen met dyslexie bij een frequent woordgebruik. De decodeertijden bij deelnemers met dyslexie waren de significant korter bij het gebruik van frequente woordenschat. De decodeertijd bij woordenschat met een minder aantal voorkomens lag hoger. Het verschil bij deelnemers zonder dyslexie was amper merkbaar.

\begin{figure}
	\includegraphics[width=\linewidth]{img/readability-mean-fixation-duration.png}
	\caption{Afbeelding van \textcite{Rello2013}. Volgens de richting van de pijl wordt de ideale situatie benaderd, gekenmerkt door doelwaarden. Deze waarden worden bereikt door mensen zonder dyslexie onder optimale omstandigheden. Het gebruik van vaak voorkomende woorden vermindert de decodeertijd en verbetert de leesbaarheid voor mensen met dyslexie.}
\end{figure}


\subsubsection{Digitale weergave}

Bij digitale en uitgeprinte documenten worden de letters vergroot. De achtergrondkleur aanpassen naar zachtgeel, -groen of lichtblauw heeft een verbeterd effect op scholieren met dyslexie in het lager en middelbaar onderwijs \autocite{Bezem2016, Rello2017}. 

\textcite{Rello2012} voerde een onderzoek uit naar de ideale parameters voor een digitale toepassing die zich richt op het weergeven van tekst en rekening houdt met visuele dysfuncties bij mensen met dyslexie.

% todo \textcite{Rosetti2022}

\section{Wetenschappelijke artikelen}

\subsection{Wetenschappelijke geletterdheid in Vlaanderen}

De \textit{Programme for International Student Assessment} of PISA-test\footnote{https://www.pisa.ugent.be/resultaten/pisa-2022} van OESO is een driejaarlijkse test bij vijftienjarigen. Deze test bestudeert de wiskundige en wetenschappelijke geletterdheid\footnote{“Het beheersen van vaardigheden om als kritische burger om te gaan met wetenschappelijke onderwerpen en ideeën.” volgens \textcite{DeMeyer2019}} van 15-jarigen in geïndustrialiseerde landen, wat op ongeveer 79 landen komt. 4822 Vlaamse scholieren van vijftien jaar namen deel aan deze test. Dit onderzoek baseert op de cijfers van 2018, aangezien de testen van 2022 pas eind 2023 worden gepresenteerd. Deze testen houden echter geen rekening met leer- en leesstoornissen, waaronder dyslexie en dyscalculie. Het is echter nodig om deze cijfers mee te geven, om een idee te geven waar de doelgroep staat voor de start van de derde graad middelbaar onderwijs. 

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=\linewidth]{img/oeso-graphic-pisa-trend-samenvatting.png}
	\end{center}
	\caption{Figuur van \textcite{DeMeyer2019}. Op alle PISA-domeinen scoren de Vlaamse vijftienjarigen in ASO, BSO en TSO significant slechter dan de eerste metingen. \textcite{DeMeyer2019} noemen dit een achteruitgang in alle onderwijsvormen.}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=\linewidth]{img/oeso-graphic-leesplezier.png}
	\end{center}
	\caption{Figuur van \textcite{DeMeyer2019}. Het leesplezier van Vlaamse 15-jarigen. Zij uitten zich uiterst negatief op stellingen over leesplezier. Volgens de enquète vond de helft van de scholieren begrijpend lezen enkel tijdsverlies en slechts 17\% gaf aan dat lezen één van hun favoriete hobby's is. Er is wel een significant verschil tussen de mening van jongens en meisjes, waarvan jongens negatiever antwoorden op lezen.}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=5cm]{img/oeso-graphic-wetenschappelijke-geletterdheid-2.png}
	\end{center}
	\caption{Figuur van \textcite{DeMeyer2019}. De wetenschappelijke geletterdheid bij vijftienjarigen op internationaal niveau. Vlaanderen scoort significant slechter dan acht deelnemende landen.}
\end{figure}


\subsection{Trends rond wetenschappelijke artikelen}
% inleiding over het formaat van teksten

De leesgraad van wetenschappelijke teksten volgt al sinds de tweede helft van de twintigste eeuw een stijgende trend \autocite{Hayes1992}. Meerdere onderzoeken in de voorbije tien jaar besluiten dat de complexe woordenschat en zinsbouw deze wetenschappelijke artikelen ontoegankelijk maakt voor doelgroepen naast onderzoekers \autocite{Ball2017, PlavenSigray2017, Jones2019}. 

% \textcite{Ball2017}

\textcite{PlavenSigray2017} onderzoekt de verschillende trends waarom wetenschappelijke artikelen alsmaar moeilijker te lezen worden. De relatie tussen de leesbaarheid van een abstract werd vergeleken met het jaar waarin het wetenschappelijk artikel werd gepubliceerd. De \textit{Flesch-Reading-Ease} of FRE score werd gebruikt om de leesgraad van een wetenschappelijk artikel te beoordelen. Om te bevestigen dat de relatie tussen de complexiteit van een abstract overeenstemt met die van de volledige tekstinhoud, werden er vergelijkingen gemaakt met zes verschillende wetenschappelijke journalen. De overeenkomst tussen de leesgraad van het abstract en de overige tekstinhoud in een wetenschappelijk artikel werd eerder bevestigd door \textcite{Dronberger1975}. Dat onderzoek benadrukte dat een abstract complexer werd geschreven, vergeleken met de rest van een wetenschappelijk artikel.

\begin{figure}[H]
	\includegraphics[width=\linewidth]{img/fre-ndc.png}
	\caption{Afbeelding uit \textcite{PlavenSigray2017}. Links wordt de evolutie per FRE-score getoond. Hoe hoger de score, hoe hoger de gemiddelde complexiteit van een tekst. Rechts wordt de evolutie volgens de NDC-score getoond. Hoe hoger de score, hoe lager de gemiddelde complexiteit van een tekst. Het onderzoek schat dat nu een kwart van alle wetenschappelijke artikelen gebruik maken van Engels op het niveau van een masterstudent, ofwel een FRE onder nul.}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=\linewidth]{img/ndc-number-of-authors.png}
	\caption{Afbeelding uit \textcite{PlavenSigray2017}. Horizontaal worden het aantal auteurs per wetenschappelijk artikel aangeduidt. Verticaal wordt de gemiddelde NDC-score weergegeven. HOe hoger de NDC-score, hoe hoger de vereiste leesgraad om de tekst te kunnen lezen.}
\end{figure}

De hoge leesgraad van wetenschappelijke artikelen beperkt volgens \textcite{PlavenSigray2017} twee aspecten: de toegankelijkheid en de herproduceerbaarheid.

\subsubsection{Toegankelijkheid}

Bronnen worden minder toegankelijk tot het algemene publiek. Wetenschappelijke artikels worden enkel toegankelijk tot mensen die wetenschappelijk geletterd zijn of een leesgraad daarboven hebben. \textcite{Ennals2010} zegt dat wetenschap ons de nauwkeurige kennis moet geven, omdat mensen zich zorgen maken dat moderne samenlevingen minder streng worden met feitelijke waarheden en deze vervangen door \textit{post-facts} die waar lijken te klinken. Wetenschappelijke inhoud moet volgens hem zo toegankelijk mogelijk worden gemaakt, zodat een zo breed mogelijk publiek de kern begrijpt.

\subsubsection{Reproduceerbaarheid}

Onbegrijpelijke en ontoegankelijke zinsstructuren hinderen ook vakexperten. Het herschrijven van abstracten vergroot de begrijpbaarheid bij academici volgens \textcite{Hartley1999, Snow2010}. De wetenschap bouwt voort op betrouwbare ontdekkingen en het reproduceren van experimenten is een belangrijke manier voor wetenschappers om vertrouwen te krijgen in hun besluiten. De inhoud van het wetenschappelijke artikel moet gecontroleerd kunnen worden. Voor de reproduceerbaarheid van onderzoeken is het volgens \textcite{McNutt2014} belangrijk dat de methodologie en resultaten begrijpelijk zijn. Een lage leesgraad en duidelijke zinsbouw beperkt het aantal misopvattingen en verwarringen bij onderzoekers.

% todo FRE grens aanduiden op volgende grafieken

\subsection{Formaat en structuur}

Wetenschappelijke artikelen hebben een uniform formaat. Experimenten uit \textcite{Hubbard2017} wijzen erop dat de bevraagde onderzoekers zowel de methodologie als de resultaten de twee componenten vonden die een hoge leesgraad vergden. 



% https://psychology.ucsd.edu/undergraduate-program/undergraduate-resources/academic-writing-resources/writing-research-papers/research-paper-structure.html#:~:text=A%20complete%20research%20paper%20in,%2C%20Discussion%2C%20and%20References%20sections.&text=Many%20will%20also%20contain%20Figures,have%20an%20Appendix%20or%20Appendices.

% todo Abstracten bij wetenschappelijke artikelen 

\subsection{Woordenschat en vakjargon}

Complexe processen, methoden en ideeën worden in wetenschappelijke artikelen verwoord met gebruik van grammatische embeddings, doordachte en abstracte woordenschat en naamwoordstijlen. De kenmerken van academische taal variëren afhankelijk van de discipline, het onderwerp en de vorm, maar er zijn gemeenschappelijke kenmerken die wetenschappelijke taal onderscheiden van taal van een lagere leesgraad. \autocite{Ennals2010, Snow2010}

Wetenschappelijke artikelen dienen volgens \textcite{PlavenSigray2017} in eerste instantie als uitwisseling van kennis tussen vakexperten. Daarnaast moet er rekening worden gehouden met de lengte wat een nadelig effect heeft op de beschikbare uitleg voor deze terminologie.

\textcite{Snow2010} beklemtoont dat deze zaken in het onderwijs moeten betrokken worden. STEM-vakken of vakken waar deze wetenschappelijke artikelen aan bod komen, moeten stil staan bij voldoende uitleg over de toegepaste grammatica en woordenschat voorzien tijdens de lessen.


% https://ctsi.ucla.edu/education/files/view/docs/06_08_2016_PALM_Communication_of_Science_Poster.pdf

\begin{figure}[H]
	\includegraphics[width=5cm]{img/fre-fog-per-sector.png}
	\caption{Afbeelding van (...) Volgens deze grafiek scoren de wetenschappelijke artikels rond fysica gemiddeld het best op de FRE-score. Al scoren de wetenschappelijke artikels rond microbiologie gemiddeld het zwakst op de FRE-score, ze scoren gemiddeld beter op de FOG-score.}
\end{figure}

\subsection{Aanpak voor het lezen van wetenschappelijke artikelen}

Als reactie op een satirisch artikel van \textcite{Ruben2016}, bracht \textcite{Pain2016} het onderwerp bij wetenschappers aan het licht om zo verschillende tactieken te verzamelen om wetenschappelijke artikelen te begrijpen. Sommige wetenschappers zoeken direct onbekende woorden op of raadplegen extra informatiebronnen, terwijl andere wetenschappers hoofdstukken overslaan. Het is belangrijk om een balans te vinden tussen het begrijpen van de inhoud en het efficiënt gebruiken van de tijd. Sommige wetenschappers geven toe dat ze het soms opgeven als het te moeilijk wordt of als de literatuur net niet relevant is voor hun onderzoek. {Pain2016} bouwt verder op deze adviesen en geeft verdere tactieken mee hoe (startende) lezers wetenschappelijke artikelen kunnen aanpakken.

\begin{itemize}
	\item Begin altijd met het lezen van de samenvatting en conclusie om een idee te krijgen van het doel en de uitkomst van het onderzoek.
	\item De figuren en tabellen in het artikel zijn cruciaal omdat deze een snelle en duidelijke weergave geven van de belangrijkste bevindingen.
	\item Focus op de informatie die je nodig hebt en ga vervolgens terug om de technische details te begrijpen.
	\item Let op de beperkingen en juiste interpretatie van de resultaten, en controleer of de onderzoeksvraag en -methode adequaat zijn.
	\item Controleer of de referenties relevant zijn en zoek naar andere artikelen over hetzelfde onderwerp.
	\item Overweeg welke stukken opwindend, nieuw en relevant zijn voor uw eigen onderzoeksvragen en hypotheses.
	\item Maak aantekeningen en schrijf terwijl je leest, zodat je actief betrokken bent bij het lezen van het artikel.
\end{itemize}

De bevraagde onderzoekers in het onderzoek van \textcite{Hubbard2017} geven de volgende tips mee. Wetenschappelijke artikelen vereist een selectieve leesstijl, waarbij bepaalde delen van het artikel worden geprioriteerd, zoals het abstract. Het abstract en de discussie bepaalt of het artikel de moeite waard is om te lezen. Sommige bevraagden adviseren om de methodologie te negeren en direct over te gaan naar de discussie of resultaten, terwijl anderen onderzoekers aanbevelen om eerst de hypothesen van een artikel te achterhalen. Een artikel wordt ook best meermaals gelezen, waarbij de lezer steeds in meer detail leest. Kritisch lezen is belangrijk, waarbij de conclusies worden beoordeeld en de data voor zichzelf spreekt. Er is geen standaardaanpak volgens \textcite{Hubbard2017}, maar de bevraagde onderzoekers bevelen tactieken aan zoals selectief, kritisch en met een specifiek doel voor ogen lezen.

\subsection{Conclusie}

Het lezen van wetenschappelijke artikelen kan overweldigend zijn, vooral bij onbekende vakgebieden, lange artikelen en technisch jargon. Nieuwe versies van een wetenschappelijk artikel moeten nieuwe doelgroepen toelaten om over voldoende achtergrondinformatie te beschikken.

\section{Tekstvereenvoudiging}

Vereenvoudigde teksten worden geschreven om leerlingen te helpen specifieke taalkenmerken te begrijpen, de hoeveelheid nieuwe woordenschat te beperken of de complexiteit van de tekst te beheersen. Deskundigen zijn van mening dat vereenvoudigde teksten nuttig zijn voor startende en gevorderde lezers \autocite{Louwerse2007}. Samenvattingen van teksten bieden een oplossing om een snel zicht te krijgen over (lange) documenten, of om snel zaken te herinneren over een tekst die al gelezen is \autocite{McCombes2020}. Vereenvoudigen kan handmatig door de docent gebeuren, maar recente technologische ontwikkelingen bieden de mogelijkheid om dit proces te automatiseren.

\subsection{Manuele tekstvereenvoudiging}

Wetenschappelijke artikelen moeten informatie begrijpelijk weergeven voor een breed publiek, waaronder de scholieren die deze artikelen voorgeschoteld krijgen. Vereenvoudigde teksten zijn nuttig volgens (Simensen) om drie redenen, namelijk het illustreren van een specifiek taalkenmerk, ongekende woordenschat voor een doelgroep aan te passen en de hoeveelheid gegeven informatie onder controle te houden. 

\textcite{Crossley2012} wijst op twee soorten van handmatige tekstvereenvoudiging. Intuïtieve tekstvereenvoudiging is een methode waar de auteur die de transformatie uitvoert, wordt beïnvloed door persoonlijke vermoedens over wat een tekst beter leesbaar maakt. Structurele vereenvoudiging daarentegen vervangt vermoedens door het gebruik van woordenlijsten en leesbaarheidsformules zoals Flesch Reading Ease, Gunning Fog en SMOG-Cro en de Coleman-Liau Index.

Er zijn gekende technieken dat leerkrachten kunnen toepassen om artikels te vereenvoudigen. \textcite{Dubay2004} haalt vier categorieën en principes aan die bijdragen tot een eenvoudigere tekst.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=5cm]{img/text-simplification-reading-ease.png}
	\end{center}
	\caption{Afbeelding van \textcite{Dubay2004}}
\end{figure}


\subsubsection{Lengte en formaat}

De leesgraad van de woordenschat moet overeenstemmen met de syntactische leesgraad. vereenvoudigd. Vervolgens kan tekst naar een ander formaat worden omgezet, zoals \textit{post-itnotes}, \textit{postcards} of emails, om het begrijpelijker te maken. Dit wordt vooral ingezet in het lager onderwijs. De schrijf- en vertelstijl moet consistent blijven in het nieuwe formaat. Ten slotte moeten verwijswoorden worden aangepast om de tekst toegankelijker te maken voor meertalige lezers. Bijvoorbeeld door eenvoudige verwijswoorden zoals 'zij' of namen te gebruiken \autocite{Rijkhoff2022}. 

Een samenvatting verkort de lengte van een tekst. Kernzinnen en trefwoorden worden eerst in een tekst gemarkeerd en vervolgens op een nieuw blad geschreven. De kernzinnen worden achterhaald door woord- en zoektermfrequentie en anderzijds door het stellen van algemene vragen over het artikel. Trefwoorden achterhalen gebeurt gelijkaardig en deze zijn regelmatig af te leiden uit de inhoudstafel en titels. Voor deze twee methoden moet de persoon die een samenvatting maakt al vooraf de tekst meermaals gelezen hebben. Een alternatief op markeren is het parafraseren van de tekst. De geparafraseerde tekst blijft semantisch gelijk, maar het neemt een andere syntax, structuur en woordenschat aan \autocite{Rijkhoff2022}.


Volgens \textcite{Hollenkamp2020, McCombes2022} moet de samenvatting van een wetenschappelijk artikel altijd de volgende drie vragen kunnen beantwoorden: 

\begin{itemize}
	\item Waarom werd het onderzoek verricht? Welke achtergrondinformatie en context nam de onderzoeker in achting. Daarnaast moeten de geformuleerde hypotheses aan bod komen.
	\item Wat werd er geëxperimenteerd? Alle gebruikte methoden en resultaten moeten in een samenvatting terug te vinden zijn en enkel de noodzakelijke kwalitatieve waarden mogen aan bod komen.
	\item Welke conclusies trekken de onderzoeker(s) uit het onderzoek? De implicaties en beperkingen tijdens het onderzoek, alsook de aanradingen moeten in de samenvattingen aan bod komen.
\end{itemize}



\subsubsection{Woordenschat}

Moeilijke woorden kunnen op twee manieren beperkt worden. Eerst moet een tekst op maat zijn van het doelpubliek. De gehanteerde (vak)termen moeten begrijpelijk zijn voor iedereen binnen het doelpubliek. Deze leesgraad en voorkennis wisselt sterk af bij scholieren in de laatste graad middelbaar onderwijs. Als het niet mogelijk is om eenvoudigere synoniemen te gebruiken, dan komt het van pas om de woorden uit te leggen. Dit hoeft enkel te gebeuren bij de eerste keer dat deze woorden voorkomen \autocite{Bosmans2022a, Bosmans2022b}. \textcite{Case2008} haalt aan om homoniemen en homofonen te vervangen. % TODO aanvullen

\subsubsection{Grammatica}

Mensen proberen bij het schrijven wel vaak om iets kort en bondig te schrijven, al schrijven veel mensen nog steeds volgens hun gedachten. Dit leidt tot een omslachtige schrijfstijl en dit heeft een nadelig effect op de grammatica in een tekst. Tangconstructies, lange zinsaanlopen en voorzetselketens zijn vaak voorkomende boosdoeners volgens \textcite{Bosmans2022c}. Tangconstructies zijn zinsstructuren waarbij een bijwoordelijke bepaling of bijzin tussen het onderwerp en de persoonsvorm van een zin wordt geplaatst. Tangconstructies kunnen minder zwaar worden gemaakt door de twee grijpers van de tang dichter bij elkaar te brengen of door lange zinnen te splitsen. Aanvullende informatie kan beter kort worden gehouden en vooraan of achteraan in de zin worden geplaatst om onderbrekingen te voorkomen. \textcite{Rijnvis2020, Bosmans2022c} halen drie aanpakken aan om tangconstructies te vermijden:

\begin{itemize}
	\item De bijzin naar het begin of het einde van een zin plaatsen.
	\item De zin splitsen in twee kortere zinnen.
	\item Het onderwerp en de persoonsvorm dichter bij elkaar plaatsen door minder informatie tussen hen in te plaatsen.
\end{itemize}

Een lange zinsaanloop kan worden verkort om de aandacht van de lezer niet op de proef te stellen. Voorzetselketens kunnen worden vermeden door informatie over verschillende zinnen te verdelen. Voorzetseluitdrukkingen worden best vervangen door gewone voorzetsels \autocite{Bosmans2022c}.

\subsubsection{Pedagogische en onderwijsgerelateerde kritieken}

%todo

Al besluit het onderzoek van \textcite{Crossley2012} dat tekstvereenvoudiging een bevorderend effect heeft voor scholieren met afwisselende leesgraden, het onderzoek beklemtoont de unieke aanpakken per docent. Iedere docent heeft een eigen procedure om een vereenvoudigde tekst op maat te kunnen schrijven.

\subsection{Natural Language Processing}

Tekstvereenvoudiging is het proces waarin het technisch leesniveau en/of woordgebruik van een geschreven tekst wordt verminderd. Het resultaat van deze fase is een tekst die korter en aangenamer is, zonder het verlies van de kerninhoud. Binnen machinaal leren (ML) is tekstvereenvoudiging een zijtak van natuurlijke taalverwerking. \autocite{Siddharthan2006} Volgens \autocite{Siddharthan2014} bestaat een complete en geautomatiseerde tekstvereenvoudiging uit vier verschillende vereenvoudigingen. 

\textit{Natural Language Processing} (NLP) of natuurlijke taalverwerking is een brede term die zich richt op het verwerken en analyseren van menselijke taal door computers \autocite{Eisenstein2019}. NLP omvat verschillende technieken, zoals tekstanalyse, taalherkenning en -generatie, spraakherkenning en -synthese, en semantische analyse. Computers zijn in staat om op een menselijke manier te communiceren en begrijpen wat er wordt gezegd. De volgende begrippen worden aangehaald in \textcite{Sohom2019, Eisenstein2019} en zijn fundamenteel voor de concepten die volgen.

\subsubsection{Tokenisation}

Tokenisatie} splitst de stam of basisvorm van woorden in een tekst. Gebruikelijk zetten ontwikkelaars deze stap in om een woordenschat voor een taalmodel op te bouwen. Bij tokenisatie wordt er geen rekening gehouden met de betekenis achter ieder woord. Tokeniseren kan volgens \textcite{Menzli2023} op vier manieren:


\begin{itemize}
	\item Word-level tokenisation of WTL splitst de tekst op per woord.
	\item Character-level tokenisation of CLT splitst de tekst per karakter. 'Slimmer' wordt s-l-i-m-m-e-r. Deze vorm achterhaalt de semantiek van een tekst beter en laat de het. Nadelig hebben de karakters op zich weinig betekenis, alsook maakt deze vorm de inputlengte groter. \autocite{Ribeiro2018}
	\item Subword-level tokenisation splitst de tekst op in stukken op basis van de woordfrequentie. Veelvoorkomende woorden worden hele woorden getokeniseerd, terwijl zeldzamere woorden opgesplitst worden in kleinere stukken die kunnen worden gebruikt. De rest van de woorden in de relevante dataset te creëren. Dit biedt een voordeel ten opzichte van word-level tokenisation omdat het een balans biedt tussen WLT en CLT \autocite{Iredale2022}.
	\item Sentence tokenization splitst de tekst op per zin. \textcite{Fardeen2021} haalt aan dat de tokenizer ineffectief is tegen afkortingen, maar dit is afhankelijk volgens de gebruikte dataset. 
\end{itemize}

\begin{table}[h!]
	\centering
	\begin{tabular}{|l|c|c|c|}
		\hline
		Feature & spaCy & NLTK & Gensim \\
		\hline
		Word-level & X & X & X \\
		Character-Level & X & X &  \\
		Subword-Level & X &  & X \\
		Sentence-level & X & X & X \\
		\hline
	\end{tabular}
	\caption{Vergelijking van methodes voor tokenisatie met Spacy, nltk, en gensim.}
	\label{tab:nlp-features}
\end{table}

\subsubsection{Lemmatiseren en parsen}

Lemmatiseren in NLP bouwt verder op \textit{stemming}, maar de betekenis van ieder woord wordt in acht genomen. Voor het lemmatiseren bestaan er Nederlandstalige modellen, waaronder JohnSnow\footnote{https://nlp.johnsnowlabs.com/2020/05/03/lemma\_nl.html}. Bij \textbf{omgekeerd lemmatiseren} wordt er een afgeleide achterhaald vanuit de stam. Bijvoorbeeld voor het werkwoord 'zijn' zou dit 'is', 'was' of 'ben' zijn. Voor zelfstandige naamwoorden, zoals 'hond', is dit dan enkelvoud of meervoud \autocite{Eisenstein2019}.

Bij een \textbf{parsing}-fase wordt er een label aan ieder woord of zinsdeel toegekend. Voorbeelden van labels zijn zelfstandig naamwoord, bijwoord, werkwoord, bijzin of stopwoord. Het herkennen van zinsdelen wordt \textit{chunking} genoemd. Parsing heeft een dubbelzinnigheidsprobleem, want een 'plant' staat niet gelijk aan de vervoeging van werkwoord 'planten' \autocite{Eisenstein2019}.

% Sentimentanalyse is het achterhalen van de mening of gevoelens uit een tekst. de stemming of mening van een tekst te achterhalen op basis van het onderwerp. is een tak van Natural Language Understanding of NLU die de stemming, mening of gevoelens van de schrijver of spreker probeert te achterhalen ten opzichte van het onderwerp. % Dit kan lastig zijn omdat niet elke tekst een duidelijk positief of negatief sentiment heeft. 

\subsubsection{Sequence labeling en part-of-speech tagging}

Een machine moet de betekenis achter ieder token kunnen vatten. Hier komt \textit{sequence labeling} aan de pas volgens \textcite{Eisenstein2019}. Elk woord in een tekst wordt gekoppeld aan een \textit{Part-of-Speech} (PoS) of \textit{Named-Entity-Recognition} (NER) label. Deze NLP-fase achterhaalt de structuur van een tekst. PoS-tagging richt zich op grammaticale categorieën van woorden, terwijl NER-labeling instaat voor het herkennen van specifieke entiteiten in een tekst. 

Bij PoS-tagging worden de woorden in een zin geanalyseerd. Elk woord wordt gekoppeld aan een grammaticale categorie, zoals een zelfstandig naamwoord, werkwoord, bijvoeglijk naamwoord of bijwoord. \textit{PoS-tagging} helpt bij het achterhalen van de syntactische structuur van een zin. Deze taak komt van pas bij parsing en machinevertaling. \textit{PoS-tagging} wordt aanschouwelijk gemaakt op \ref{fig:pos}

Namen van personen, organisaties en locaties worden herkend en geclassificeerd met NER-labeling. Met NER-labeling wordt volgens \textcite{Jurafsky2014} specifieke informatie uit tekst gehaald, zoals het identificeren van de namen van personen, plaatsen of bedrijven die in nieuwsartikelen worden genoemd, of het extraheren van belangrijke data of getallen uit financiële rapporten. Dit wordt aanschouwelijk gemaakt \ref{fig:ner}. \textcite{Li2018} benoemt vier vormen voor NER-labeling:

\begin{itemize}
		\item \textit{Dictionary-based NER labeling} gebruikt vooraf gedefinieerde woordenboeken die de namen van de entiteiten bevatten. Het vergelijkt de woorden in de tekst met de woordenboeken en labelt ze als ze overeenkomen.
		\item \textit{Rule-based NER labeling} gebruikt vooraf gedefinieerde regels die gebaseerd zijn op syntactische of semantische patronen om de entiteiten te identificeren. Het past de regels toe op de tekst en labelt de woorden die aan de regels voldoen.
		\item \textit{Machine learning-based NER labeling} gebruikt statistische modellen zoals Hidden Markov Model (HMM) of Conditional Random Field (CRF) om te leren van gelabelde trainingsgegevens hoe ze entiteiten kunnen herkennen. Het gebruikt kenmerken zoals het woord zelf, omliggende PoS-labels en het hoofdlettergebruik om te beslissen welk label aan elk woord moet worden toegekend.
		\item Deep learning-based NER labeling gebruikt neurale netwerken zoals recurrent neural network (RNN) of convolutional neural network (CNN) om te leren van ongelabelde of gedeeltelijk gelabelde trainingsgegevens hoe ze entiteiten kunnen herkennen. Het gebruikt woordvectoren en niet-lineaire representaties om complexe relaties tussen woorden te modelleren.
\end{itemize}

% Ten slotte halen \textcite{Li2018} Python-bibliotheken aan om een pipeline voor NER-labeling mogelijk te maken. Spacy heeft deze functie ingebouwd. Standford NER-tagger is een tool die samen met het NLTK-pakket werkt.

\textcite{Poel2008} onderzocht \textit{PoS-tagging} met een neuraal netwerk voor Nederlandstalige teksten. Het model behaalde een nauwkeurigheid van 97,88\% voor bekende woorden en 41,67\% voor onbekende woorden. Het model gebruikte de Corpus Gesproken Nederlands (CGN) als trainingsdata.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=10cm]{img/poslabeling.png}
	\end{center}
	\caption{Voorbeeld van PoS-labeling op de Engelstalige zin "She sells seashells on the seashore". Afbeelding van \textcite{Bilisci2021} }
	\label{fig:pos}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=10cm]{img/nerlabeling.jpg}
	\end{center}
	\caption{Voorbeeld van sequence labeling op de Engelstalige zin "She sells seashells on the seashore". Afbeelding van \textcite{Bilisci2021} }
	\label{fig:ner}
\end{figure}


\subsubsection{Prompt engineering}

% Liu2021

\subsubsection{NLP-features per Python-library}

% TODO tabel

\section{De verschillende soorten tekstvereenvoudiging}

Tekstvereenvoudiging bestaat volgens \textcite{Siddharthan2014} uit vier soorten transformaties: lexicale, syntactische en semantische vereenvoudiging en samenvatten.

\begin{figure}[H]
	\begin{center}
			\includegraphics[width=5cm]{img/voorbeeld-manuele-vereenvoudiging.png}
	\end{center}
	\caption{Voorbeeld van tekstvereenvoudiging. Oorspronkelijke tekst uit Historia 5 bron toe te voegen}
\end{figure}

\subsection{Lexicale vereenvoudiging}

Bij \textit{lexical simplification} (LS) of lexicale vereenvoudiging worden complexe woorden vervangen door eenvoudigere synoniemen. Bijvoorbeeld, het woord 'adhesief' wordt vervangen door 'klevend'. \textcite{Kandula2010} haalt twee manieren aan om lexicale vereenvoudiging mogelijk te maken, namelijk het vervangen door een synoniem en het aanmaken of genereren van extra uitleg. De zinsstructuur verandert niet en er is garantie dat de kerninhoud en benadrukking in een tekst identiek blijft. Het doel van lexicale vereenvoudiging is om de moeilijkheidsgraad van de woordenschat in een zin of tekst te verlagen. 

% Dit is, volgens het aantal onderzoeken, de meest gekende vorm van vereenvoudiging en een noodzakelijke stap bij het vereenvoudigen van een tekst. Voor prevalente domeinen, zoals de onderwijs-, medische en financiële sector, zijn er onderzoeken vrij beschikbaar. 

\subsubsection{Complex Word Identification}

\textit{Complex word identification} of CWI is een gesuperviseerde NLP-taak. In een pipeline voor lexicale tekstvereenvoudiging is CWI de eerste stap. Moeilijke woorden of \textit{multi-word expressions} (MWE) in een tekst worden achterhaald  \autocite{Shardlow2013, Gooding2019}. Na CWI kan LS gebruikt worden om deze woorden te vervangen door eenvoudigere synoniemen of om verdere elaboratie te voorzien met behulp van voorbeelden of definities \autocite{Zeng2005, Kandula2010}. CWI is volgens \textcite{Shardlow2013} een cruciale stap, want een lage \textit{recall} van dit component zal een uitvoertekst geven waar moeilijke woorden niet worden vereenvoudigd. Het model zal moeilijke woorden laten staan.

\subsubsection{Substitutiegeneratie en ranking}

Substitutiegeneratie wordt gedaan door synoniemen te zoeken voor een doelwoord in lexicale databanken zoals WordNet, BERT, context2vec, nPIC of OOC. Voor de Nederlandse taal zijn er twee alternatieven, gebouwd vanop BERT, namelijk RobBERT en BERTje. Volgens (..) is RobBERT de krachtigste van de twee modellen, waar BERTje compacter is. Vervolgens bepaalt de \textit{Substitution Ranking} stap welke vervanging de beste is uit een set van kandidaten. Ranking gebeurt met het rangschikken van gegenereerde substituties op basis van relevantie.

\begin{figure}[H]
	\includegraphics{img/lexical-simplification-pipeline.png}
	\caption{Afbeelding van \textcite{Althunayyan2021}. Deze pipeline wordt in meerdere onderzoeken rond lexicale vereenvoudiging toegepast, zoals \textcite{Paetzold2016, Bingel2018, Bulte2018}}
\end{figure}

% todo FrenLys

% todo \textcite{Bingel2018}

\subsection{Syntactische vereenvoudiging}

Syntactische vereenvoudiging verlaagt de leesgraad en complexiteit van een zin door de grammatica en zinsstructuur van een tekst aan te passen. Twee afzonderlijke zinnen kunnen samengevoegd worden tot één eenvoudigere zin. Zo worden complexe of onduidelijke zinsconstructies verminderd, terwijl de inhoud en betekenis van de tekst behouden blijft. Dergelijke transformaties zijn het vereenvoudigen van de syntax of door de zinnen korter te maken. Zinnen worden toegankelijker, zonder de kerninhoud of relevante inhoud te verliezen.

\textcite{Kandula2010} ontwikkelde een toepassing om medische informatie bij beschikbare biomedische bronnen te vereenvoudigen. Dit model verlaagt de leesgraad door syntactische vereenvoudiging op zinniveau toe te passen. Zinnen met meer dan tien woorden worden in het onderzoek als complex beschouwd en worden vereenvoudigd door drie modules. Na deze transformatie kan de oorspronkelijke zin ongewijzigd worden behouden of vervangen worden door twee of meer kortere zinnen. De architectuur van dit model omvat drie onderdelen: een \textit{Part of Speech (PoS) Tagger}, een \textit{Grammar Simplifier} en een \textit{Output Validator}. 

\begin{itemize}
	\item Voor de \textit{PoS Tagger}-fase gebruikten \textcite{Kandula2010} beschikbare functies uit het open-source pakket OpenNLP\footnote{https://opennlp.apache.org/}.
	\item De \textit{Grammar Simplifier} module splitst de lange zin in twee of meer kortere zinnen door POS-patronen te identificeren en een set transformatieregels toe te passen.
	\item De \textit{Output Validator} module controleert de output van de Grammar Simplifier op grammatica en leesbaarheid.
\end{itemize}  

% todo probleemstelling van lexicaal vereenvoudigen

\subsection{Conceptuele of semantische vereenvoudiging}

Conceptuele tekstvereenvoudiging deelt complexe concepten op in eenvoudigere delen, past duidelijke en bondige taal toe en vermijdt technische jargon en abstracte uitdrukkingen. Er wordt meer uitleg of voorbeelden gegeven, of dat niet-relevante delen van de tekst worden weggelaten. Na deze transformatie is de tekst beter te begrijpen, zonder het verlies aan betekenis of nauwkeurigheid. \textcite{Siddharthan2014} noemt deze transformatie een vorm van elaboratie of het uiteenzetten van een begrip.

\subsection{Overige vormen van vereenvoudiging}

Metaforen, \textit{short language} of \textit{slang} en idiomen kan de menselijke interpretatie van een zin of paragraaf in de war brengen. Pragmatische vereenvoudiging zet deze constructies om naar een letterlijke en duidelijke tekst \autocite{JavoureyDrevet2022}. Ten slotte is het mogelijk om parafrases en alinea's in een ander formaat te schrijven. Een opsomming of oplijsting benadrukt belangrijke punten en maakt een duidelijke structuur van een mogelijks complexe tekst. Dezelfde tekst wordt meer beklemtoond wanneer deze als een opsomming wordt weergegeven, in plaats van als een eenvoudige zin \autocite{Siddharthan2014, Hale2022}. 

\subsection{Tekstvereenvoudiging automatiseren}

Geautomatiseerde tekstvereenvoudiging is geen nieuw concept. Volgens onderzoeken van \textcite{Canning2000, Siddharthan2006} waren de eerste aanpakken op geautomatiseerde tekstvereenvoudiging gebouwd op rule-based modellen. Deze modellen bewerken de syntax door zinnen te splitsen, te verwijderen of de volgorde van de zinnen in een tekst aan te passen. Lexicale vereenvoudiging kwam hier niet aan de pas. Enkel bij recentere onderzoeken van \textcite{Coster2011, Bulte2018} werd het duidelijk hoe lexicale en syntactische vereenvoudiging gecombineerd kon worden.

\subsection{Combineren tot het geheel van tekstvereenvoudiging}

Het onderzoek van \textcite{DeBelder2010} richt zich op tekstvereenvoudiging voor kinderen. De doelgroep ligt echter jonger dan deze casus, maar het onderzoek haalt aan hoe de onderzoekers een methode opzetten voor lexicale en syntactische vereenvoudiging. \textcite{Bulte2018} werkte het aspect rond lexicale vereenvoudiging verder uit. Het resultaat van dit onderzoek was een \textit{pipeline} ontworpen om moeilijke woordenschat naar simpele synoniemen te vervangen. Eerst ging de tekstinhoud door een \textit{preprocessing}-fase, samen met het uitvoeren van WSE. Daarna werd de moeilijkheidsgraad van ieder token overlopen. De moeilijkheidsgraad is gebaseerd op hoe vaak een woord voorkomt in SONAR500\footnote{https://taalmaterialen.ivdnt.org/download/tstc-sonar-corpus/} een corpus met eenvoudige Nederlandstalige woorden. Synoniemen werden teruggevonden met Cornetto\footnote{https://github.com/emsrc/pycornetto}, een lexicale databank met Nederlandstalige woorden. Hiervoor gebruikten de onderzoekers een \textit{reverse lemmatization} fase. Lexicale vereenvoudiging is ingewikkeld wanneer er geen eenvoudigere synoniemen zijn. In dat geval blijft een moeilijk woord voor wat het is.

\section{Samenvatten}

Teksten vereenvoudigen met lexicale, conceptuele en/of syntactische vereenvoudiging biedt geen garantie dat de tekstinhoud korter zal worden. Bij de drie soorten vereenvoudiging wordt er initieel enkel per zin gekeken. De vereenvoudiging houdt geen rekening met voorafgaande of opvolgende zinnen \autocite{Dubay2004}. Teksten machinaal samenvatten is geen nieuw concept. Het onderzoek van \textcite{Hahn2000} onderzoekt hoe teksten automatisch samengevat kunnen worden. Dit onderzoek haalt onder meer twee aanpakken aan hoe een machine teksten kan samenvatten, namelijk extraherend en abstraherend. Daarnaast reikt \textcite{Hahn2000} drie manieren aan welke inhoud er zeker in de samengevatte versie moet op te merken zijn:

\begin{itemize}
	\item Informatieve samenvattingen vervangen de oorspronkelijke tekst. Alles wat de lezer nodig heeft, dus hoofd- en bijzaken, zijn betrokken in de samengevatte tekst.
	\item Indicatieve samenvattingen behouden enkel een tekst met links die een lezer doorverwijzen naar andere bronnen. 
	\item Kritische samenvattingen of \textit{reviews} bestaan uit de kerninhoud van de oorspronkelijke tekst en een opiniestuk over die specifieke kerninhoud.
\end{itemize}

% Generiek en gebruikersgerichte samenvatting
Verder haalt \textcite{Hahn2000} ook het onderscheid tussen een generieke en een gebruikersgerichte samenvatting. Een generieke samenvatting staat niet stil bij speciale noden of interesses van de eindgebruiker. Daarnaast houdt een gebruikersgerichte samenvatting wel rekening met sleutelwoorden of thema's in een tekst. \textcite{Hahn2000} haalt aan dat technologieën zoals \textit{full-text-search} en gepersonaliseerde informatiefiltering het belang van gebruikersgerichte samenvatting naar voor duwen. \textcite{Hahn2000} omschrijft de architectuur van een samenvattingssysteem aan de hand van drie fases. Allereerst wordt de brontekst geanalyseerd. Daarna worden de \textit{salient points} of kernpunten in een tekst aangeduid. Deze punten zijn zinnen of tokens. Ten slotte worden de punten samengevoegd tot één uitvoertekst. De nadruk is verschillend per samenvattingsmethode.

\begin{figure}
	\includegraphics{img/summarization-mindmap.png}
	\caption{Afbeelding van \textcite{Chauchan2018}. De manier waarop teksten automatisch samengevat kunnen worden, is afhankelijk van drie verschillende domeinen.}
\end{figure}



\subsection{Extraherend samenvatten}

% todo Leveraging BERT for Extractive Text Summarization on Lectures

Bij deze vorm worden de belangrijkste zinnen gemarkeerd en vervolgens opnieuw neergeschreven.  Dit is het equivalent van handmatig zinnen te markeren en vervolgens op een blanco papier neerschrijven. Het nadeel hiervan is dat de uitvoertekst niet samenhangend zal zijn na het samenvatten. Dit maakt de tekst minder aangenaam om te lezen. \textcite{Verma2020} onderzocht de verschillende manieren waarop een tekst op een extractieve manier kan worden samengevat. Zij halen drie grote componenten aan, namelijk:

\begin{itemize}
	\item Graafgebaseerd extraherend samenvatten
	\item Maximal Marginal Relevance
	\item Meta-heuristic-based
\end{itemize}

\subsubsection{Graafgebaseerd extraherend samenvatten}

Graafgebaseerd extraherend samenvatten is een techniek die een document voorstelt als een graaf, waarbij de knopen zinnen voorstellen en bogen de relatie tussen de zinnen voorstellen. Deze algoritmen achterhalen de belangrijkste zinnen in de graaf. Bijvoorbeeld kan het PageRank-algoritme, dat vaak wordt gebruikt voor het rangschikken van webpagina's in zoekmachines, worden gebruikt om de zinnen in de grafiek te rangschikken op basis van hun belangrijkheid.

\textcite{Parveen2015} raadt een graafgebaseerd systeem aan voor \textit{unsupervised learning}. Belangrijke zinnen worden bepaald met een lokaal minimum, alsook wordt redundantie vermeden. Deze methode blijkt goed te werken bij het ophalen van samenvattingen uit zowel lange wetenschappelijke artikelen als korte nieuwsartikelen. Daarnaast vermeldt \textcite{Parveen2015} ook dat het systeem altijd beter presteert wanneer coherentie wordt opgenomen en wanneer het wordt gecombineerd met positionele informatie. In toekomstig werk is \textcite{Parveen2015} van plan om meer taalkundige informatie in de entiteitsgrafiek op te nemen en beoordelingen van domeinexperts te verkrijgen om te zien of de redactiesamenvattingen als gouden samenvattingen kunnen worden gebruikt voor evaluatie.

\textcite{AbdelSalam2022} voerden een vergelijkend onderzoek uit rond SqueezeBERT en BERT. Met behulp van de compacte architectuur van SqueezeBERT kan een samenvatter worden gemaakt en ingezet voor real-time samenvatting. Dit is volgens de onderzoeker een interessant alternatief voor de originele BERT-base samenvatter, die meer dan 120 miljoen trainbare parameters heeft. In vergelijking heeft de voorgestelde SqueezeBERT slechts ongeveer 62 miljoen parameters, terwijl het samenvattingsprestatieniveau nog steeds boven de 90\% van het BERT-baseline model blijft. Uit de experimenten van \textcite{AbdelSalam2022} blijkt dat de SqueezeBERT-samenvatter een goed alternatief is om een samenvatter te trainen met bijna de helft van de grootte van het originele model met minimale afbreuk in de samenvattingsprestaties. Daarnaast blijkt uit het onderzoek dat het gebruik van efficiënte netwerken geïnspireerd door \textit{computer-vision literature}, zoals \textit{grouped convolutional layers}, de NLP downstream taken kan verbeteren.  \textcite{AbdelSalam2022} haalt verder aan dat er potentie is voor een productieversie van een SqueezeBERT-samenvatter, die minder parameters heeft dan DistilBERT met ongeveer 20\% en dezelfde ROUGE-1 score behoudt, terwijl het iets hogere ROUGE-2 en ROUGE-L scores behaalt. Hoewel de SqueezeBERT en DistilBERT iets lagere scores produceren in vergelijking met het BERT-baseline model, heeft SqueezeBERT als voordeel dat het minder trainingstijd en minder parameters heeft dan het baseline model met ~48,44\%. 

\subsubsection{Maximal Marginal Relevance}

Traditionele extractieve samenvattingssystemen bouwen verder op de door \textcite{Carbonell1998} ontworpen architectuur. Deze architectuur gebruikt een maximaal marginale relevantiescore of MMR. Deze architectuur houdt rekening met de diversiteit en de relevantie van de gemarkeerde zinnen. De relevantie van een zin in een tekst wordt bepaald door de mate waarin het de belangrijkste informatie overbrengt van de tekst waarvan het afkomstig is. Om diversiteit aan tekstinhoud te waarborgen, wordt er gekeken naar de mate waarin de geselecteerde zinnen verschillen van de eerder geselecteerde zinnen in de samenvatting. Als een zin relevant is maar qua inhoud te veel overlapt met de eerder geselecteerde zinnen, dan heeft deze minder kans om in de samenvatting opgenomen te worden. Deze score kan doorgaans berekend worden met KeyBERT\footnote{https://maartengr.github.io/KeyBERT/api/mmr.html}.

Extraherend samenvatten met de MMR-methode is de methode bij uitstek voor ML-toepassingen. Onderzoekers bouwden verder op dit principe. In \textcite{McDonald2007} stelt de onderzoeker voor om de gulzige zoekalgoritme van MMR te vervangen door een globaal optimale formulering, waarbij het MMR-framework wordt uitgedrukt als een knapzakprobleem en er een \textit{integer linear programming} (ILP) \textit{solver} kan worden gebruikt om de functie te maximaliseren. De MMR-methode hield voordien enkel rekening met relevantie en diversiteit, maar niet met de optimale combinatie van zinnnen die in een samenvatting moet worden opgenomen. Deze aanpak vereist echter meer rekenkracht en tijd dan de standaard MMR-methode, maar het experiment van \textcite{McDonald2007} haalde wel aan dat dit leidde tot betere resultaten. \textcite{Lin2010} evolueerde het oorspronkelijke MMR-algoritme. Bij de evaluatie van deze architectuur benadrukte zij betere resultaten. 

\subsubsection{Metaheuristiek-gebaseerd}

Metaheuristieke samenvatting maakt gebruik van metaheuristieke optimalisatie-algoritmen zoals genetische algoritmen, \textit{simulated annealing} of zwermoptimalisatie om de belangrijkste zinnen in een tekst te achterhalen. Deze algoritmen zoeken volgens \textcite{Verma2020, Premjith2015} naar de beste combinatie van zinnen die de belangrijkste informatie in de tekst bevatten. De evaluatiefunctie in metaheuristische samenvattingsalgoritmen kan gebaseerd zijn op verschillende criteria, zoals zinslengte, -relevantie en -verbanden. \textcite{Rani2021} benadrukt dat teksten samenvatten met een metaheuristieke methode regelmatig vastraakt in een lokaal optimum. Dit is een tekortkoming op andere methoden. Daarnaast wijst het onderzoek uit aan dat metaheuristieke methoden geen \textit{steepness} of extremen op een \textit{search space behaviour} aanduiden. Er moet gebruikt gemaakt worden van een optimalisatiestrategie die gebaseerd is op gradiënten om de convergentie aanzienlijk te versnellen.

% gradienten: (een wiskundig concept dat de richting van de snelste toename aangeeft)
% convergentie: (het proces waarbij het algoritme naar de juiste oplossing toewerkt) -- Hierdoor wordt het algoritme efficiënter en sneller uitgevoerd.

\subsubsection{Experimenten over extraherend samenvatten}
% \subsubsection{title}

% todo https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1 --> voorbeeld van een pipeline

\textcite{McKeown1999} voerden experimenten uit op extractieve samenvattingen van nieuwsartikelen. De resultaten wijzen erop dat deze vorm vatbaar is op vooroordelen. Bij nieuwsartikelen wordt er geen rekening gehouden met vooroordelen van de auteur. De zinnen worden genomen zoals ze zijn. \textcite{Hahn2000} bouwde verder op dit experiment. Zij voerden een experiment uit met een mix van \textit{knowledge-rich} en \textit{knowledge-poor} methoden, met succesvolle resultaten tot gevolg.

De nadruk bij extraherend samenvatten ligt in het kiezen van de \textit{salient text units}. Deze punten zijn typisch in de vorm van zinnen. Er is nood aan een manier om de lexicale en statistische relevantie van een zin te kunnen aanduiden. Hiervoor haalt \textcite{Hahn2000} twee manieren aan:

\begin{itemize}
	\item Met een lineair gewicht model. Iedere teksteenheid wordt gewogen op factoren zoals de \textit{location weight} en het aantal voorkomens.
	\item Een gewicht model op basis van de statistische opvallendheid van een eenheid. Zo wordt er rekening gehouden met de aanwezigheid van een woord in (sub)titels.
\end{itemize}

% resultaten lineair gewicht model
% resultaten statistische opvallendheid

\textcite{Nallapati2017} wilden de nauwkeurigheid van deze modellen overbruggen. Dit doen ze met \textit{SummaRuNNer}\footnote{https://github.com/hpzhao/SummaRuNNer}, een oplossing voor het extraherend samenvatten van teksten met een neuraal netwerk. De toepassing werd opgebouwd met PyTorch in  en bestaat uit een combinatie van drie modellen: een recurrent neuraal netwerk, een convolutioneel recurrent neuraal netwerk en een \textit{hiërarchical attention network}.

\subsection{Abstraherend samenvatten}

Kernzinnen achterhalen gebeurt bij geautomatiseerde samenvatting met zes features volgens \textcite{Khan2014}, namelijk de woordfrequentie, de plaats van een zin in de tekst, de \textit{cue method} of een woord dat de kerngedachte van een paragraaf benadrukt, titels, de lengte van de zin, de gelijkenissen tussen de zin en de rest van het document, het gebruik van \textit{proper nouns} en ten slotte de afstand tussen \textit{text units} waarin entiteiten voorkomen. Een tekst abstraherend samenvatten kan volgens \textcite{Khan2014} op twee manieren: semantisch en structuurgebaseerd. \textcite{Cao2022} deed verder onderzoek naar \textit{deep learning} methoden om abstraherende samenvattingen te automatiseren.

\begin{figure}
	\begin{center}
		\includegraphics[width=5cm]{img/abstractive-summarization-visualization.png}
	\end{center}
	\caption{test}
\end{figure}


\subsubsection{Structuurgebaseerde benaderingen op abstraherend samenvatten}

Structuurgebaseerde benaderingen zoeken naar belangrijke informatie in de tekst en gebruiken regels om samenvattingen te maken. Ze worden vaak gecombineerd met andere methoden. \textcite{Khan2014} motiveert dat deze vorm ideaal is voor het samenvatten naar korte, samenhangende teksten met redundante zinnen. De linguïstische kwaliteit ligt laag en samengevatte zinnen kunnen volgens \textcite{Khan2014} grammaticale fouten bevatten, omdat een structuurgebaseerde aanpak niet afhankelijk is van de oorspronkelijke tekststructuur.

\subsubsection{Semantisch-gebaseerde benaderingen op abstraherend samenvatten}

De semantisch-gebaseerde benadering gebruikt de betekenis van de tekst om samenvattingen te maken. Deze samenvattingen zijn kort, duidelijk en bevatten veel informatie. Er zijn verschillende manieren om dit te doen. Deze aanpak toont vorderingen op structuurgebaseerd volgens \textcite{Khan2014}. Zo zijn de samenvattingen beknopt en bevatten voldoende kern- en deelzaken voor de lezer. De linguïstische kwaliteit is beter en er zijn minder redundante zinnen. Ten slotte worden er minder grammaticale fouten gemaakt, al is er wel de nood aan een extra parsingfase.

\subsubsection{Abstraherend samenvatten met deep learning}

\textit{Deep learning} voor abstraherend samenvatten kan met verschillende modellen zoals RNN’s (terugkerende neurale netwerken), CNN’s (convolutionele neurale netwerken) en sequence-to-sequence (Seq2Seq) modellen. Deze modellen kunnen leren om samenvattingen te maken door de betekenis van de tekst te begrijpen en nieuwe tekst te maken die de belangrijkste informatie overbrengt \autocite{Suleiman2020}.

Om een abstractieve samenvatting met deep learning op te bouwen bestaan er verschillende modellen. Het Pegasus-model beschreven in \textcite{Zhang2020} handelt \textit{gap-sentences} af met pre-trained models voor samenvatting met NLP.  Dit model werd getrained en beoordeeld op samenvattingstaken zoals emails, patenten, rekeningen en ook wetenschappelijke artikelen \autocite{Zhang2020}.


% Pegasus haalt kernzinnen uit een invoertekst en zal die zinnen vervolgens als één uitvoerzin uitschrijven.


\subsection{Hybride samenvatting}

In het best denkbare geval wordt abstraherende en extraherende samenvatting gecombineerd volgens \textcite{Hsu2018, Huang2019}. Zo omvat een pipeline voor hybride samenvatting twee onderdelen: een \textit{content selection} fase waarin de kernzinnen met extractieve samenvatting worden opgehaald en \textit{paraphrasing} waarbij de gemarkeerde kernzinnen worden samengevat met abstractieve samenvatting. 

\subsection{Evaluatie}

Samenvattingen van lange documenten handmatig beoordelen vergt tijd en voldoende planning van een mens \autocite{Nenkova2004}. Met behulp van een vooraf geschreven samenvatting als referentietekst zorgen twee metrieken voor ondersteuning om een samenvatting automatisch te laten beoordelen. Samenvattingen beoordelen kan ook zonder referentietekst, al moeten verschillende factoren in acting worden genomen.

\subsubsection{Evaluatie met referentieteksten}

Onderzoeken bij het vergelijken van een teksttransformatie schakelen BLEU en ROUGE in. Deze twee metrieken meten de gelijkenis tussen een machine-gegenereerde tekst en een referentietekst. Deze referentietekst is gemaakt door de mens. ROUGE is recall-gebaseerd en gebaseerd op exacte \textit{token matches}. Deze aanpak impliceert dat er geen rekening wordt gehouden met synonieme zinnen of zinnen met een gelijke betekenis \autocite{Lin2004}. De ROUGE-modellen die verderbouwen houden rekening met deze tekortkomingen. ROUGE-2 van \textcite{Ganesan2018} voorziet dictionaries van synoniemen, zodat er rekening wordt gehouden met synonieme zinnen. ROUGE-G van \textcite{ShafieiBavani2018} gebruikt graafalgoritmen om lexicale en semantische matching mogelijk te maken. \textcite{Lin2004} beschrijft een Python-bibliotheek\footnote{https://github.com/pltrdy/rouge} dat de berekening van deze metriek vereenvoudigt.

BLEU volgt een gelijkaardige werking en beoordeelt de gelijkenis tussen een machine-gegenereerde tekst en een referentietekst, maar deze meting is precision-gebaseerd. BLEU introduceert een strafterm voor te korte teksten, om te voorkomen dat modellen alleen maar veelvoorkomende woorden produceren die een hoge precisie opleveren met weinig zinvolle zinnen \autocite{Chiusano2022}. Voor de BLEU-metriek bestaat er ook een Python-bibliotheek\footnote{https://github.com/neural-dialogue-metrics/BLEU}. 

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		Metriek & ROUGE & BLEU \\
		\hline
		Soort metriek & Recall-gebaseerd & Precision-gebaseerd \\
		\hline
		Nut en gebruik & Evalueert hoe goed een samenvatting de belangrijke inhoud van een referentiesamenvatting dekt & Evalueert hoe goed een gegenereerde samenvatting overeenkomt met een referentiesamenvatting \\
		\hline
		Te meten waarde & De overlap van n-grams (sequentie van n woorden) tussen de gegenereerde samenvatting en de referentiesamenvatting & De overlap van n-grams (sequentie van n woorden) tussen de gegenereerde samenvatting en de referentiesamenvatting \\
		\hline
		n-gram range & Meet meestal overlap van 1-4 grams & Kan overlap van 1-4 gram meten, of elk ander bereik van n-grams \\
		\hline
		Weging & Gewogen of ongewogen & Gewogen of ongewogen \\
		\hline
		Sterke punten & Goed voor het meten van de dekking van inhoud en de algehele kwaliteit van de samenvatting & Goed voor het meten van de vloeiendheid van zinnen en de grammaticale correctheid \\
		\hline
		Zwakke punten & Kan gevoelig zijn voor verschillen in woordvolgorde en zinsstructuur tussen de gegenereerde samenvatting en de referentiesamenvatting & Vangt de semantische overeenkomst tussen de gegenereerde samenvatting en de referentiesamenvatting niet op \\
		\hline
		Gebruik & Vaak gebruikt voor samenvattingstaken & Vaak gebruikt voor machinevertalingstaken \\
		\hline
	\end{tabular}
	\caption{Comparison of ROUGE and BLEU metrics}
	\label{tab:rouge_bleu_comparison}
\end{table}


\subsubsection{Evaluatie zonder referentieteksten}

Een samengevatte tekst beoordelen zonder een referentietekst vereist volgens \textcite{Steinberger2009} meer subjectiviteit en menselijke betrokkenheid dan met een referentietekst. Deze soort kan handmatig gebeuren, maar ook semi-automatisch. De type tekst, de lengte en de complexiteit van de oorspronkelijke tekst zijn factoren die in acht moeten worden genomen bij het beoordelen van de samengevatte tekst. Daar moet er worden gekeken naar het doelpubliek en het formaat.

De tekst- en inhoudskwaliteit van de samengevatte tekst moet worden beoordeeld. De tekstkwaliteit is de grammaticale correctheid, niet-redundantie van zinnen en woordenschat en coherente structuur \autocite{McCombes2022}. De inhoudskwaliteit wijst op de informatie dat wordt opgenomen in de samengevatte tekst. Dit omvat de relevantie met de doelgroep bij kern- en bijzaken of misleidende informatie door een misinterpretatie van het systeem.


\subsection{Conclusie}

Wetenschappelijke artikelen volgen een gelijke structuur. De inhoud in PDF- of afbeeldingvorm vergt voldoende cleaning-fasen. Het beoordelen van de samenvatting op basis van een referentietekst met de ROUGE-metriek wordt aangeraden, al kan deze beoordeling niet enkel machinaal gebeuren. Daarnaast is er input en bijsturing nodig van de mens omtrent een samenvatting op maat en de grammaticale, lexicale en semantische correctheid.

% De theoretische concepten om teksten te vereenvoudigen. Teksten kunnen op vier manieren worden vereenvoudig 

\section{Valkuilen en uitdagingen voor AI-ontwikkelaars bij tekstvereenvoudiging met AI}

AI en ML zijn volop in groei. NLP gebruikt AI en ML om menselijke taal te verwerken, terwijl NLU deze technologieën gebruikt om menselijke taal te begrijpen. Hoewel deze technologieën veelbelovend zijn, moeten AI-ontwikkelaars rekening houden met veelvoorkomende en genegligeerde uitdagingen en valkuilen \autocite{Sciforce2020, Roldos2020, Khurana2022}.

\subsubsection{Uitdagingen voor softwarebedrijven}

Volgens het jaarlijks rapport van IBM behoren Natural Language toepassingen tot de duurste soort om te ontwikkelen. Ongeveer 54\% van de bevraagde IT-professionals vond de bijhorende kosten een obstakel bij het starten van de ontwikkeling voor NLP-toepassingen. Professionals halen verschillende pijlers aan, waaronder de kwaliteit en kwantiteit van de data, het trainen van de data, het gebrek van NLP-experten, de integratie en deployment van de taalmodellen en ten slotte de transparantie van het model. Gespecialiseerde modellen zijn use-case afhankelijk wat ze niet voor iedere toepassing bruikbaar maakt. Als oplossing kunnen softwarebedrijven partnerships afsluiten, investeren in NLP-talent, klein starten en stelselmatig opschalen, cloud-gebaseerde oplossingen aanreiken of de transparantie van een model benadrukken in hun specifieke toepassing \autocite{IBM2022}.

\subsection{Taalgerelateerde valkuilen}

\subsubsection{Homoniemen}

\textit{Sequence Labeling} koppelt labels aan tokens in doorlopende tekst. Homoniemen kunnen echter roet in het eten gooien. Het is voor een machine volgens \textcite{Roldos2020} moeilijk om de context van homoniemen te achterhalen. Bijvoorbeeld bij het woord ‘bank’ is het niet duidelijk voor de machine of het gaat over de geldinstelling of het meubel. \textit{Word Sense Disambiguation} of WSD is een NLP-taak waarbij de betekenis van een woord wordt bepaald. Deze bepaling gebeurt volgens \autocite{Eisenstein2019} op basis van de context waarin een woord gebruikt wordt. Deze taak is nodig binnen NLP om rekening te houden met homoniemen. WSD implementeren kan dictionary-gebaseerd, gesuperviseerde, semi-gesuperviseerd of niet-gesuperviseerd.

\subsubsection{Synoniemen}

% Daarnaast zijn synoniemen een probleem voor tekstverwerking.

% \subsection{Evaluatie van de toepassing}

\subsection{Datasets}

Het onderzoek van \textcite{Sciforce2020} haalt aan dat het merendeel van NLP-toepassingen Engelstalige invoer gebruikt. Niet-Engelstalige toepassingen zijn zeldzaam. De opkomst van AI technologieën die twee datasets gebruiken, biedt een oplossing voor dit probleem. De software vertaalt eerst de oorspronkelijke tekst naar de gewenste taal, voordat de tekst wordt herwerkt. 


% todo bron openai
% The Reddit TL;DR dataset used for training the summarization models contains offensive or biased content, which can result in biased or offensive summaries generated by the models.


% Hetzelfde onderzoek bewijst dat het vertalen van gelijkaardige talen, zoals Duits en Nederlands, een minimaal verschil opleverd.

% \subsection{Meaning distortion}



\subsection{Paternalisme}

De doelstelling van ondersteunende toepassingen is om gelijke kansen te bieden aan iedere doelgroep. Tekstvereenvoudiging voorziet een eenvoudigere syntax en woordenschat in een tekst. Volgens \textcite{Niemeijer2010} zijn de ethische overwegingen die samenhangen met tekstvereenvoudiging niet gemakkelijk te scheden van de gebruikte technologie om het resultaat te bereiken. Het onderzoek van \textcite{Gooding2022} haalt pijlers aan waarmee ontwikkelaars en softwarebedrijven rekening moeten houden bij de ontwikkeling van adaptieve en ondersteunende leessoftware, voornamelijk toepassingen voor tekstvereenvoudiging. Ontwikkelaars moeten zich meer bewust worden van de behoeften en verwachtingen van de eindgebruiker bij het ontwikkelen van een tekstvereenvoudigingstoepassing. Haar onderzoek benadrukt de paternalistische of afhankelijke aard van assisterende toepassingen. Tekstvereenvoudiging omvat vier transformaties, maar niet iedere transformatie is vereist voor iedere gebruiker. Een adaptieve tekstvereenvoudigingstoepassing moet de eindgebruiker een keuze aanbieden om aan te passen wat vereenvoudigd wordt, afhankelijk van specifieke behoeften.

% Xu bron

Software-ontwikkelaars verkiezen volgens \textcite{Punardeep2020} voor \textit{black-box} modellen bij de ontwikkeling en finetuning van een NLP-toepassing met AI. Al is het verschil qua nauwkeurigheid minimaal, de afweging wordt gemaakt bij de transparantie van het model. Na een transformatie wordt er niet aangegeven waarom specifieke transformaties werden uitgevoerd, bijvoorbeeld het vervangen van een woord door een eenvoudiger synoniem. \textcite{Xu2015} benadrukt dat toepassingen voor tekstvereenvoudiging meer rekening moeten houden met de doelgroep waarvoor ze worden ontwikkeld.

White-box modellen zijn er in schaarse hoeveelheden. 

% https://hdsr.mitpress.mit.edu/pub/f9kuryi8/release/8 --> benadruk gevaar van black-box modellen

\subsubsection{Oplossing}

Om dit probleem op te lossen, is het belangrijk om de eindgebruiker, in dit geval scholieren met dyslexie in het derde graad middelbaar onderwijs, de keuze te geven. Zoals beschreven in \textcite{Gooding2022}, zijn er verschillende mogelijkheden. Bijvoorbeeld, de eindgebruiker moet de mogelijkheid hebben om te kiezen welke synoniemen de tekst lexicaal zullen aanpassen. Een alternatieve aanpak voor syntactische vereenvoudiging is om de scholier zelf zinnen te laten markeren die moeilijk te begrijpen zijn, zodat het systeem alleen de door de eindgebruiker aangegeven zinnen vereenvoudigt.

\subsection{Evaluatie en interpretatie}

\subsubsection{Alignment problem}

Machines 

% To safely deploy powerful, general-purpose artificial intelligence in the future, we need to ensure that machine learning models act in accordance with human intentions. This challenge has become known as the alignment problem. A scalable solution to the alignment problem needs to work on tasks where model outputs are difficult or time-consuming for humans to evaluate. To test scalable alignment techniques, we trained a model to summarize entire books, as shown in the following samples. These samples were selected from works in the public domain, and are part of GPT-3′s pretraining data. To control for this effect, and purely for research purposes, our paper evaluates summaries of books the model has never seen before. Our model works by first summarizing small sections of a book, then summarizing those summaries into a higher-level summary, and so on.

\subsubsection{Menselijke feedback bij reinforcement learning}

De beste samengevatte versie van een tekst achterhalen met menselijke feedback vergt de juiste methode. De doelgroep waarvoor een tekst wordt samengevat, moeten nauw in het proces worden opgenomen.

% \subsubsection{Betrouwbaarheid van automatische metrieken voor precision en recall}


\section{Beschikbare software voor tekstvereenvoudiging}

% inleiding voor welke software
Dyslexie is een veelvoorkomende aandoening die de lees- en schrijfvaardigheden van scholieren kan belemmeren. Om deze scholieren te ondersteunen, worden er verschillende softwareprogramma's en tools ontwikkeld. In dit hoofdstuk zal worden gekeken naar mogelijke nationale en internationale software die specifiek is ontworpen om scholieren met dyslexie te helpen bij het lezen van teksten. Er zal met name worden gekeken naar de beschikbare software in Vlaamse middelbare scholen, chatbots, zoals Bing AI en ChatGPT, en software die speciaal is ontwikkeld om dyslexie te ondersteunen bij het lezen.

\subsection{Momenteel ingezet in het onderwijs}

In het middelbaar onderwijs wordt lees- en studieondersteuning voor scholieren met dyslexie enkel in de vorm van voorleessoftware voorzien \autocite{DeCraemer2018, OnderwijsVlaanderen2023}. \textcite{OnderwijsVlaanderen2023} leent licenties voor de volgende softwarepakketten uit:

\begin{itemize}
	\item SprintPlus
	\item Kurzweil3000
	\item Alinea Suite
	\item IntoWords
	\item TextAid
\end{itemize}

Naast luister- en schrijfopties kunnen scholieren deze toepassingen gebruiken om zinnen te markeren om deze zinnen vervolgens samen te vatten. Enkel de gemarkeerde zinnen worden betrokken in de samengevatte versie, dus de zinnen blijven lexicaal, syntactisch en semantisch identiek. Alle vermelde softwarepakketten bieden echter geen onafhankelijke samenvat- of vereenvoudigfunctie aan.

% todo eventueel een tabel

\subsection{Proof-of-concepts en online webapplicaties}

Online zijn er tools beschikbaar om teksten generiek samen te vatten. Resoomer, Paraphraser en Scholarcy zijn oorspronkelijk Engelstalige tools, met ondertussen de mogelijkheid om een abstractieve samenvatting te maken van Nederlandstalige teksten. De taalmodellen waar deze applicaties op werken, is niet gekend. Daarnaast zijn er ook geen API's beschikbaar om mee te werken. Gepersonaliseerde toepassingen zijn er in mindere mate. \textcite{Bingel2018} omschrijft een proof-of-concept voor een webtoepassing dat teksten vereenvoudigd, met oog op mensen met dyslexie. Deze software noemt nu Hero en bevindt zich in betafase.

% De assumptie is dat dit gericht kan zijn op de Nederlandse taal, of een anderstalig model en nadien vertaald naar het Nederlands.

Toepassingen om wetenschappelijke artikelen te vereenvoudigen zijn schaars, maar er zijn enkele gratis en betalende toepassingen beschikbaar. SciSpace\footnote{https://typeset.io/} is gratis. Scholarcy\footnote{https://www.scholarcy.com/?ref=theresanaiforthat} is betalend. 

\begin{figure}
	\includegraphics{img/typeset-example.png}
	\caption{Schermafbeelding van SciSpace.}
\end{figure}}

\subsection{GPT-3}

% uitleg over gpt
\textit{Generative Pretrained Transformer 3} of GPT-3 is een taalmodel ontworpen door OpenAI. Het model is getraind op niet-gecategoriseerde data van het internet en is gebaseerd op datasets zoals Common Crawl, WebText2, Books1, Books2, and Wikipedia. Dit taalmodel steunt op \textit{Reinforcement Learning from Human Feedback} of RLHF. 

\begin{figure}[H]
	\includegraphics[width=10cm]{img/chatgpt-example-simplification-gooding.png}
	\caption{Afbeelding van Gooding 2022. De invoertekst is een paragraaf uit een niet-vermeld boek van de Russische schrijver Dostoevsky. Het resultaat van de meegegeven prompt is een transformatie dat iedere vorm van vooraf aangehaalde vereenvoudiging weergeeft. Lexicale, conceptuele en syntactische vereeenvoudiging worden op de invoertekst toegepast.}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=10cm]{img/chatgpt-example-different-versions-gooding.png}
	\caption{Afbeelding van Gooding 2022. Gooding haalt verder aan dat modellen zoals ChatGPT op twee vlakken de leesbaarheid van een tekst kan bevorderen. Allereerst door het verlenen van verschillende mogelijke versies van een vereenvoudigingstaak.}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=10cm]{img/chatgpt-example-evaluation-gooding.png}
	\caption{Afbeelding van Gooding 2022. Gooding haalt aan dat %todo!!
	}
\end{figure}

\textcite{Lisowski2023} vergelijkt de twee OpenAI taalmodellen met een \textit{mixed-methods} onderzoek. Al blijken de twee heel gelijkaardig, het experiment benadrukt dat het ChatGPT-model een conversationeel model is, terwijl GPT-3 een ML-model is bedoeld om met hoogstens één prompt te werken. De grootte van het GPT-3 model met 175 miljard parameters imposanter dan Chat-GPT. Daarnaast is de limiet bij het meest recente GPT-3 model is 4000 tokens. Verder haalt Lisowski aan dat de kwaliteit bij beide modellen sterk afhankelijk is van de invoer. De prompts moeten concreet genoeg zijn, om zo niet af te wijken van wat de gebruiker wilt.

\subsubsection{Beschikbare GPT-3 engines}

De documentatie van OpenAI\footnote{https://platform.openai.com/docs/} reikt vier verschillende engines voor het GPT-3 taalmodel aan, namelijk Davinci, Curie, Babbage en Ada.

% (...) raadt aan om Davinci voor Ada daarentegen bevat minder recente data, maar is geschikt voor kleinere taaltaken. De andere modellen zijn echter cost-effective en sneller. 

% https://platform.openai.com/docs/models/finding-the-right-model

\begin{itemize}
	\item Davinci-003 is het meest recente model en is in staat om alles te doen wat de andere engines in staat zijn. Het model maakt gebruik van text de invoertekst eventueel kan aanvullen, mocht de invoertekst afgebroken zijn. Deze aanvulling kan in vraag worden gesteld. Aanvullend geeft aan dat deze engine de meest menselijke antwoorden geeft op basis van foutenmarge. De andere engines kwamen niet in de buurt. \textcite{Binz2023} vult aan dat deze engine de meest \textit{menselijke} antwoorden teruggeeft. Daarom is deze engine geschikt voor taken zoals essays schrijven, vragen beantwoorden of code genereren.
	\item Curie is in staat om zinnen met nuance te verwerken, maar maakt een grote sprong terug qua menselijke interpretatie vergeleken met Davinci. Deze engine wordt ingezet voor taken zoals tekstclassificatie, samenvatting of vertaling.
	\item Ada is niet in staat om zinnen met nuance te verwerken. Deze engine wordt aangeraden voor taken zoals het aanvullen van tekst of het aanmaken van labels.
	\item Babbage is de minst krachtige en kan ook geen zinnen met nuance verwerken, maar het is de snelste engine. Deze engine toekennen aan eenvoudige taken zoals sentiment analyse of het achterhalen van keywords is volgens de documentatie \textit{best practice}.
\end{itemize} 

\begin{figure}
	\begin{center}
		\includegraphics{img/chatgpt-engines-mean-regret.png}
		\caption{Afbeelding van \textcite{Binz2023}. Dit toont de \textit{mean regret} aan tussen de vier engines en de menselijke antwoorden.}
	\end{center}
\end{figure}

\subsubsection{Tools met GPT-3}

\textcite{Mottesi2023} haalt lees- en schrijftools aan die gebruik maken van de GPT-3 API. Jasper AI is een chatbot bestemd voor customer support en een virtueel assistent voor e-commerce. ChatSonic is een tool gericht om social media posts of nieuwsartikelen te generere op basis van een kernzin of kernwoord. 

Verschillende artikels vermelden de mogelijkheden voor het gebruik van GPT-3 en ChatGPT in het onderwijs. \textcite{Roose2023} haalt zo de hoge toegankelijkheid, engagement bij scholieren en granulaire personalisatie aan dat het GPT-3 model toe in staat is. \textcite{Garg2022} ziet in GPT-3 en ChatGPT een portaalfunctie, om scholieren te helpen bij het opzoeken van nieuwe informatie tijdens de les en bij het instuderen.

\subsubsection{Vergelijking met andere taalmodellen}

De architectuur tussen GPT-3 en BERT is volgens \textcite{Mottesi2023} het meest opvallende verschil. GPT-3 is een autoregressief model en houdt daarmee enkel rekening met de linkercontext bij het voorspellen of genereren van tekst. BERT daarentegen is bidirectioneel en neemt zowel de linker- als de rechtercontext in overweging. De bidirectionele werking is geschikt voor sentimentanalyse waarbij begrip van de volledige zincontext noodzakelijk is. GPT-3 heeft toegang tot meer informatie (45TB) dan BERT (3TB), wat het een voordeel kan geven bij het samenvatten of het vertalen. Ten slotte zijn er ook verschillen in grootte. Hoewel beide modellen erg groot zijn, GPT-3 is aanzienlijk groter dan de voorganger vanwege de uitgebreide trainingsdatasetgrootte \autocite{Brown2020}.


\begin{figure}[H]
	\includegraphics{img/graph-language-models.png}
	\caption{Afbeelding van \textcite{Simon2021}. De evolutie van pre-trained taalmodellen wordt hier weergegeven tot eind 2022. De performantie van de modellen ten opzichte van de grootte volgt een lineaire functie.}
\end{figure}

% todo Uit General Language Understanding Evaluation (GLUE) benchmarks van (..) werden GPT-3 en verwante BERT-modellen tegen elkaar gestaafd. 

\textcite{Li2022} benadrukt dat GPT-3 voor simpele taken \textit{overkill} is. Taken buiten het genereren van teksten, zoals sentimentanalyse en -classificatie, worden beter met een kleiner taalmodel zoals BERT en aanverwante BERT-zijtakmodellen uitgevoerd. Dit heeft ook een invloed op budget, want GPT-3 is een API waar per token wordt betaald, terwijl BERT gratis en open-source is. \textcite{Strubell2019, Simon2021} haalt de ecologische effecten aan van ontwikkelaars die te snel voor deze modellen grijpen. Er is een bewezen effect kleinere modellen, gebruik van Cloud-infrastructuur en ten slotte een geschikte model finetuning bijdragen tot efficiëntere alsook minder klimaatbelastende effect.


\subsubsection{GPT-3 voor samenvattingen}

% datamodellen -- da vinci

% news summarization \textcite{Goyal2022}

% https://openai.com/research/learning-to-summarize-with-human-feedback

Onderzoek naar OpenAI's ChatGPT en GPT-3 modellen bevindt zich in een vrij vroeg stadium, al zijn er wel enkele vergelijkende onderzoeken die de kracht en zwaktes van deze technologieën aantonen. Het experiment van \textcite{Goyal2022} achterhaalt het gebruik van \textit{zero-shot} samenvattingen buiten generieke samenvattingen. Het onderzoek staat stil bij de impact van prompt-gebaseerde modellen voor het automatisch samenvatten van nieuwsartikelen. Daarnaast maakte het onderzoek gebruik van text-davinci-002 als case study. Uit het experiment besluiten de onderzoekers dat \textit{zero-shot} samenvattingen met GPT-3 beter presteren dan \textit{fine-tuned} modellen, en dat bestaande automatische metrieken zoals BLEU, ROUGE en BERTScore niet geschikt zijn om \textit{zero-shot} samenvattingen te beoordelen. Verder blijkt dat zero-shot samenvattingen meer coherentie en relevantie hebben voor trefwoord-gebaseerde samenvattingen, terwijl aspect-gebaseerde samenvattingen nog vaak blijven te falen.

% https://ai.stackexchange.com/questions/32477/what-is-the-temperature-in-the-gpt-models

\subsubsection{GPT-3 finetuning}

\begin{tabular}{|c|p{7cm}|p{5cm}|}
	\hline
	Parameter & Omschrijving & Mogelijke waarden \\
	\hline
	model & Het GPT-3 model om te gebruiken & davinci, curie, babbage, ada, text-davinci-002, text-curie-001, text-babbage-001, text-ada-001, davinci-codex \\
	\hline
	temperature & De gulzigheid van een generatief model. Een lagere waarde zal conservatieve en voorspelbare tekst teruggeven. Hogere waarden zullen meer gevarieerde en onverwachtse tekst teruggeven, wat beter werkt bij creatieve toepassingen. & Een kommagetal tussen 0 en 1. \\
	\hline
	max\_tokens & Het maximaal aantal tokens (woorden of subwoorden) dat het generatief model kan teruggeven. & Een getal tussen 1 and 2048. \\
	\hline
	top\_p & Vergelijkbaar met temperature, maar deze waarde onderhoudt de probability distribution voor common tokens. Hoe lager de waarde, hoe waarschijnlijker de woordenschat dat het model zal overwegen bij het genereren van tekst. Een hoge waarde is toepasselijker wanneer een toepassing gericht is op nauwkeurigheid en correctheid. & Een kommagetal tussen 0 en 1. \\
	\hline
	stop & Een tekstwaarde (woord/symbool) tot waar het model zal genereren. When the model generates a string that matches any of the specified strings, it stops generating text. & Een lijst van string-waarden, of een enkele string. \\
	\hline
	presence\_penalty & Factor die bepaalt hoe regelmatig woorden voorkomen. & Een kommagetal tussen 0 en 1 \\
	\hline
\end{tabular}

\subsection{Bing AI}

Microsoft en OpenAI werken nauw samen. Zo maakt het conversationele taalmodel van Bing ook gebruik van GPT-3. Deze chatbot bouwt verder en biedt zo verwijzingen en referenties aan naar andere websites. Deze verwijzingen zijn volgens mogelijk door de Prometheus-technologie van Microsoft \autocite{Ribas2023}.

Prometheus is een eigen technologie die door Bing is ontwikkeld. Het AI-model is volgens \textcite{Ribas2023} de eerste van zijn soort die de Bing-index-, ranking- en antwoordresultaten combineert met het redeneervermogen van OpenAI’s GPT-modellen. Prometheus maakt gebruik van de kracht van Bing en GPT om iteratief via een component genaamd \textit{Bing Orchestrator} een set interne queries te genereren met als doel binnen gegeven gesprekscontext een nauwkeurig antwoord op gebruikersqueries te bieden \autocite{Ribas2023}.

\begin{figure}[H]
	\includegraphics[width=6cm]{img/bing-ai-prometheus.png}
	\caption{Afbeelding van \textcite{Ribas2023}.}
\end{figure}

Bing AI is nu in testfase met wachtlijst en bestaat in de vorm van een webpagina en een browserextensie voor Microsoft Edge. Onderzoek naar deze chatbot staat nog in de kinderschoenen en er is nood aan onderzoek naar de credibiliteit en correctheid van de verwijzingen. Deze chatbot gebruikt een combinatie van extractieve en abstractieve samenvattingen. In tegenstelling tot GPT-3 is er geen officiële API beschikbaar. Daarnaast is de limiet ook lager met 2000 tokens per bericht tijdens een conversatie. 

\begin{figure}[H]
	\includegraphics{img/bing-ai-chatbot-example.png}
	\caption{In deze afbeelding wordt er een online wetenschappelijk artikel meegegeven. Er wordt geen titel of onderwerp meegegeven, maar de Bing AI chatbot is in staat om een abstractieve samenvatting te maken van het artikel. Daarna geeft de chatbot verder uitleg over een bepaald onderwerp en geeft het extra referenties mee.}
\end{figure}


\subsection{Meta LLaMa}

Ten slotte is \textit{\textit{Large Language Model Meta AI}} of LLaMa) van Meta een generatief taalmodel in dezelfde lijn als de vooraf vermelde taalmodellen. Meta omschrijft LLaMa als een "kleiner foundation model". Het doel van Meta is om een even groot taalmodel als GPT-3 te lanceren met minder rekenkracht en nodige middelen. Dit taalmodel staat in de kinderschoenen en is nog niet beschikbaar in de vorm van online webtoepassing of online API \autocite{Hern2023, Touvron2023}. LLaMa toont potentieel, want bij het experiment van \textcite{Touvron2023} is LLaMa sterker dan GPT-3 en soortgenoten, terwijl het van tien keer minder parameters gebruik maakt.

\subsection{Samenvattend schema AI NLP-modellen}

\subsection{Conclusie}

Experten halen het GPT-3 model en ChatGPT aan als de toekomst voor gepersonaliseerde en adaptieve uitleg aan scholieren. Bing AI biedt een extra dat revolutionair kan zijn bij het opzoeken van uitleg voor zoektermen, zonder het verlies aan bronvermelding. Huidige toepassingen staan mogelijks in een spreekwoordelijke schaduw eenmaal leessoftware voor scholieren met dyslexie worden ontwikkeld met AI. De mogelijkheden van GPT-3 zijn eindeloos en toepassingen die hiervan gebruik maken, kunnen in het onderwijs ingezet worden als ondersteunende software.

\section{Conclusie}



% welk soort samenvatting? -- waarom
% welke soorten vereenvouding? -- waarom
% wat moet een applicatie zeker hebben om scholieren met dyslexie te ondersteunen?
% brengt GPT-3 hier een meerwaarde? -- hoe inzetten?