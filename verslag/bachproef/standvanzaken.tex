\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}%
\label{ch:stand-van-zaken}


\section{Onderzoeken rond dyslexie}

In het volgende deel staat het onderzoek stil bij de 

\subsection{Problemen bij taal}

% inleiding rond taal
% hoe zit taal in mekaar

Taal speelt een prominente rol om dyslexie beter te begrijpen. In \textcite{Avontuur2015} worden getuigenissen van taalproblemen bij fonologie, morfologie, zinsbouw en semantiek aangehaald:

\begin{quote}
	André, een man van 45 jaar met een managementfunctie, betrapt zichzelf erop dat hij 'zijn' kan schrijven in plaats van zien en 'fliegende' in plaats van vliegende.
\end{quote}

\begin{quote}
	Koen, een jongeman van 20 jaar, heeft veel moeite met samengestelde woorden. Hij schrijft ze veelal los, bijvoorbeeld 'zee spiegel', 'uit wisseling', 'oogst maand'. Hij heeft dit zelf niet in de gaten. Voor hem zijn het twee aparte woorden.
\end{quote}

\begin{quote}
	Marc, een universitair student, mailt naar een vriend: 'Ik kan het weekend van de 20e september zou kunnen' en 'Ik mag vanaf heden ben ik bachelor of science.' Dit soort dingen schrijft hij herhaaldelijk, vertelt hij, en hij ziet het zelf niet, vult hij enigszins gefrustreerd aan. Hij geeft aan dat het eenvoudige zinnetjes zijn en zelfs die schrijft hij fout.
\end{quote}

\begin{quote}
	Myrthe studeert rechten. In werkcolleges kan ze goed meedoen en geeft ze blijk van voldoende kennis. Ze moet zich echter bovenmatig inspannen om de lesstof in de studieboeken te lezen en te verwerken. Het kost haar veel tijd en ze krijgt er hoofdpijn van.
\end{quote}

\subsection{Centrale blik op de doelgroep}

\subsubsection{Statistieken rond prevalentie en comorbiditeit}

Vlaamse en Nederlandse onderzoeken zoals \textcite{Wentink2008, Desoete2017} wijzen uit dat gemiddeld 4\% van de Nederlandstalige bevolking de diagnose van dyslexie heeft. De prevalentie van dyslexie is taalafhankelijk. Zo is volgens DSM-5 het percentage met mensen met dyslexie in China slechts circa 1\% van de bevolking, terwijl het cijfer bij het Engels, een opake taal\footnote{Talen met inconsistente klank-tekenkoppelingen. Voorbeeld \textit{height} en \textit{weight}.}, drastisch hoger wordt geschat op ongeveer 15\% van de Engelstalige bevolking. Het aantal scholieren met dyslexie wereldwijd in het lager en middelbaar onderwijs wordt ingeschat op 5 tot 10\% \autocite{Bonte2020}. Verder wijst \textcite{Desoete2015} aan dat de prevalentie van gecombineerde reken- en leesstoornissen hoog ligt, geschat op een 25 tot 50\%. De prevalentie van het voorkomen van spraak- en taalstoornissen ligt volgens \textcite{Dirks2008, Desoete2017} op 50 tot 80\%. 

\subsubsection{Scholieren met dyslexie in het derde graad middelbaar onderwijs}

Mensen met dyslexie ondervinden een last bij het technisch lezen van een tekst. Al zijn er onderzoeken naar de doelgroep van jongvolwassenen en volwassenen met dyslexie, de meeste onderzoeken rond dyslexie centreren zich op kinderen in het kleuter- en basisonderwijs. Volgens \textcite{Bonte2020} is dit zo omdat de diagnose zo vroeg mogelijk moet worden vastgelegd, dus in de kleuter- of kinderfase. Deze diagnose zo vroeg mogelijk vastleggen vereist voldoende onderzoek. Volgens \textcite{Lissens2020} zijn jongvolwassenen en ouderen een leeftijdsgroep die bij onderzoeken rond dyslexie over het hoofd word gezien.

Het onderzoek van \textcite{Lissens2020} benadrukt deze vaak over het hoofd geziene doelgroep. Mensen met dyslexie ervaren uitdagingen bij het lezen en schrijven. Op sociaal vlak worden deze mensen niet begrepen door anderen, omdat ze woorden vaak verkeerd uitspreken of verkeerd spellen. Het tempo van anderen bijhouden verloopt stroef en het verwerken van teksten vereist meer energie. Ondanks het vele oefenen blijft snel en veel lezen moeilijk. Het toepassen van spellingsregels hindert mensen met dyslexie, wat vaak leidt tot een gevoel van onzekerheid en angst om fouten te maken. Dit kan leiden tot frustratie en stress, waardoor het voor mensen met dyslexie moeilijker wordt om hun vaardigheden te verbeteren. Toch motiveren onderzoeken zoals \textcite{Ghesquiere2018, Lissens2020, Bonte2020} deze doelgroep door het sterk doorzettingsvermogen te benadrukken. Dit helpt hen om te blijven oefenen en hun vaardigheden te ontwikkelen, ondanks de uitdagingen.

\subsection{Diagnosecriteria}

Dyslexie is geen lijst van 'kwalen' waaraan een scholier moet voldoen om dit te bezitten. Zo halen \textcite{Kleijnen2008, Ghesquiere2018} samen drie criteria aan waarmee de diagnose van dyslexie wordt vastgesteld.

\begin{itemize}
	\item Het \textbf{achterstandscriterium} wijst aan dat er een ernstige lees- of spellingsachterstand is. 
	\item Het \textbf{hardnekkigheidscriterium} houdt in dat de lees- of spellingsachterstand het gevolg is van een moeizame automatisering van het lees- en spellingsproces. De leessnelheid vertraagt, terwijl het aantal lees- of spellingsfouten verhoogt terwijl een scholier complexe taken uitvoert.
	\item Het \textbf{exclusiviteitscriterium} volgens \textcite{Ghesquiere2018} wijst erop dat lees- en spellingsstoornissen niet volledig verklaard worden door andere condities, zoals verstandelijke beperkingen, emotionele moeilijkheden of zintuiglijke beperkingen.
\end{itemize}

Het exclusiviteitscriterium benadrukt dat alle noden en obstakels van mensen met dyslexie verschillend zijn. Zo halen \textcite{VanVreckem2015, Ghesquiere2018} de volgende kenmerken aan die kunnen verschillen per individu.

\begin{itemize}
	\item De ernst of uitgebreidheid van een stoornis.
	\item De gevolgen van een stoornis, zoals faalangst.
	\item De mate waarin iemand al dan niet kan compenseren.
	\item De secundaire kenmerken zoals problemen met werkhouden en structuur.
\end{itemize}

\subsection{Groepsprofiel}

% todo opnieuw!!

\textcite{VanVreckem2015} onderzocht of kinderen met dyslexie als groep al dan niet problemen hebben met begrijpend lezen. Het onderzoek achterhaalt of het groepsprofiel overeenkomt met de individuele profielen bij begrijpend lezen en spelling. De onderzoeksresultaten bij een experiment met zeventien kinderen wijst uit dat er een geïndividualiseerde analyse en effectieve behandeling op maat nodig is bij begrijpend lezen. Onvoldoende beheerste leerstof en leesstrategieën per kind moet achterhaald worden om zo specifieke begeleiding te kunnen bieden. Verder wijst het onderzoek uit dat kinderen met dyslexie meer problemen hebben bij het spellen van pseudowoorden. Er werden geen significante verschillen geconstateerd bij comorbide stoornissen.

\subsection{Aandachtspunten}

Bij het ontwikkelen van een toepassing voor scholieren met dyslexie moeten onderzoekers volgens \textcite{VanVreckem2015} rekening houden met de volgende punten:

\begin{itemize}
	\item Individuele analyse: Dyslexie kan zich op verschillende manieren uiten bij verschillende kinderen. Een app moet worden ontworpen met een individuele analyse van de specifieke behoeften en uitdagingen van elke leerling in gedachten.
	\item Instructies in de applicatie moeten op een begrijpelijke en geïndividualiseerde manier worden gepresenteerd om de leerlingen te helpen bij het begrijpen en toepassen van de informatie.
	\item Categorisatie van inferenties: Om de leerlingen te helpen bij het leggen van relaties in een volledige tekst, moet de app de verschillende soorten inferenties zoals causale, logische en anaforische inferenties, benadrukken.
	\item Spellingsachterstand. Een toepassing moet zich specifiek richten op het verbeteren van de spellingvaardigheden van de leerlingen, omdat dit vaak een van de grootste uitdagingen is voor kinderen met dyslexie.
	\item Diversiteit van dyslexie: Het is belangrijk om te erkennen dat dyslexie zich bij verschillende kinderen op verschillende manieren kan uiten. Een bijkomende stoornis heeft bijvoorbeeld geen impact op de spellingprestaties van een kind. Het is daarom belangrijk om de app te ontwerpen met de diversiteit van dyslexie in gedachten.
\end{itemize}

\subsection{Leesproblemen}

\textcite{Filipak2020} haalt zes leesproblemen aan die kunnen voorkomen bij een scholier met dyslexie in het middelbaar onderwijs.

\begin{itemize}
	\item Langzame woordbenoeming
	\item Begripsproblemen
	\item Hardnekkig letter-voor-letter lezen
	\item Woordherkenning
	\item Visuele disfunctie
	\item Letter- en klankvorming
\end{itemize}

\subsubsection{Langzame woordbenoeming}

Het correct spellen van pseudowoorden en regelmatig gespelde woorden is mogelijk met beheerste letterklankkoppelingen. Echter verloopt het automatiseren van moeilijke en nieuwe woorden stroef, met een trage woordbenoeming tot gevolg. Lezers kunnen met dit leesprobleem veel woorden niet als één geheel herkennen. \textcite{Filipak2020} raadt aan om pseudowoorden en het identificeren te oefenen als mogelijke hulp. De meeste schrijffouten komen voor in onregelmatig gespelde woorden waardoor een fonologische route die wel takt is, leidt tot het schrijven van \textit{gedaan} als \textit{guhdaan}.

% todo oplossing

\subsubsection{Begripsproblemen}

Typerende symptomen van \textit{Deep Dyslexia} is de verstoring van leesbegrip en het spreken in qua betekenis onbedoelde klanken, woorden en woordgroepen (parphasias). Bij \textit{deep dyslexia} kan bos bijvoorbeeld gelezen worden als boom. Begripsproblemen bij het lezen kunnen goed visueel, met steun van film en afbeeldingen ondersteund worden, beter dan alleen via gedrukte woorden. Daarbij moet de lezer die het gedrukte woord wil ontcijferen, gebruik kunnen maken van bronnen van kennis op een hoger niveau: een grote woordenschat en een goed redeneervermogen. Schriftelijke expressie is uit den boze.

\subsubsection{Hardnekkig letter-voor-letter lezen}

\textcite{Bonte2020} haalt een minder optimale informatieverwerking in visuele gebieden aan bij scholieren met dyslexie. Die zijn belangrijk voor letter- en woordherkenning. Dit is een gevolg van een minder optimale leesontwikkeling. Het visuele proces vindt plaats in de 'letterbox'\footnote{Het primaire visuele cortex van het brein}. Lezers zijn niet in staat woorden goed te lezen, zelfs niet met een langzame en spellende letter-klankroute. Lange woorden worden moeizaam gelezen en scholieren hebben de neiging om visueel gedesoriënteerde te raken. Er is verwarring over de richting van de letters.

\textcite{Rello2013} voerde onderzoek uit naar het gebruik van korte woorden bij mensen met dyslexie.

\subsubsection{Woordherkenning}

% todo welke onderzoeken?

% Onderzoeken zoals waarbij de oogbewegingen van lezers worden gevolgd tonen aan dat een geoefende lezer bij vijftig tot tachtig procent van de woorden pauzeert. Een persoon moet zich op woorden fixeren om ze te kunnen zien en dat gaat heel snel. Gedurende deze zogenoemde saccade, een snelle beweging van de ogen die tot doel heeft een nieuw fixatiepunt te vinden, wordt het woordbeeld van de vorige woordfixatie onderdrukt, voordat een volgende woord wordt gefixeerd. 



% Leesonderzoekers de Universiteit van Tel Aviv in Israël vonden in 2010 bijvoorbeeld een soort leesprobleem dat men ‘aandachts-dyslexie’ noemde, waarin kinderen letters correct identificeren, maar tijdens het lezen last hebben van verspringende letters tussen de woorden in de zinnen. Dit is minder bij het lezen van woorden in lijsten dan met woorden in lopende tekst. Denk aan het verschil in leesprestaties op de Drie-Minuten-Test (losse woorden lezen) en op de AVI-toets (tekstlezen). 

% TODO Oogfixatie
% https://www.sciencedirect.com/science/article/pii/S0042698905004864
% An experimental eye-tracking study of text adaptation for readers with dyslexia: effects of visual support and word frequency
% Investigating Efects of Typographic Variables on Webpage Reading Through Eye Movements

\textit{Top-down attention and serial reading}. In een WISC-afname kan blijken dat de organisatie van de ruimtelijke waarneming redelijk is, maar dat een leerling zwakker is met doolhoven, plaatjes ordenen, onvolledige tekeningen, substitutie-taken en vooral met symboolverwerking. Dan kan er sprake zijn van een visueel en/of neuropsychologische dysfunctie dat ten grondslag ligt aan de moeite met lezen. Dan gaat het dus , nogmaals, niet om een fonologische dysfunctie.

\subsubsection{Visuele disfunctie}


\subsubsection{Letter- en klankverwarring}
Verder gaat het om de verwisseling van de lettervolgorde, om letterweglatingen, letter-toevoegingen, letter-vervangingen, en het onherkenbaar verminken van woorden in dictees. En ook om de moeite met auditieve analyse en synthese. Veel kinderen kunnen deze leesfouten maken en dat is dan niet meteen fonologische dyslexie.

\subsection{Bewezen voordelen van tekstvereenvoudiging bij scholieren met dyslexie}

\subsubsection{Kortere fixatietijd}

Het experiment van \textcite{Rello2013} wijst uit dat de fixatietijd bij mensen met dyslexie drastisch vermindert bij een frequent woordgebruik. Bij deelnemers met dyslexie waren de fixatietijden significant korter bij het gebruik van frequente woordenschat. De fixatietijd bij woordenschat met een minder aantal voorkomens lag hoger. Bij deelnemers zonder dyslexie was het verschil amper merkbaar.

\begin{figure}
	\includegraphics[width=\linewidth]{img/readability-mean-fixation-duration.png}
	\caption{Afbeelding van \textcite{Rello2013}. Langs de richting van de pijl wordt de ideale situatie benaderdf, gekenmerkt door doelwaarden die worden bereikt door mensen zonder dyslexie onder optimale omstandigheden. Het gebruik van meer frequente woorden vermindert de fixatietijd en verbetert de leesbaarheid voor mensen met dyslexie.}
\end{figure}


% todo bronnen:

% \textcite{Rosetti2022}

\section{Wetenschappelijke artikelen}

\subsection{Wetenschappelijke geletterdheid in Vlaanderen}

De \textit{Programme for International Student Assessment} of PISA-test\footnote{https://www.pisa.ugent.be/resultaten/pisa-2022} van OESO is een driejaarlijkse test bij vijftienjarigen. Deze test bestudeert de wiskundige en wetenschappelijke geletterdheid\footnote{“Het beheersen van vaardigheden om als kritische burger om te gaan met wetenschappelijke onderwerpen en ideeën.” volgens \textcite{DeMeyer2019}} van 15-jarigen in geïndustrialiseerde landen, wat op ongeveer 79 landen komt. 4822 Vlaamse scholieren van vijftien jaar namen deel aan deze test. Dit onderzoek baseert op de cijfers van 2018, aangezien de testen van 2022 pas eind 2023 worden gepresenteerd. Deze testen houden echter geen rekening met leer- en leesstoornissen, waaronder dyslexie en dyscalculie. Het is echter nodig om deze cijfers mee te geven, om een idee te geven waar de doelgroep staat voor de start van de derde graad middelbaar onderwijs. 

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=\linewidth]{img/oeso-graphic-pisa-trend-samenvatting.png}
	\end{center}
	\caption{Figuur van \textcite{DeMeyer2019}. Op alle PISA-domeinen scoren de Vlaamse vijftienjarigen in ASO, BSO en TSO significant slechter dan de eerste metingen. \textcite{DeMeyer2019} noemen dit een achteruitgang in alle onderwijsvormen.}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=\linewidth]{img/oeso-graphic-leesplezier.png}
	\end{center}
	\caption{Figuur van \textcite{DeMeyer2019}. Het leesplezier van Vlaamse 15-jarigen. Zij uitten zich uiterst negatief op stellingen over leesplezier. Volgens de enquète vond de helft van de scholieren begrijpend lezen enkel tijdsverlies en slechts 17\% gaf aan dat lezen één van hun favoriete hobby's is. Er is wel een significant verschil tussen de mening van jongens en meisjes, waarvan jongens negatiever antwoorden op lezen.}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=5cm]{img/oeso-graphic-wetenschappelijke-geletterdheid-2.png}
	\end{center}
	\caption{Figuur van \textcite{DeMeyer2019}. De wetenschappelijke geletterdheid bij vijftienjarigen op internationaal niveau. Vlaanderen scoort significant slechter dan acht deelnemende landen.}
\end{figure}


\subsection{Trends rond wetenschappelijke artikelen}
% inleiding over het formaat van teksten

De leesbaarheid van wetenschappelijke teksten volgt al sinds de twintigste eeuw een neergaande trend \autocite{Hayes1992}. Meerdere onderzoeken in de voorbije tien jaar trokken besluit dat de complexe woordenschat en zinsbouw simpelweg ontoegankelijk maakt \autocite{Ball2017, PlavenSigray2017, Jones2019}. 

% \textcite{Ball2017}

\textcite{PlavenSigray2017} onderzochten de verschillende trends waarom wetenschappelijke artikelen alsmaar moeilijker te lezen worden. Dit deden ze door de relatie tussen de leesbaarheid van een abstract te vergelijken met het jaar waarin het wetenschappelijk artikel werd gepubliceerd. De complexiteit van het wetenschappelijk artikel beoordelen werd gedaan met de Flesch-Reading Ease (FRE) score. Om te bevestigen dat de relatie tussen de complexiteit van een abstract overeenstemt met die van de volledige tekstinhoud, werden er vergelijkingen gemaakt met zes verschillende wetenschappelijke journalen. De onderzoekers vertrokken uit het onderzoek van \textcite{Dronberger1975}. Zij onderzochten de overeenkomsten tussen de complexiteit van een abstract en de inhoud van het artikel zelf. Die toonden aan dat een abstract complexere werd geschreven, vergeleken met de rest van een wetenschappelijk artikel.

\begin{figure}[H]
	\includegraphics[width=\linewidth]{img/fre-ndc.png}
	\caption{Afbeelding uit \textcite{PlavenSigray2017}. Links wordt de evolutie per FRE-score getoond. Hoe hoger de score, hoe hoger de gemiddelde complexiteit van een tekst. Rechts wordt de evolutie volgens de NDC-score getoond. Hoe hoger de score, hoe lager de gemiddelde complexiteit van een tekst. Het onderzoek schat dat nu een kwart van alle wetenschappelijke artikelen gebruik maken van Engels op het niveau van een masterstudent, ofwel een FRE onder nul.}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=\linewidth]{img/ndc-number-of-authors.png}
	\caption{Afbeelding uit \textcite{PlavenSigray2017}. Horizontaal worden het aantal auteurs per wetenschappelijk artikel aangeduidt. Verticaal wordt de gemiddelde NDC-score weergegeven. HOe hoger de NDC-score, hoe hoger de vereiste leesgraad om de tekst te kunnen lezen.}
\end{figure}

De moeilijke leesbaarheid van wetenschappelijke artikelen heeft volgens \textcite{PlavenSigray2017} gevolgen op twee aspecten: de toegankelijkheid en de herproduceerbaarheid.

\subsubsection{Toegankelijkheid}

Allereerst benadeelt dit de toegankelijkheid tot deze bronnen. Deze bronnen worden enkel toegankelijk tot wetenschappelijk geletterden. \textcite{Ennals2010} zegt dat wetenschap ons de nauwkeurige kennis moet geven, omdat mensen zich zorgen maken dat moderne samenlevingen minder streng worden met feitelijke waarheden en deze vervangen door \textit{post-facts} die waar lijken te klinken. Wetenschappelijke inhoud moet volgens hem zo toegankelijk mogelijk worden gemaakt, zodat een zo breed mogelijk publiek de kern begrijpt.

\subsubsection{Reproduceerbaarheid}

Meerdere onderzoeken, halen de gevolgen bij vakexperts aan. \textcite{Hartley1999} toont zo aan dat het herschrijven van abstracten juist de begrijpbaarheid van academici vergrootte. De wetenschap bouwt voort op betrouwbare ontdekkingen en het reproduceren van experimenten is een belangrijke manier voor wetenschappers om vertrouwen te krijgen in hun besluiten. De inhoud van de wetenschappelijke artikelen moeten echter gecontroleerd kunnen worden. Voor de reproduceerbaarheid van onderzoeken is het volgens \textcite{McNutt2014} belangrijk dat de methodologie en resultaten begrijpelijk zijn. Dit beperkt het aantal misopvattingen en verwarringen bij onderzoekers.

% todo FRE grens aanduiden op volgende grafieken

\subsection{Formaat}

Experimenten uit het onderzoek van \textcite{Hubbard2017} wijzen uit dat de bevraagde onderzoekers zowel de methodologie als de resultaten de twee componenten vonden die een hoge leesgraad vergden. 

\subsection{Woordenschat en vakjargon}

% \textcite{Snow2010}

\subsection{Countering}

\textcite{Pain2016} schreef, als reactie op een satirisch artikel van \textcite{Ruben2016}, een artikel dat in gesprek ging met verschillende wetenschappers om het onderwerp aan het licht te brengen. Wetenschappers gebruiken verschillende strategieën om wetenschappelijke artikelen te begrijpen. Sommigen zoeken meteen onbekende woorden op, terwijl anderen delen overslaan of extra informatiebronnen raadplegen. Het lezen van wetenschappelijke artikelen kan overweldigend zijn, vooral bij onbekende vakgebieden, lange artikelen en technisch jargon. Het is belangrijk om een balans te vinden tussen het begrijpen van de inhoud en het efficiënt gebruiken van de tijd. Sommige wetenschappers geven toe dat ze het soms gewoon opgeven als het te moeilijk wordt of als het niet relevant is voor hun onderzoek. Verder geeft \textcite{Pain2016} in haar artikel advies hoe startende lezers wetenschappelijke artikelen kunnen aanpakken.

\begin{itemize}
	\item Begin altijd met het lezen van de samenvatting en conclusie om een idee te krijgen van het doel en de uitkomst van het onderzoek.
	\item De figuren en tabellen in het artikel zijn cruciaal omdat deze een snelle en duidelijke weergave geven van de belangrijkste bevindingen.
	\item Focus op de informatie die je nodig hebt en ga vervolgens terug om de technische details te begrijpen.
	\item Let op de beperkingen en juiste interpretatie van de resultaten, en controleer of de onderzoeksvraag en -methode adequaat zijn.
	\item Controleer of de referenties relevant zijn en zoek naar andere artikelen over hetzelfde onderwerp.
	\item Overweeg welke stukken opwindend, nieuw en relevant zijn voor uw eigen onderzoeksvragen en hypotheses.
	\item Maak aantekeningen en schrijf terwijl je leest, zodat je actief betrokken bent bij het lezen van het artikel.
\end{itemize}

De bevraagde onderzoekers in het onderzoek van \textcite{Hubbard2017} haalden de volgende adviezen aan. Het lezen van wetenschappelijke artikelen vereist selectief lezen, waarbij men bepaalde delen van het artikel prioriteert, zoals het abstract. Sommige bevraagden adviseren om de methodologie te negeren, terwijl anderen aanbevelen om de belangrijkste vragen of hypothesen van het artikel te achterhalen. Het is ook belangrijk om het artikel meerdere keren te lezen, waarbij men steeds gedetailleerder leest. Het abstract en/of de discussie bepaalt of het artikel de moeite waard is om te lezen. Kritisch lezen is eveneens belangrijk, waarbij men de conclusies beoordeelt en de data interpreteert voor zichzelf. Over het algemeen haalt het onderzoek van \textcite{Hubbard2017} aan dat er geen standaard aanpak is, maar selectief, kritisch en met een specifiek doel voor ogen lezen zijn tactieken die de bevraagde onderzoekers aanbevelen.

%todo bron Leopold

\textcite{Leopold2015} voerden een experiment uit om een leerstrategie te achterhalen bij het leren van wetenschappelijke teksten. In het onderzoek testte het experiment drie leermethoden: het markeren van zinnen, \textit{concept mapping} en het visualiseren van de tekst. Dit experiment werd uitgevoerd bij 51 scholieren van gemiddeld vijftien jaar en met een licht overwegend vrouwelijk publiek. % Het experiment gaf geen inzicht over de leesbegaafdheid van een scholier.

\section{Tekstvereenvoudiging}

% inleiding

\subsection{Manuele tekstvereenvoudiging}

% todo bron toevoegen

Wetenschappelijke artikelen moeten informatie begrijpelijk weergeven voor een breed publiek, waaronder scholieren die deze artikelen voorgeschoteld krijgen. Om tekst toegankelijker te maken, kunnen leerkrachten verschillende tactieken toepassen. 

\begin{enumerate}
	\item Allereerst kan de tekst worden ingekort door meerdere keren te lezen en een samenvatting te maken met een haalbare tekstlengte voor scholieren.
	\item Daarnaast kan de woordenschat en grammatica van tevoren worden uitgelegd, belangrijke zinnen kunnen worden gemarkeerd en er kan een extra inleiding worden geschreven om de interesse van scholieren te wekken.
	\item Vervolgens kan aanschouwelijkheid worden vergroot met afbeeldingen en kunnen woorden worden aangepast aan de moeilijkheidsgraad, die kan worden gebaseerd op de leesleeftijd van de persoon waarvoor de tekst wordt vereenvoudigd.
	\item Ten vierde kan de tekst worden omgezet naar een ander formaat, zoals notes, postcards of emails, om het begrijpelijker te maken. 
	\item Ten slotte moeten verwijswoorden worden aangepast om de tekst toegankelijker te maken voor multilinguale lezers, bijvoorbeeld door eenvoudige verwijswoorden zoals 'zij' of namen te gebruiken.
\end{enumerate}    

Het is echter belangrijk om ervoor te zorgen dat de tekst niet de flow verliest door deze aanpassingen. Glossaries worden over het algemeen vermeden omdat deze nadelige effecten kunnen hebben op de leesbaarheid van de tekst, vooral voor oudere doelgroepen.


\subsubsection{Lengte en formaat}

\textcite{Rijkhoff2022} benadrukt dat het tijdsintensief is om teksten in te korten. 

% https://dialoogtrainers.nl/tekst-inkorten-tips/

\subsubsection{Woordenschat}

Moeilijke woorden kunnen op twee manieren beperkt worden. Eerst moet een tekst op maat zijn van het doelpubliek. De gehanteerde (vak)termen moeten begrijpelijk zijn voor iedereen binnen het doelpubliek. Deze leesgraad en voorkennis wisselt sterk af bij scholieren in de laatste graad middelbaar onderwijs. Als het niet mogelijk is om eenvoudigere synoniemen te gebruiken, dan komt het van pas om de woorden uit te leggen. Dit hoeft enkel te gebeuren bij de eerste keer dat deze woorden voorkomen \autocite{Bosmans2022a, Bosmans2022b}.


\subsubsection{Grammatica}
\textcite{Bosmans2022c} halen vier methoden aan om complexe constructies te vereenvoudigen.

\begin{itemize}
	\item Tangconstructies omvormen % U kunt de tangconstructie minder zwaar maken door de twee grijpers van de tang dichter bij elkaar te brengen. Als de zin erg lang is, kunt u de tang gemakkelijk wegwerken door de zin te splitsen.
	\item Onderbroken zinsstructuur % U kunt aanvullende informatie daarom beter zo kort mogelijk houden, of vooraan of achteraan in de zin zetten zodat die het geheel niet onderbreekt. U kunt er ook een aparte zin van maken. In de onderstaande voorbeelden is de aanvullende informatie gecursiveerd.
	\item Zinsaanloop verkorten % Door een lange aanloop stelt u de aandacht van uw lezer extra op de proef omdat het te lang duurt voordat hij bij de kern komt. 
	\item Voorzetselketens % U kunt voorzetselketens vermijden door de informatie over verschillende zinnen te verdelen. Voorzetseluitdrukkingen kunt u het best vervangen door gewone voorzetsels.
\end{itemize}

% https://www.vlaanderen.be/taaladvies/taaladviezen/teksten-schrijven/formulering/zinsbouw-moeilijke-constructies
% https://www.vlaanderen.be/taaladvies/taaladviezen/teksten-schrijven/formulering/afkortingen-gebruik

\subsubsection{Aanschouwelijkheid}


\subsection{Natural Language Processing}

% Eerst moet er een technologische fundering gelegd worden over de basisconcepten en verschillende soorten van tekstvereenvoudiging. 

Tekstvereenvoudiging is het proces waarin het technisch leesniveau en/of woordgebruik van een geschreven tekst wordt verminderd. Het resultaat van deze fase is een tekst die korter en aangenamer is, zonder het verlies van de kerninhoud. Het langlopende onderzoek van Advaith Siddharthan dient als vertrekpunt voor de literatuurstudie rond tekstvereenvoudiging. Binnen machinaal leren (ML) is tekstvereenvoudiging een zijtak van natuurlijke taalverwerking. Volgens \autocite{Siddharthan2014} bestaat een complete tekstvereenvoudiging uit vier transformaties. % Daarnaast is tekstvereenvoudiging een taalbewerking dat geautomatiseerd kan worden.

\textit{Natural Language Processing} (NLP) of natuurlijke taalverwerking is een brede term die zich richt op het verwerken en analyseren van menselijke taal door computers en andere technologieën \autocite{Eisenstein2019}. Het omvat verschillende technieken, zoals tekstanalyse, taalherkenning en -generatie, spraakherkenning en -synthese, en semantische analyse. Computers zijn in staat om op een menselijke manier te communiceren en begrijpen wat er wordt gezegd. \textcite{Sohom2019} haalt de volgende begrippen aan.

\begin{itemize}
	\item \textbf{Tokenisatie} splitst de stam of basisvorm van woorden in een tekst. Gebruikelijk zetten ontwikkelaars deze stap in om een woordenschat voor een taalmodel op te bouwen. Bij tokenisatie wordt er geen rekening gehouden met de betekenis achter ieder woord.
	\item \textbf{Lemmatiseren} in NLP bouwt verder op \textit{stemming}, maar de betekenis van ieder woord wordt in acht genomen. Voor het lemmatiseren bestaan er Nederlandstalige modellen, waaronder JohnSnow\footnote{https://nlp.johnsnowlabs.com/2020/05/03/lemma\_nl.html}. Bij \textbf{omgekeerd lemmatiseren} wordt er een afgeleide achterhaald vanuit de stam. Bijvoorbeeld voor het werkwoord 'zijn' zou dit 'is', 'was' of 'ben' zijn. Voor zelfstandige naamwoorden, zoals 'hond', is dit dan enkelvoud of meervoud.
	\item Bij een \textbf{parsing}-fase wordt er een label aan ieder woord of zinsdeel toegekend. Voorbeelden van labels zijn zelfstandig naamwoord, bijwoord, werkwoord, bijzin of stopwoord. Het herkennen van zinsdelen wordt \textit{chunking} genoemd. Parsing heeft een dubbelzinnigheidsprobleem, want een 'plant' staat niet gelijk aan de vervoeging van werkwoord 'planten'.
	\item Sentimentanalyse is een tak onder Natural Language Understanding (NLU). % todo aanvullen
\end{itemize}

\subsubsection{Sequence Labeling}

Volgens \textcite{Eisenstein2019} is \textit{sequence labeling} essentieel tot het achterhalen van de structuur van een tekst met \textit{supervised learning}. Elk woord in een tekst of zin wordt geclassificeerd met behulp van specifieke labels, zoals bijvoorbeeld een \textit{Part of Speech} of PoS-label of een \textit{Named Entity Recognition} of NER-label. De structuur van de tekst wordt achterhaald en informatie en patronen kunnen uit de tekst worden gehaald. \textcite{Jurafsky2014} haalt PoS en NER-labeling verder aan in hun boek. Terwijl POS-tagging zich richt op grammaticale categorieën van woorden, richt NER-labeling zich op het identificeren van specifieke entiteiten in tekst. 

\begin{itemize}
	\item Bij \textbf{POS-tagging} worden de woorden in een zin geanalyseerd en krijgt elk woord een grammaticale categorie of een deel van de rede toegewezen, zoals zelfstandig naamwoord, werkwoord, bijvoeglijk naamwoord of bijwoord. POS-tagging helpt volgens \textcite{Jurafsky2014} bij het identificeren van de syntactische structuur van een zin. Dit is volgens de onderzoeker handig voor taken zoals parsing en machinevertaling. Dit wordt aanschouwelijk gemaakt op \ref{fig:pos}
	\item Aan de andere kant houdt \textbf{NER-labeling} zich bezig met het herkennen en classificeren van \textit{named entities} in een zin, zoals namen van personen, organisaties, locaties, data, enzovoort. NER-labeling wordt volgens \textcite{Jurafsky2014} gebruikt om specifieke informatie uit tekst te halen, zoals het identificeren van de namen van personen, plaatsen of bedrijven die in nieuwsartikelen worden genoemd, of het extraheren van belangrijke data of getallen uit financiële rapporten. Dit wordt aanschouwelijk gemaakt \ref{fig:ner}. \textcite{Li2018} haalt vier technieken aan waarop NER-labeling kan gebeuren:
	\begin{itemize}
		\item \textit{Dictionary-based} systemen waarbij een dictionary een verzameling van de woordenschat bijhoudt. Hierop wordt \textit{basic string matching} toegepast.
		\item \textit{Rule-based} systemen met een vooraf gekregen verzameling van regels voor het ophalen van informatie. Het toewijzen gebeurt met patronen, of met de context van een woord.
		\item \textit{ML-based} modellen trainen eerst op geannoteerde tekstdocumenten, vervolgens gebruikt het getrainede model deze annotaties.
		\item \textit{Deep-learning} of DL-modellen mappen de invoerdata aan een niet-lineaire representatie. De complexe modellen maken het mogelijk om niet voor de hand liggende relaties uit te pluizen, wat het de sterkste van de vier opties maakt.
	\end{itemize}
	Daarnaast haalt \textcite{Li2018} modellen aan om een pipeline voor NER-labeling mogelijk te maken. Spacy heeft deze functie ingebouwd. Standford NER-tagger is een tool die samen met het NLTK-pakket werkt.
\end{itemize}

\begin{figure}
	\begin{center}
		\includegraphics[width=10cm]{img/poslabeling.png}
	\end{center}
	\caption{Voorbeeld van PoS-labeling op de Engelstalige zin "She sells seashells on the seashore". Afbeelding van \textcite{Bilisci2021} }
	\label{fig:pos}
\end{figure}

\begin{figure}
	\begin{center}
		\includegraphics[width=10cm]{img/nerlabeling.jpg}
	\end{center}
	\caption{Voorbeeld van sequence labeling op de Engelstalige zin "She sells seashells on the seashore". Afbeelding van \textcite{Bilisci2021} }
	\label{fig:ner}
\end{figure}

\section{De verschillende soorten tekstvereenvoudiging}

Tekstvereenvoudiging bestaat uit vier soorten transformaties: lexicale, syntactische en semantische vereenvoudiging en samenvatten.

\begin{figure}
	\begin{center}
			\includegraphics[width=5cm]{img/voorbeeld-manuele-vereenvoudiging.png}
	\end{center}
	\caption{Voorbeeld van manuele tekstvereenvoudiging. Oorspronkelijke tekst uit Historia 5 bron toe te voegen}
\end{figure}

Verder haalt \textcite{Dubay2004} de vier basiselementen aan die bijdragen tot een eenvoudigere tekst.

\begin{figure}
	\begin{center}
		\includegraphics[width=5cm]{img/text-simplification-reading-ease.png}
	\end{center}
	\caption{Afbeelding van \textcite{Dubay2004}}
\end{figure}

\subsection{Lexicale vereenvoudiging}

% todo bron
Bij lexicale vereenvoudiging worden complexe woorden vervangen door eenvoudigere synoniemen. Bijvoorbeeld, het woord 'adhesief' kan worden vervangen door 'klevend'. De zinsstructuur verandert niet en er is garantie dat de kerninhoud en benadrukking hetzelfde blijft. Het doel van lexicale vereenvoudiging is om de moeilijkheidsgraad van de woordenschat in een zin of tekst te verlagen. Dit is, volgens het aantal onderzoeken, de meest gekende vorm van vereenvoudiging en een noodzakelijke stap bij het vereenvoudigen van een tekst. Voor prevalente domeinen, zoals de onderwijs-, medische en financiële sector, zijn er onderzoeken vrij beschikbaar. 

In de medische sector haalt \textcite{Kandula2010} twee manieren aan om lexicale vereenvoudiging mogelijk te maken, namelijk het vervangen door een synoniem en het aanmaken of genereren van extra uitleg. Zij bouwden verder op een vorig onderzoek van \textcite{Zeng2005}.

\subsubsection{Complex Word Identification}

Complex word identification of CWI is een supervised NLP-taak in een pipeline voor tekstvereenvoudiging. Moeilijke woorden of \textit{multi-word expressions} (MWE) in een tekst worden achterhaald  \autocite{Shardlow2013, Gooding2019}. Dit is volgens \textcite{Shardlow2013} een cruciale stap, want een lage recall van dit component zal een uitvoertekst geven waar moeilijke woorden niet worden vereenvoudigd.

% todo Binnen Germaanse talen zijn er verschillende datasets die zich op deze taak toespitsen. Zo is er 

% todo FrenLys

% todo \textcite{Bingel2018}

\subsection{Syntactische vereenvoudiging}

% todo bron 

Syntactische vereenvoudiging verandert de grammatica en zinsstructuur van een tekst om de complexiteit van een zin te verlagen. Twee afzonderlijke zinnen kunnen samengevoegd worden tot één eenvoudigere zin. Zo worden complexe of onduidelijke zinsconstructies verminderd, terwijl de inhoud en betekenis van de tekst behouden blijft. Dergelijke transformaties zijn het vereenvoudigen van de syntax of door de zinnen korter te maken. Zinnen worden toegankelijker, zonder de kerninhoud of relevante inhoud te verliezen.

Het onderzoek van \textcite{Kandula2010} bespreekt het vereenvoudigen van medische journalen. Zij ontwikkelden een toepassing om medische informatie te vereenvoudigen met beschikbare biomedische bronnen, door syntactische vereenvoudiging op zinniveau toe te passen. Zinnen met meer dan tien woorden worden als complex beschouwd en worden verwerkt door drie modules. Op het einde van deze vereenvoudiging kan de oorspronkelijke zin ongewijzigd worden behouden of vervangen worden door twee of meer kortere zinnen. De architectuur van het model omvat drie onderdelen: een \textit{Part of Speech (PoS) Tagger}, een \textit{Grammar Simplifier} en een \textit{Output Validator}. 

\begin{itemize}
	\item Voor de \textit{PoS Tagger}-fase gebruikten \textcite{Kandula2010} beschikbare functies uit het open-source pakket OpenNLP\footnote{https://opennlp.apache.org/}.
	\item De \textit{Grammar Simplifier} module splitst de lange zin in twee of meer kortere zinnen door POS-patronen te identificeren en een set transformatieregels toe te passen.
	\item De \textit{Output Validator} module controleert de output van de Grammar Simplifier op grammatica en leesbaarheid. Er zijn drie condities:
\end{itemize}  

% De toepassing werd getest met vier leesbaarheidsmetrieken en een "cloze"-test op verschillende soorten medische documenten, en liet verbeteringen zien in alle metingen. De verbeteringen waren echter relatief klein en er is meer uitgebreide gebruikerstesten nodig voor een betere validatie van het hulpmiddel. De resultaten lieten zien dat het hulpmiddel verbeterd was ten opzichte van eerdere versies. Er is verder werk nodig om de cohesiemeting te verbeteren en de methode voor het genereren van uitleg, waaronder het identificeren van geschikte verbindingswoorden en bronnen voor het genereren van betekenisvolle uitleg.

% todo probleemstelling van lexicaal vereenvoudigen

\subsection{Conceptuele of semantische vereenvoudiging}

Conceptuele vereenvoudiging lost dit probleem op. Theoretische kennis hierover is schaars, maar \textcite{Siddharthan2006} bestudeerde dit concept verder. Dit type vereenvoudiging betreft het opdelen van complexe concepten in eenvoudigere delen, het gebruik van duidelijke en bondige taal en het vermijden van technische jargon en abstracte uitdrukkingen. Het doel is om de inhoud begrijpelijker te maken, zonder dat hierbij de betekenis of nauwkeurigheid wordt aangetast. \textcite{Siddharthan2006} noemt deze transformatie een vorm van elaboratie of het uiteenzetten van een begrip.

\subsection{Semantische vereenvoudiging}

Semantisch vereenvoudigen is volgens \textcite{Siddharthan2006} de inhoud of betekenis van een tekst aanpassen om het begrijpelijker te maken voor een doelgroep. Zo wordt er meer uitleg of voorbeelden gegeven, of dat niet-relevante delen van de tekst worden weggelaten. 

% aanvraag via researchgate

\subsection{Tekstvereenvoudiging automatiseren}

Geautomatiseerde tekstvereenvoudiging is geen nieuw concept. Volgens onderzoeken van \textcite{Canning2000, Siddharthan2006} waren de eerste aanpakken op geautomatiseerde tekstvereenvoudiging gebouwd op rule-based modellen. Deze modellen bewerken de syntax door zinnen te splitsen, te verwijderen of de volgorde van de zinnen in een tekst aan te passen. Lexicale vereenvoudiging kwam hier niet aan de pas. Enkel bij recentere onderzoeken van \textcite{Coster2011, Bulte2018} werd het duidelijk hoe lexicale en syntactische vereenvoudiging gecombineerd kon worden.

\subsection{Combineren tot het geheel van tekstvereenvoudiging}

Het onderzoek van \textcite{DeBelder2010} richt zich op tekstvereenvoudiging voor kinderen. De doelgroep ligt echter jonger dan deze casus, maar het onderzoek haalt aan hoe de onderzoekers een methode opzetten voor lexicale en syntactische vereenvoudiging. \textcite{Bulte2018} werkte het aspect rond lexicale vereenvoudiging verder uit. Het resultaat van dit onderzoek was een \textit{pipeline} ontworpen om moeilijke woordenschat naar simpele synoniemen te vervangen. Eerst ging de tekstinhoud door een \textit{preprocessing}-fase, samen met het uitvoeren van WSE. Daarna werd de moeilijkheidsgraad van ieder token overlopen. De moeilijkheidsgraad is gebaseerd op hoe vaak een woord voorkomt in SONAR500\footnote{https://taalmaterialen.ivdnt.org/download/tstc-sonar-corpus/} een corpus met eenvoudige Nederlandstalige woorden. Synoniemen werden teruggevonden met Cornetto\footnote{https://github.com/emsrc/pycornetto}, een lexicale databank met Nederlandstalige woorden. Hiervoor gebruikten de onderzoekers een \textit{reverse lemmatization} fase. Lexicale vereenvoudiging is ingewikkeld wanneer er geen eenvoudigere synoniemen zijn. In dat geval blijft een moeilijk woord voor wat het is.

\section{Samenvatten}

Teksten vereenvoudigen met lexicale, conceptuele en/of syntactische vereenvoudiging biedt geen garantie dat de tekstinhoud korter zal worden. Bij de drie soorten vereenvoudiging wordt er initieel enkel per zin gekeken. De vereenvoudiging houdt geen rekening met voorafgaande of opvolgende zinnen \autocite{Dubay2004}. Teksten machinaal samenvatten is geen nieuw concept. Het onderzoek van \textcite{Hahn2000} onderzoekt hoe teksten automatisch samengevat kunnen worden. Dit onderzoek haalt onder meer twee aanpakken aan hoe een machine teksten kan samenvatten, namelijk extractief en abstractief. Daarnaast reikt \textcite{Hahn2000} drie manieren aan welke inhoud er zeker in de samengevatte versie moet op te merken zijn:

\begin{itemize}
	\item Informatieve samenvattingen vervangen de oorspronkelijke tekst. Alles wat de lezer nodig heeft, dus hoofd- en bijzaken, zijn betrokken in de samengevatte tekst.
	\item Indicatieve samenvattingen behouden enkel een tekst met links die een lezer doorverwijzen naar andere bronnen. 
	\item Kritische samenvattingen of \textit{reviews} bestaan uit de kerninhoud van de oorspronkelijke tekst en een opiniestuk over die specifieke kerninhoud.
\end{itemize}

% Generiek en gebruikersgerichte samenvatting
Verder haalt \textcite{Hahn2000} ook het onderscheid tussen een generieke en een gebruikersgerichte samenvatting. Een generieke samenvatting staat niet stil bij speciale noden of interesses van de eindgebruiker. Daarnaast houdt een gebruikersgerichte samenvatting wel rekening met sleutelwoorden of thema's in een tekst. \textcite{Hahn2000} haalt aan dat technologieën zoals full-text-search en gepersonaliseerd informatiefiltering het belang van gebruikersgerichte samenvatting naar voor duwen. \textcite{Hahn2000} omschrijft de architectuur van een samenvattingssysteem aan de hand van drie fases. Allereerst wordt de brontekst geanalyseerd. Daarna worden de \textit{salient points} of kernpunten in een tekst aangeduid. Deze punten zijn zinnen of tokens. Ten slotte worden de punten samengevoegd tot één uitvoertekst. De nadruk is verschillend per samenvattingsmethode.

\begin{figure}
	\includegraphics{img/summarization-mindmap.png}
	\caption{Afbeelding van \textcite{Chauchan2018}. De manier waarop teksten automatisch samengevat kunnen worden, is afhankelijk van drie verschillende domeinen.}
\end{figure}

\subsection{Extractief samenvatten}

% todo Leveraging BERT for Extractive Text Summarization on Lectures

Bij deze vorm worden de belangrijkste zinnen gemarkeerd en vervolgens opnieuw neergeschreven.  Dit is het equivalent van handmatig zinnen te fluoriseren en vervolgens op een blanco papier neerschrijven. Het nadeel hiervan is dat de uitvoertekst niet samenhangend zal zijn na het samenvatten. Dit maakt de tekst minder aangenaam om te lezen. \textcite{Verma2020} onderzocht de verschillende manieren waarop een tekst op een extractieve manier kan worden samengevat. Zij halen drie grote componenten aan, namelijk:

\begin{itemize}
	\item Graph-based
	\item Maximal Marginal Relevance
	\item Meta-heuristic-based
\end{itemize}

\subsubsection{Graafgebaseerd extractief samenvatten}

Graafgebaseerd extractief samenvatten is een techniek die een document voorstelt als een graaf, waarbij de knopen zinnen voorstellen en bogen de relatie tussen de zinnen voorstellen. Deze algoritmen achterhalen de belangrijkste zinnen in de graaf. Bijvoorbeeld kan het PageRank-algoritme, dat vaak wordt gebruikt voor het rangschikken van webpagina's in zoekmachines, worden gebruikt om de zinnen in de grafiek te rangschikken op basis van hun belangrijkheid.

\textcite{Parveen2015} raadt een graafgebaseerd systeem aan voor \textit{unsupervised learning}. Belangrijke zinnen worden bepaald met een lokaal minimum, alsook wordt redundantie vermeden. Deze methode blijkt goed te werken bij het ophalen van samenvattingen uit zowel lange wetenschappelijke artikelen als korte nieuwsartikelen. Daarnaast vermeldt \textcite{Parveen2015} ook dat het systeem altijd beter presteert wanneer coherentie wordt opgenomen en wanneer het wordt gecombineerd met positionele informatie. In toekomstig werk is \textcite{Parveen2015} van plan om meer taalkundige informatie in de entiteitsgrafiek op te nemen en beoordelingen van domeinexperts te verkrijgen om te zien of de redactiesamenvattingen als gouden samenvattingen kunnen worden gebruikt voor evaluatie.

\textcite{AbdelSalam2022} voerden een vergelijkend onderzoek uit rond SqueezeBERT en BERT. Met behulp van de compacte architectuur van SqueezeBERT kan een samenvatter worden gemaakt en ingezet voor real-time samenvatting. Dit is volgens de onderzoeker een interessant alternatief voor de originele BERT-base samenvatter, die meer dan 120 miljoen trainbare parameters heeft. In vergelijking heeft de voorgestelde SqueezeBERT slechts ongeveer 62 miljoen parameters, terwijl het samenvattingsprestatieniveau nog steeds boven de 90\% van het BERT-baseline model blijft. Uit de experimenten van \textcite{AbdelSalam2022} blijkt dat de SqueezeBERT-samenvatter een goed alternatief is om een samenvatter te trainen met bijna de helft van de grootte van het originele model met minimale afbreuk in de samenvattingsprestaties. Daarnaast blijkt uit het onderzoek dat het gebruik van efficiënte netwerken geïnspireerd door \textit{computer-vision literature}, zoals \textit{grouped convolutional layers}, de NLP downstream taken kan verbeteren.  \textcite{AbdelSalam2022} haalt verder aan dat er potentie is voor een productieversie van een SqueezeBERT-samenvatter, die minder parameters heeft dan DistilBERT met ongeveer 20\% en dezelfde ROUGE-1 score behoudt, terwijl het iets hogere ROUGE-2 en ROUGE-L scores behaalt. Hoewel de SqueezeBERT en DistilBERT iets lagere scores produceren in vergelijking met het BERT-baseline model, heeft SqueezeBERT als voordeel dat het minder trainingstijd en minder parameters heeft dan het baseline model met ~48,44\%. 

\subsubsection{Maximal Marginal Relevance}

Traditionele extractieve samenvattingssystemen bouwen verder op de door \textcite{Carbonell1998} ontworpen architectuur. Deze architectuur gebruikt een maximaal marginale relevantiescore of MMR. Deze architectuur houdt rekening met de diversiteit en de relevantie van de gemarkeerde zinnen. De relevantie van een zin in een tekst wordt bepaald door de mate waarin het de belangrijkste informatie overbrengt van de tekst waarvan het afkomstig is. Om diversiteit aan tekstinhoud te waarborgen, wordt er gekeken naar de mate waarin de geselecteerde zinnen verschillen van de eerder geselecteerde zinnen in de samenvatting. Als een zin relevant is maar qua inhoud te veel overlapt met de eerder geselecteerde zinnen, dan heeft deze minder kans om in de samenvatting opgenomen te worden. Deze score kan doorgaans berekend worden met KeyBERT\footnote{https://maartengr.github.io/KeyBERT/api/mmr.html}.

Extractief samenvatten met de MMR-methode is de methode bij uitstek voor ML-toepassingen. Onderzoekers bouwden verder op dit principe. In \textcite{McDonald2007} stelt de onderzoeker voor om de gulzige zoekalgoritme van MMR te vervangen door een globaal optimale formulering, waarbij het MMR-framework wordt uitgedrukt als een knapzakprobleem en er een \textit{integer linear programming} (ILP) \textit{solver} kan worden gebruikt om de functie te maximaliseren. De MMR-methode hield voordien enkel rekening met relevantie en diversiteit, maar niet met de optimale combinatie van zinnnen die in een samenvatting moet worden opgenomen. Deze aanpak vereist echter meer rekenkracht en tijd dan de standaard MMR-methode, maar het experiment van \textcite{McDonald2007} haalde wel aan dat dit leidde tot betere resultaten. \textcite{Lin2010} evolueerde het oorspronkelijke MMR-algoritme. Bij de evaluatie van deze architectuur benadrukte zij betere resultaten. 

\subsubsection{Metaheuristiek-gebaseerd}

Metaheuristieke samenvatting maakt gebruik van metaheuristieke optimalisatie-algoritmen zoals genetische algoritmen, \textit{simulated annealing} of zwermoptimalisatie om de belangrijkste zinnen in een tekst te achterhalen. Deze algoritmen zoeken volgens \textcite{Verma2020, Premjith2015} naar de beste combinatie van zinnen die de belangrijkste informatie in de tekst bevatten. De evaluatiefunctie in metaheuristische samenvattingsalgoritmen kan gebaseerd zijn op verschillende criteria, zoals zinslengte, -relevantie en -verbanden. \textcite{Rani2021} benadrukt dat teksten samenvatten met een metaheuristieke methode regelmatig vastraakt in een lokaal optimum. Dit is een tekortkoming op andere methoden. Daarnaast wijst het onderzoek uit aan dat metaheuristieke methoden geen \textit{steepness} of extremen op een \textit{search space behaviour} aanduiden. Er moet gebruikt gemaakt worden van een optimalisatiestrategie die gebaseerd is op gradiënten om de convergentie aanzienlijk te versnellen.

% gradienten: (een wiskundig concept dat de richting van de snelste toename aangeeft)
% convergentie: (het proces waarbij het algoritme naar de juiste oplossing toewerkt) -- Hierdoor wordt het algoritme efficiënter en sneller uitgevoerd.

\subsubsection{Experimenten over extractief samenvatten}
% \subsubsection{title}

% todo https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1 --> voorbeeld van een pipeline

\textcite{McKeown1999} voerden experimenten uit op extractieve samenvattingen van nieuwsartikelen. De resultaten wijzen erop dat deze vorm vatbaar is op vooroordelen. Bij nieuwsartikelen wordt er geen rekening gehouden met vooroordelen van de auteur. De zinnen worden genomen zoals ze zijn. \textcite{Hahn2000} bouwde verder op dit experiment. Zij voerden een experiment uit met een mix van \textit{knowledge-rich} en \textit{knowledge-poor} methoden, met succesvolle resultaten tot gevolg.

De nadruk bij extractief samenvatten ligt in het kiezen van de \textit{salient text units}. Deze punten zijn typisch in de vorm van zinnen. Er is nood aan een manier om de lexicale en statistische relevantie van een zin te kunnen aanduiden. Hiervoor haalt \textcite{Hahn2000} twee manieren aan:

\begin{itemize}
	\item Met een lineair gewicht model. Iedere teksteenheid wordt gewogen op factoren zoals de \textit{location weight} en het aantal voorkomens.
	\item Een gewicht model op basis van de statistische opvallendheid van een eenheid. Zo wordt er rekening gehouden met de aanwezigheid van een woord in (sub)titels.
\end{itemize}

% resultaten lineair gewicht model
% resultaten statistische opvallendheid

\textcite{Nallapati2017} wilden de nauwkeurigheid van andere modellen overbruggen. Dit doen ze met \textit{SummaRuNNer}\footnote{https://github.com/hpzhao/SummaRuNNer}, een oplossing voor het extractief samenvatten van teksten met een neuraal netwerk. De toepassing werd opgebouwd met PyTorch in  en bestaat uit een combinatie van drie modellen: een recurrent neuraal netwerk, een convolutioneel recurrent neuraal netwerk en een \textit{hiërarchical attention network}.

\subsubsection{Programmeren}

\begin{lstlisting}[language=Python]
todo
\end{lstlisting}

\subsection{Abstractief samenvatten}

% Kernzinnen achterhalen gebeurt met zes belangrijke features volgens \textcite{Khan2014}. Zij onderzochten de verschillende manieren om een tekst samen te vatten. Ze halen een semantische en een structuurgerichte aanpak aan.

\textcite{Cao2022} deed verder onderzoek naar \textit{deep learning} methoden om abstractieve samenvattingen te automatiseren. 

\subsubsection{Semantische aanpak}

% todo

\subsubsection{Structuurgerichte aanpak}

\subsubsection{Programmeren}

Om een abstractieve samenvatting op te bouwen bestaan er verschillende modellen. Het Pegasus-model vloeide voort uit een onderzoek van \textcite{Zhang2020} over het afhandelen van \textit{gap-sentences} met pre-trained models voor samenvatting met NLP. Pegasus haalt kernzinnen uit een invoertekst en zal die zinnen vervolgens als één uitvoerzin uitschrijven. Dit model werd getrained en beoordeeld op samenvattingstaken zoals emails, patenten, rekeningen en ook wetenschappelijke artikelen. Hieronder een code-snippet van hoe een simpele abstractieve samenvatting kan worden gemaakt met Google Pegasus.

\begin{lstlisting}[language=Python]
todo
\end{lstlisting}


\subsection{Hybride samenvatting}

In het best denkbare geval wordt abstractieve en extractieve samenvatting gecombineerd volgens \textcite{Hsu2018, Huang2019}. Zo omvat een pipeline voor hybride samenvatting twee onderdelen: een \textit{content selection} fase waarin de kernzinnen met extractieve samenvatting worden opgehaald en \textit{paraphrasing} waarbij de gemarkeerde kernzinnen worden samengevat met abstractieve samenvatting. 

\subsection{Evaluatie}

% manuele en semi-automatische

Handmatig samenvattingen van lange documenten gaan beoordelen vergt tijd en voldoende planning \autocite{Nenkova2004}. Zo zijn er twee metrieken om een samenvatting automatisch te beoordelen.

% ROUGE

\subsubsection{Referentieteksten}

ROUGE meet de gelijkenis tussen \textit{machine-generated} tekst en een referentietekst, meestal gemaakt door een mens. Deze meting is recall-gebaseerd en gebaseerd op exacte token matches. Dit impliceert dat er geen rekening wordt gehouden met gelijkbetekenende of synonieme zinnen \autocite{Lin2004}. De ROUGE-modellen die verderbouwen houden rekening met deze tekortkomingen. ROUGE-2 van \textcite{Ganesan2018} voorziet dictionaries van synoniemen, zodat er rekening wordt gehouden met synonieme zinnen. ROUGE-G van \textcite{ShafieiBavani2018} gebruikt graafalgoritmen om lexicale en semantische matching mogelijk te maken.

BLEU volgt een gelijkaardige werking. De gelijkenis tussen een machine-generated tekst en een referentietekst wordt beoordeeld, maar deze meting is precision-gebaseerd.

% todo



\subsection{Conclusie}

% De theoretische concepten om teksten te vereenvoudigen. Teksten kunnen op vier manieren worden vereenvoudig 

\section{Valkuilen}

NLP maakt gebruik van kunstmatige intelligentie en machine learning om menselijke taal te begrijpen en te verwerken, terwijl tekstvereenvoudiging ingewikkelde teksten omzet in begrijpelijke taal voor een breder publiek. Hoewel deze technologieën veelbelovend zijn, zijn er veelvoorkomende valkuilen waar ontwikkelaars en gebruikers rekening mee moeten houden \autocite{Sciforce2020, Roldos2020, Khurana2022}.

\subsection{Taalgerelateerde valkuilen}

\subsubsection{Homoniemen}

\textit{Sequence Labeling} koppelt labels aan tokens in doorlopende tekst. Homoniemen kunnen echter roet in het eten gooien. \textcite{Roldos2020} haalt aan dat het voor een machine moeilijk is om de context van homoniemen te achterhalen. Bijvoorbeeld bij het woord ‘bank’ is het niet duidelijk voor de machine of het gaat over de geldinstelling of het meubel. 

\subsubsection{Synoniemen}

% Daarnaast zijn synoniemen een probleem voor tekstverwerking.

% \subsection{Evaluatie van de toepassing}

\subsection{Datasets}

Het onderzoek van \textcite{Sciforce2020} haalt aan dat het merendeel van NLP-toepassingen Engelstalige invoer gebruikt. Niet-Engelstalige toepassingen zijn zeldzaam. De opkomst van AI technologieën die twee datasets gebruiken, biedt een oplossing voor dit probleem. De software vertaalt eerst de oorspronkelijke tekst naar de gewenste taal, voordat de tekst wordt herwerkt. 


% todo bron openai
% The Reddit TL;DR dataset used for training the summarization models contains offensive or biased content, which can result in biased or offensive summaries generated by the models.


% Hetzelfde onderzoek bewijst dat het vertalen van gelijkaardige talen, zoals Duits en Nederlands, een minimaal verschil opleverd.

\subsection{Meaning distortion}



\subsection{Paternalisme}

De doelstelling van assisterende software is om gelijke kansen te bieden aan iedereen. Zoals eerder vermeld, zorgt tekstvereenvoudiging voor een simpelere syntax en woordenschat in een tekst. Volgens \textcite{Niemeijer2010} zijn de ethische overwegingen die samenhangen met tekstvereenvoudiging via implicaties voor assistieve technologie niet gemakkelijk te scheiden van de technologie die wordt gebruikt om het resultaat te bereiken. Ontwikkelaars moeten, volgens deze auteur, rekening houden met de doelgroep waarvoor ze een toepassing maken.

\subsubsection{Ethische implicaties}

Het onderzoek van \textcite{Gooding2022} onderzocht waar ontwikkelaars rekening mee moeten houden bij de ontwikkeling van adaptieve software, waaronder het vereenvoudigen van teksten. Ontwikkelaars moeten zich meer bewust worden van de behoeften en verwachtingen van de eindgebruiker bij het ontwikkelen van een tekstvereenvoudigingstoepassing. Haar onderzoek benadrukt de paternalistische en afhankelijke aard van assisterende toepassingen. Tekstvereenvoudiging omvat drie transformaties, maar de moeilijkheidsgraad is niet statisch. Een adaptieve tekstvereenvoudigingstoepassing moet de eindgebruiker een keuze aanbieden om aan te passen wat vereenvoudigd wordt, afhankelijk van zijn of haar specifieke behoeften.

% Xu bron

Volgens \textcite{Punardeep2020} maken de meeste AI-toepassingen voor tekstvereenvoudiging gebruik van \textit{black-box} modellen. Een \textit{black-box} model geeft niet aan waarom specifieke transformaties worden uitgevoerd, bijvoorbeeld het vervangen van een woord door een eenvoudiger synoniem. Het model kan dus niet aangeven waarom het juist dat woord heeft vervangen door dat specifieke synoniem. Deze AI-toepassingen vallen onder de categorie van \textit{supervised learning} en het model leert handelingen uit de data waarop het is getraind. Dit is echter problematisch, aangezien \textcite{Xu2015} benadrukt dat veel toepassingen voor tekstvereenvoudiging geen rekening houden met de doelgroep waarvoor ze zijn ontwikkeld. 

% https://hdsr.mitpress.mit.edu/pub/f9kuryi8/release/8 --> benadruk gevaar van black-box modellen

\subsubsection{Oplossing}

Om dit probleem op te lossen, is het belangrijk om de eindgebruiker, in dit geval scholieren met dyslexie in het derde graad middelbaar onderwijs, de keuze te geven. Zoals beschreven in \textcite{Gooding2022}, zijn er verschillende mogelijkheden. Bijvoorbeeld, de eindgebruiker moet de mogelijkheid hebben om te kiezen welke synoniemen de tekst lexicaal zullen aanpassen. Een alternatieve aanpak voor syntactische vereenvoudiging is om de scholier zelf zinnen te laten markeren die moeilijk te begrijpen zijn, zodat het systeem alleen de door de eindgebruiker aangegeven zinnen vereenvoudigt.


\subsection{Problemen bij lexicale vereenvoudiging}

\begin{itemize}
	\item Acroniemen
	\item Homoniemen
\end{itemize}

\subsection{Problemen bij syntactische vereenvoudiging}

\begin{itemize}
	\item Kerninhoud verliezen
\end{itemize}

\subsection{Evaluatie en interpretatie}

\subsubsection{Alignment problem}

% To safely deploy powerful, general-purpose artificial intelligence in the future, we need to ensure that machine learning models act in accordance with human intentions. This challenge has become known as the alignment problem. A scalable solution to the alignment problem needs to work on tasks where model outputs are difficult or time-consuming for humans to evaluate. To test scalable alignment techniques, we trained a model to summarize entire books, as shown in the following samples. These samples were selected from works in the public domain, and are part of GPT-3′s pretraining data. To control for this effect, and purely for research purposes, our paper evaluates summaries of books the model has never seen before. Our model works by first summarizing small sections of a book, then summarizing those summaries into a higher-level summary, and so on.

\subsubsection{Menselijke feedback bij reinforcement learning}

De beste samengevatte versie van een tekst achterhalen met menselijke feedback vergt de juiste methode. De doelgroep waarvoor een tekst wordt samengevat, moeten nauw in het proces worden opgenomen.

\subsubsection{Betrouwbaarheid van automatische metrieken voor precision en recall}

\section{Beschikbare software voor tekstvereenvoudiging}

% inleiding voor welke software
Dyslexie is een veelvoorkomende aandoening die de lees- en schrijfvaardigheden van scholieren kan belemmeren. Om deze scholieren te ondersteunen, worden er verschillende softwareprogramma's en tools ontwikkeld. In dit hoofdstuk zal worden gekeken naar mogelijke nationale en internationale software die specifiek is ontworpen om scholieren met dyslexie te helpen bij het lezen van teksten. Er zal met name worden gekeken naar de beschikbare software in Vlaamse middelbare scholen, chatbots, zoals Bing AI en ChatGPT, en software die speciaal is ontwikkeld om dyslexie te ondersteunen bij het lezen.

\subsection{Momenteel ingezet in het onderwijs}

% inleiding

In het middelbaar onderwijs wordt lees- en studieondersteuning voor scholieren met dyslexie enkel in de vorm van voorleessoftware voorzien \autocite{DeCraemer2018, OnderwijsVlaanderen2023}. Naast luister- en schrijfopties kunnen scholieren zinnen markeren om teksten samen te vatten, maar enkel de gemarkeerde zinnen worden betrokken in de samengevatte versie. Alle softwarepakketten bieden echter geen onafhankelijke samenvat- of vereenvoudigfunctie aan. \textcite{OnderwijsVlaanderen2023} leent licenties voor de volgende softwarepakketten uit:

\begin{itemize}
	\item SprintPlus
	\item Kurzweil3000
	\item Alinea Suite
	\item IntoWords
	\item TextAid
\end{itemize}

% afbeelding

\subsection{Proof-of-concepts en online webapplicaties}

Tot dusver zijn er talloze tools online beschikbaar die teksten generiek of voor een algemeen doelpubliek kunnen vereenvoudigen of samenvatten. Zo omschrijft \textcite{Bingel2018} een proof-of-concept voor een webapplicatie die teksten vereenvoudigd, vooral voor mensen met dyslexie. Deze software noemt nu Hero en bevindt zich in betafase.

Resoomer, Paraphraser en Scholarcy zijn oorspronkelijk Engelstalige tools, met ondertussen de mogelijkheid om een abstractieve samenvatting te maken van Nederlandstalige teksten. De taalmodellen waar deze applicaties op werken, is niet gekend. Daarnaast zijn er ook geen API's beschikbaar om mee te werken. % De assumptie is dat dit gericht kan zijn op de Nederlandse taal, of een anderstalig model en nadien vertaald naar het Nederlands.

% voetn(o)ot(en) toevoegen

\subsection{GPT-3}

% uitleg over gpt
\textit{Generative Pretrained Transformer 3} of GPT-3 is een taalmodel ontworpen door OpenAI. Het model is getraind op niet-gecategoriseerde data van het internet en is gebaseerd op datasets zoals Common Crawl, WebText2, Books1, Books2, and Wikipedia. Dit taalmodel steunt op \textit{Reinforcement Learning from Human Feedback} of RLHF. 

% verschil tussen chat gpt en gpt 3

\begin{figure}[H]
	\includegraphics[width=10cm]{img/chatgpt-example-simplification-gooding.png}
	\caption{Afbeelding van Gooding 2022. De invoertekst is een paragraaf uit een niet-vermeld boek van de Russische schrijver Dostoevsky. Het resultaat van de meegegeven prompt is een transformatie dat iedere vorm van vooraf aangehaalde vereenvoudiging weergeeft. Lexicale, conceptuele en syntactische vereeenvoudiging worden op de invoertekst toegepast.}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=10cm]{img/chatgpt-example-different-versions-gooding.png}
	\caption{Afbeelding van Gooding 2022. Gooding haalt verder aan dat modellen zoals ChatGPT op twee vlakken de leesbaarheid van een tekst kan bevorderen. Allereerst door het verlenen van verschillende mogelijke versies van een vereenvoudigingstaak.}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=10cm]{img/chatgpt-example-evaluation-gooding.png}
	\caption{Afbeelding van Gooding 2022. Gooding haalt aan dat %todo!!
	}
\end{figure}

\textcite{Lisowski2023} vergelijkt de twee OpenAI taalmodellen met een \textit{mixed-methods} onderzoek. Al blijken de twee heel gelijkaardig, het experiment benadrukt dat het ChatGPT-model een conversationeel model is, terwijl GPT-3 een ML-model is bedoeld om met hoogstens één prompt te werken. De grootte van het GPT-3 model met 175 miljard parameters imposanter dan Chat-GPT. Daarnaast is de limiet bij het meest recente GPT-3 model is 4000 tokens. Verder haalt Lisowski aan dat de kwaliteit bij beide modellen sterk afhankelijk is van de invoer. De prompts moeten concreet genoeg zijn, om zo niet af te wijken van wat de gebruiker wilt.

\subsubsection{Beschikbare GPT-3 engines}

% todo bron: https://platform.openai.com/docs/
De documentatie van OpenAI\footnote{https://platform.openai.com/docs/} reikt vier verschillende engines voor het GPT-3 taalmodel aan, namelijk Davinci, Curie, Babbage en Ada. 

% (...) raadt aan om Davinci voor Ada daarentegen bevat minder recente data, maar is geschikt voor kleinere taaltaken. De andere modellen zijn echter cost-effective en sneller. 

% https://platform.openai.com/docs/models/finding-the-right-model

\begin{itemize}
	\item Davinci-003 is het nieuwste model en is in staat om alles te doen wat de andere modellen capabel in zijn. Het model maakt gebruik van text de invoertekst eventueel kan aanvullen, mocht de invoertekst afgebroken zijn. Deze aanvulling kan in vraag worden gesteld. Aanvullend geeft (2) aan dat deze engine de meest menselijke antwoorden geeft op basis van foutenmarge. De andere engines kwamen niet in de buurt. \textcite{Binz2023} vult aan dat deze engine de meest \textit{menselijke} antwoorden teruggeeft.
	\item Curie is in staat om zinnen met nuance te verwerken.
\end{itemize} 

\begin{figure}
	\begin{center}
		\includegraphics{img/chatgpt-engines-mean-regret.png}
		\caption{Afbeelding van \textcite{Binz2023}. Dit toont de \textit{mean regret} aan tussen de vier engines en de menselijke antwoorden.}
	\end{center}
\end{figure}

\subsubsection{Tools met GPT-3}

\textcite{Mottesi2023} haalt enkele lees- en schrijftools aan die gebruik maken van de GPT-3 API.

\subsubsection{Vergelijking met andere taalmodellen}

% vergelijking met BERT
Volgens \textcite{Mottesi2023} is meest opvallende verschil tussen GPT-3 en BERT de architectuur. GPT-3 is een autoregressief model, terwijl BERT bidirectioneel is. GPT-3 houdt alleen rekening met de linkercontext bij het maken van voorspellingen, terwijl BERT zowel de linker- als de rechtercontext in overweging neemt. Dit maakt BERT beter geschikt voor taken zoals sentimentanalyse of NLU, waarbij het begrijpen van de volledige context van een zin of zinsnede essentieel is. GPT-3 heeft toegang tot meer informatie (45TB) dan BERT (3TB), wat het een voordeel kan geven bij het samenvatten of het vertalen. Ten slotte zijn er ook verschillen in grootte. Hoewel beide modellen erg groot zijn (GPT-3 heeft 1,5 miljard parameters en BERT heeft 340 miljoen parameters), is GPT-3 aanzienlijk groter dan zijn voorganger vanwege de veel uitgebreidere trainingsdatasetgrootte (470 keer groter dan die gebruikt om BERT te trainen).

\subsubsection{GPT-3 voor samenvattingen}

% datamodellen -- da vinci

% news summarization \textcite{Goyal2022}

% todo boeken samenvatten: https://openai.com/research/summarizing-books

% https://openai.com/research/learning-to-summarize-with-human-feedback

Onderzoek naar OpenAI's ChatGPT en GPT-3 modellen bevindt zich in een vrij vroeg stadium, al zijn er wel enkele vergelijkende onderzoeken die de kracht en zwaktes van deze technologieën aantonen.

Het experiment van \textcite{Goyal2022} achterhaalt het gebruik van \textit{zero-shot} samenvattingen buiten generieke samenvattingen. Het onderzoek staat stil bij de impact van prompt-gebaseerde modellen voor het automatisch samenvatten van nieuwsartikelen. Daarnaast maakte het onderzoek gebruik van text-davinci-002 als case study. Uit het experiment besluiten de onderzoekers dat \textit{zero-shot} samenvattingen met GPT-3 beter presteren dan \textit{fine-tuned} modellen, en dat bestaande automatische metrieken zoals BLEU, ROUGE en BERTScore niet geschikt zijn om \textit{zero-shot} samenvattingen te beoordelen. Verder blijkt dat zero-shot samenvattingen meer coherentie en relevantie hebben voor trefwoord-gebaseerde samenvattingen, terwijl aspect-gebaseerde samenvattingen nog vaak blijven te falen.

% todo misschien een visualisatie

\subsection{Bing AI}

% https://www.gsqi.com/marketing-blog/bing-ai-chat-in-the-edge-sidebar/

% https://twitter.com/AlphaSignalAI/status/1624077152302862339

\subsection{Google Bard en PaLM}

% https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html


\subsection{Meta LLaMa}

% https://www.theverge.com/2023/2/24/23613512/meta-llama-ai-research-large-language-model

% (2) LLaMA: Open and Efficient Foundation Language Model

LLaMa toont potentieel, want bij het experiment van (2) is LLaMa sterker dan GPT-3 en soortgenoten, terwijl het van tien keer minder parameters gebruik maakt.


\section{Conclusie}

% welk soort samenvatting? -- waarom
% welke soorten vereenvouding? -- waarom
% wat moet een applicatie zeker hebben om scholieren met dyslexie te ondersteunen?
% brengt GPT-3 hier een meerwaarde? -- hoe inzetten?