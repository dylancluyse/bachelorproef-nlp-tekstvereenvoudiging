\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}%
\label{ch:stand-van-zaken}

\section{Onderzoeken rond dyslexie}

Lezen is een essentieel onderdeel van ons dagelijks leven en speelt een belangrijke rol in onze communicatie en begrip. Dyslexie kan het functioneren in het dagelijks leven belemmeren. Het begrijpen van de noden en hindernissen voor een scholier met dyslexie is van belang om deze doelgroep te ondersteunen en hun kwaliteit van lezen te verbeteren. Deze sectie zal ingaan op de unieke noden en bespreken hoe mensen met dyslexie kunnen worden geholpen bij het lezen. De volgende onderzoeksvraag wordt in deze sectie beantwoordt: "Welke specifieke noden hebben scholieren met dyslexie van de derde graad middelbaar onderwijs bij het begrijpen van complexere teksten?"

\subsection{Centraal zicht op dyslexie}

Lezen is onnatuurlijk en volgens de geschiedenis van de mens een recent begrip. Pas 5000 jaar geleden werd de geschreven taal bedacht. Mensen worden niet met leesvaardigheid geboren, maar leren dit zelf aan en daarvoor moet het brein heringericht worden \autocite{Bonte2020, VanDerMeer2022}. De visuele cortex is een hersengebied dat instaat voor de aanschouwelijke waarneming en herkenning van objecten, zoals meubels of letters. Lezen traint dit gebied bij het herkennen van letters, maar dit is niet evident en vordering bij letterherkenning gebeurt pas na meerdere pogingen. 

% Tijdens het leren schrijven worden letters regelmatig in spiegelbeeld geschreven. De visuele cortex moet het spiegelen van objecten onderdrukken door rotaties te negeren \autocite{Bonte2020, Romanovska2021}. Een d/b of een p/d worden door elkaar gehaald. Het brein moet gemanipuleerd worden om deze spiegeling te onderdrukken. De visuele cortex moet worden gekoppeld aan de auditieve cortex, samen met verbindingen met het geheugen en de begrip van een tekst. Afzonderlijke klanken moeten ook worden aangeleerd. 
 
Dyslexie betekent letterlijk 'beperkt lezen'. Het voorlezen verloopt radend, letter-voor-letter en langzaam. Lezen gaat niet soepel en leesproblemen kunnen beperkend zijn. Elke zin verloopt langzamer. Dyslexie is genetisch en erfelijkheid speelt een rol. Goede woordenschat ontwikkeling of vaak voorlezen is een beschermende factor tegen dyslexie. Ten slotte noemen \textcite{Vellutino2004, Bonte2020} dyslexie een verborgen stoornis, want de diagnose kan niet gesteld worden met hersenscans en vereist daarmee een nauwe opvolging bij de diagnose. Onderzoeken halen drie verschillende types van dyslexie aan, namelijk fonologische dyslexie, \textit{surface dyslexia} en \textit{deep dyslexia}. Dezelfde onderzoeken wijzen erop dat een overlap van kenmerken over de drie types heen mogelijk is \autocite{Rello2012, Vellutino2004}.

\subsection{Centraal zicht op de doelgroep}

\subsubsection{Statistieken rond prevalentie en comorbiditeit}

Vlaamse en Nederlandse onderzoeken van \textcite{Wentink2008, Desoete2017} wijzen uit dat gemiddeld 4\% van de Nederlandstalige bevolking de diagnose van dyslexie heeft. De transparantie van de taal beïnvloedt volgens \textcite{APA2013} de prevalentie van dyslexie in een taalgebied. Spaans, Italiaans en Chinees zijn transparant en hebben een sterkere grafeem-foneem en foneem-grafeem koppeling. Zo is bijvoorbeeld slechts 1\% van de Chinese sprekers dyslectisch. Engels is een minder transparante taal waar 
klanken op verschillende manieren geschreven kunnen worden, bijvoorbeeld \textit{eight} en \textit{late}. De prevalentie van dyslexie ligt met 20\% dan ook hoger in Engelstalige landen. Het aantal scholieren met dyslexie in het lager en middelbaar onderwijs wereldwijd loopt op tot 15\% ingeschat \autocite{Bonte2020, VanDerMeer2022}.

% todo grafiek https://dyslexiacompass.eu/wp-content/uploads/2022/02/Dyslexia-Compass-Report_compressed.pdf

\subsubsection{Scholieren met dyslexie in de derde graad middelbaar onderwijs}

Mensen met dyslexie ondervinden een last bij het technisch lezen van een tekst. Al zijn er onderzoeken naar adolescenten en volwassenen met dyslexie, onderzoeken rond dyslexie richten zich vaker op kinderen in het kleuter- en basisonderwijs. Volgens \textcite{Bonte2020} is dit om voldoende onderzoek te hebben voor de meest geschikte diagnose en ondersteuning op jonge leeftijd. Deze diagnose zo vroeg mogelijk vastleggen vereist voldoende onderzoek. Bonte haalt een sneeuwbaleffect aan wanneer kinderen met dyslexie een zwakke ondersteuning krijgen. Deze last wordt meegedragen naar volgende levensfases. Volgens \textcite{Lissens2020} zijn jongvolwassenen en ouderen een leeftijdsgroep die bij onderzoeken rond dyslexie over het hoofd word gezien. Het onderzoek van \textcite{Lissens2020} benadrukt deze vaak over het hoofd geziene doelgroep. Mensen met dyslexie ervaren uitdagingen bij het lezen en schrijven. Op sociaal vlak worden deze mensen niet begrepen door anderen, omdat ze woorden vaak verkeerd uitspreken of verkeerd spellen. Het tempo van anderen bijhouden kan stroef verlopen en het verwerken van teksten vereist meer energie. Ondanks het vele oefenen kan snel en veel lezen moeilijk blijven. 

\subsection{Diagnosecriteria}

Dyslexie is geen lijst van 'kwalen' waaraan een scholier moet voldoen om dit te bezitten. Zo halen \textcite{Kleijnen2008, Ghesquiere2018} samen drie beschrijvende criteria aan waarmee de diagnose van dyslexie wordt vastgesteld. Het achterstandscriterium wijst aan dat een persoon ten opzichte van andere leeftijdsgenoten niet even hoog scoort op het vlak van lezen. Vervolgens houdt het hardnekkigheidscriterium in dat de lees- of spellingsachterstand het gevolg is van een moeizame automatisering van het lees- en spellingsproces. Ten slotte wijst het exclusiviteitscriterium volgens \textcite{Ghesquiere2018} erop dat een persoon enkel de diagnose van dyslexie heeft, zonder bijhorende lees- of spellingsstoornissen. 

Verder halen \textcite{VanVreckem2015, Ghesquiere2018} de volgende kenmerken aan die kunnen verschillen per individu.

\begin{itemize}
	\item De ernst of uitgebreidheid van een stoornis.
	\item De gevolgen van een stoornis, zoals faalangst.
	\item De mate waarin iemand al dan niet kan compenseren.
	\item De secundaire kenmerken zoals problemen met werkhouden en structuur.
\end{itemize}

Het onderzoek van \textcite{VanVreckem2015} achterhaalt of het groepsprofiel overeenkomt met de individuele profielen bij begrijpend lezen en spelling. De onderzoeksresultaten bij een experiment met zeventien kinderen wijst uit dat er een geïndividualiseerde analyse en effectieve behandeling op maat nodig is bij begrijpend lezen. Onvoldoende beheerste leerstof en leesstrategieën per kind moet achterhaald worden om zo specifieke begeleiding te kunnen bieden.

\subsection{Mogelijke drempels voor mensen met fonologische dyslexie.}

% In \textcite{Avontuur2015} worden getuigenissen van taalproblemen bij fonologie, morfologie, zinsbouw en semantiek aangehaald.

Spellingsregels toepassen hindert mensen met dyslexie. Dit kan leiden tot een onzeker gevoel en angst om fouten te maken, frustratie en stress, waardoor het voor mensen met dyslexie moeilijker wordt om hun vaardigheden te verbeteren. Vooroordelen aan dyslexie zijn prevalent volgens \textcite{Diels2022}. Mensen met dyslexie kunnen in het bedrijfsleven en binnen de schoolmuren als minder intelligent of traag worden afgestempeld. Sommige mensen met dyslexie proberen deze leesstoornis te maskeren door bijvoorbeeld moeilijke woorden in afkortingen te schrijven. Toch motiveren onderzoeken zoals \textcite{Ghesquiere2018, Lissens2020, Bonte2020} deze doelgroep door hun sterk doorzettingsvermogen, geduldig en luisterend karakter en probleemoplossend denkvermogen te benadrukken. Deze motivatie en inspiratie helpt deze doelgroep om te blijven oefenen en hun vaardigheden te ontwikkelen, ondanks de uitdagingen. Onderzoeken rond digitale toepassingen voor kinderen en scholieren met dyslexie reiken prevalente moeilijkheden en struikelblokken voor deze doelgroep aan. De onderzoeken beklemtonen welke unieke noden scholieren met dyslexie kunnen hebben.

\begin{itemize}
	\item Langzame woordbenoeming
	\item Hardnekkig letter-voor-letter lezen
	\item Woordherkenning en -herinnering
	\item Visuele disfunctie
	\item Letter- en klankvorming
	\item Homofonische of pseudo-homofonische woordenschat
	\item Begripsproblemen
\end{itemize}

\subsubsection{Langzame woordbenoeming}

Het correct spellen van pseudowoorden en regelmatig gespelde woorden is mogelijk met beheerste letterklankkoppelingen. Echter verloopt het automatiseren van moeilijke en nieuwe woorden stroef, met een trage woordbenoeming tot gevolg. Lezers kunnen met dit leesprobleem veel woorden niet als één geheel herkennen. \textcite{Filipak2020} raadt aan om pseudowoorden en het herkennen te oefenen als mogelijke hulp. De meeste schrijffouten komen voor in onregelmatig gespelde woorden waardoor een fonologische route die wel tact is, leidt tot het schrijven van \textit{gedaan} als \textit{guhdaan}.

\subsubsection{Begripsproblemen}

Typerende symptomen de verstoring van leesbegrip en het spreken in qua betekenis onbedoelde klanken, woorden en woordgroepen. Bij fonologische dyslexie kan bos bijvoorbeeld gelezen worden als boom. Begripsproblemen bij het lezen kunnen goed visueel, met steun van film en afbeeldingen ondersteund worden, beter dan alleen via gedrukte woorden. Daarbij moet de lezer die het geschreven woord wil ontcijferen, gebruik kunnen maken van bronnen van kennis op een hoger niveau: een grote woordenschat en een goed redeneervermogen. Schriftelijke expressie is uit den boze.

\subsubsection{Hardnekkig letter-voor-letter lezen}

\textcite{Bonte2020} haalt een minder optimale informatieverwerking in visuele gebieden aan bij scholieren met dyslexie, wat het gevolg is van een minder optimale leesontwikkeling. Deze verwerking is belangrijk voor letter- en woordherkenning. Lezers zijn niet in staat woorden goed te lezen, zelfs niet met een langzame en spellende letter-klankroute. Lange woorden worden moeizaam gelezen en scholieren hebben de neiging om visueel gedesoriënteerde te raken. Er is verwarring over de richting van de letters.

\subsubsection{Woordherkenning}

Oogbewegingsonderzoeken zoals \textcite{RiveroContreras2021, Zhang2021} laten zien dat geoefende lezers pauzeren bij 50-80\% van de woorden om zich erop te fixeren tijdens een saccade (een snelle oogbeweging). Kinderen kunnen de letters correct herkennen, maar last hebben van verspringende letters tussen woorden in zinnen, wat minder voorkomt bij het lezen van woorden in lijsten en opsommingen dan bij doorlopende tekst en volzinnen.

\subsubsection{Visuele disfunctie}

Het boek van \textcite{Bezem2016} maakt ouders en leerkrachten bewust rond de principes van visuele disfunctie. Mensen met visuele disfunctie observeren objecten anders dan de meeste mensen. Fixatie disparatie is een vorm van visuele disfunctie dat een onjuiste samenwerking van de ogen veroorzaakt. Ogen doen hun werk vanuit een verschillende positie en nemen zaken afzonderlijk waar. Deze afzonderlijke observaties moeten samengenomen worden. Als deze fixatie niet correct verloopt, dan wordt er van disparatie gesproken. Het gevolg is dat mensen met drie letters tegelijk zien en daardoor een woordbeeld missen of een zwakke spellingstijl gebruiken.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=8cm]{img/visuele-disfunctie.png}
	\end{center}
	\caption{Afbeelding uit \textcite{Bezem2016}. Deze afbeelding bootst fixatie disparatie na.}
\end{figure}

In het onderwijs worden er initiatieven ingezet. Zo krijgen scholieren in het lager en middelbaar onderwijs een vaste plaats. Deze scholieren worden niet geplaatst bij het raam, want het invallende licht in de ogen heeft een negatieve invloed op fixatie disparatie, waardoor het lastiger wordt om de ogen te laten samenwerken \autocite{Bezem2016}. Het onderzoek van \textcite{RiveroContreras2021} wijst uit dat teksten aanpassen, zoals lexicaal vereenvoudigen en samenvatten, een significant effect heeft op de leessnelheid en woordherkenning van een kind met visuele dysfunctie.

\subsubsection{Letter- en klankverwarring}

Wanneer letterverwarring en letterklankproblemen samenkomen, kan dit leiden tot diverse leesfouten zoals klank- en letterverwisselingen, weglaten van letters en moeite met auditieve analyse en synthese. Om deze problemen effectief aan te pakken, is het van groot belang om ze snel te constateren en gebruik te maken van methoden voor technisch lezen. Er zijn verschillende digitale en tekstuele tools beschikbaar om leesproblemen aan te pakken. Enkele voorbeelden zijn educatieve apps en software, e-books en luisterboeken, woordspelletjes en puzzels, en tekst-naar-spraak technologie. Hoewel deze hulpmiddelen nuttig kunnen zijn, is het belangrijk om te benadrukken dat ze niet de plaats innemen van persoonlijke begeleiding en ondersteuning door een professional.

\subsection{Bewezen effecten van tekstvereenvoudiging -en aanpassing bij scholieren met dyslexie}

Dyslexie kan zich op verschillende manieren uiten bij elke leeftijdsgroep. Een ondersteunende toepassing moet worden ontworpen met een individuele analyse van de specifieke behoeften en uitdagingen van elke leerling in gedachten \autocite{Gooding2022}. Instructies moeten op een begrijpelijke en geïndividualiseerde manier worden gepresenteerd om de leerlingen te helpen bij het begrijpen en toepassen van de informatie. Het is belangrijk om te erkennen dat dyslexie zich bij verschillende kinderen op verschillende manieren kan uiten. Een bijkomende stoornis heeft bijvoorbeeld geen impact op de spellingprestaties van een kind. Het is daarom belangrijk om een toepassing te ontwerpen met de diversiteit van dyslexie in het achterhoofd.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=9cm]{img/text-simplification-reading-ease.png}
	\end{center}
	\caption{Afbeelding van \textcite{Dubay2004}}
\end{figure}


\subsubsection{Effecten op wijzigingen op lexicaal niveau}

Het experiment van \textcite{Rello2013a} wijst uit dat de decodeertijd of ontcijfertijd vermindert significant bij mensen met dyslexie wanneer de tekst een frequent woordgebruik toepast. De decodeertijden bij deelnemers met dyslexie waren significant korter bij het gebruik van frequente woordenschat, terwijl de decodeertijd bij minder frequente woordenschat hoger lag. Het verschil bij deelnemers zonder dyslexie was amper merkbaar.

\begin{figure}
	\includegraphics[width=\linewidth]{img/readability-mean-fixation-duration.png}
	\caption{Afbeelding van \textcite{Rello2013a}. Volgens de richting van de pijl wordt de ideale situatie benaderd, gekenmerkt door doelwaarden. Deze waarden worden bereikt door mensen zonder dyslexie onder optimale omstandigheden. Het gebruik van vaak voorkomende woorden vermindert de decodeertijd en verbetert de leesbaarheid voor mensen met dyslexie.}
\end{figure}

Bevraagden met dyslexie maken minder leesfouten bij een tekst met een gereduceerde lexicale complexiteit volgens \textcite{Gala2016}. De leessnelheid bij de kinderen lag hoger zonder een invloed op de begrijpelijkheid van de tekst. Het experiment benadrukt dat de bevraagden moeite hadden bij het lezen van woorden met meer dan zeven karakters. Daarnaast zorgden onregelmatige en infrequente lettergreepcombinaties voor moeilijkheden bij de bevraagde kinderen met dyslexie.

\subsubsection{Effecten bij grammatische en syntactische wijzigingen}

Onderzoek rond de effecten op syntactische vereenvoudiging bij kinderen en scholieren met dyslexie zijn in schaarse hoeveelheid. Het aanpassen causale structuren bij kinderen en jongeren met een lage leesgraad had een significant effect op het leestempo en de foutenmarge van de bevraagden uit het experiment van \textcite{Linderholm2000}. Bij de revisies werden coherentieonderbrekingen werden hersteld door extra uitleg te voorzien, alsook door tekstgebeurtenissen in een temporele of tijdsafhankelijke volgorde te plaatsen. Zowel vaardige als minder vaardige lezers hadden baat bij de revisies. Verbale parafrasering heeft geen significant effect op lezers met dyslexie volgens \textcite{Rello2013c}. De bevraagden waren 13 tot en met 37 jaar oud met een gemiddelde leeftijd van 21 jaar. Het tekstformaat bleef ongewijzigd, maar lettertypes werden wel aangepast. 

\subsubsection{Effecten bij wijzigingen op formaat en structuur}

Geassisteerd samenvatten bevoordeelt de leesbaarheid van een scholier met dyslexie volgens het experiment van \textcite{Nandhini2013}. De geassisteerde samenvatting is gebaseerd op onaangepaste zinnen afkomstig uit de oorspronkelijke tekst. Het ontwerp bij dit experiment haalt de belangrijkste zinnen onaangepast uit de oorspronkelijke tekst, herorganiseerd deze volgens de structuur van de oorspronkelijke tekst en presenteert deze aan de lezer. Al werd de logische structuur van de gepresenteerde zinnen in vraag gesteld, de leesbaarheid van de bevraagden was significant beter dan bij de oorspronkelijke tekst zonder een nadelig effect op de verstaanbaarheid van de bevraagden.

\subsubsection{Tekstweergave voor scholieren met dyslexie}

Onderzoeken wijzen uit hoe ontwikkelaars rekening kunnen houden met de visuele weergave van een applicatie. De leessnelheid en decodeertijd van scholieren met dyslexie vergroot wanneer het lettertype groter is dan 14pt bij digitale en uitgeprinte documenten. De decodeertijd bij 18 tot 26pt was significant sneller dan teksten met 14pt bij bevraagden met en zonder dyslexie. Daarnaast wordt een sans-serif, monospaced of roman lettertype zoals Arial, Helvetica of Verdana aangeraden. Lettertypes zoals OpenDys die ontworpen zijn voor scholieren met dyslexie hebben een neutraal effect op lezers met of zonder dyslexie. Cursieve lettertypes hebben een nadelig effect op het leestempo van zowel gewone scholieren als scholieren met dyslexie en wordt afgeraden \autocite{Rello2013b, Rello2015}.

\begin{figure}[H]
	\includegraphics{img/fonts-readability.png}
	\caption{Afbeelding uit \textcite{Rello2013b}. Verticaal wordt de gemiddelde mening van de bevraagden weergegeven. Horizontaal worden de lettertypes gerangschikt op gemiddelde leestijd van alle bevraagden. Dit onderzoek wijst uit dat Arial, CMU, Helvetica en Times de populaire keuzes zijn. Arial en CMU behoren hierbij tot de drie best scorende lettertypes rond gemiddeld leestempo.}
\end{figure}

\begin{figure}[H]
	\includegraphics{img/fonts-preference.png}
	\caption{Afbeelding uit \textcite{Rello2013b}.}
\end{figure}

Op basis van experimenten op oogfixaties gaven \textcite{Rello2015} de voor- en nadelen aan van verschillende visuele parameters. De bevraagden met dyslexie hadden bij de oorspronkelijke weergave een langere decodeertijd en tragere leessnelheid vergeleken met bevraagden zonder dyslexie. De bevraagden met dyslexie waren meer gevoelig aan de veranderingen van tekstweergave bij lettertype, character spacing, tekst en achtegrondkleur en tekst grijsschaal. Er zijn geen duidelijke aanbevelingen voor een grijze achtergrond of het gebruik van grijsschalen bij de bevraagden met dyslexie, maar licht grijs wordt voorgesteld zonder verschil in objectieve leesbaarheid. De bevraagden in het experiment van \textcite{Rello2015} kozen voor een kleurencombinatie van een zwart lettertype over een gele achtergrondkleur.

De achtergrondkleur aanpassen naar zachtgeel, -groen of lichtblauw heeft een verbeterd effect op scholieren met dyslexie in het lager en middelbaar onderwijs \autocite{Bezem2016, Rello2017}. \textcite{Anthony2020} haalt vijf ontwerpmethoden aan die beneficieel zijn voor mensen met dyslexie. Een minimalistisch ontwerp met duidelijke pictogrammen en statische inhoud helpen mensen met dyslexie bij het concentreren op de belangrijke informatie. Toegankelijke kleurschema's zijn noodzakelijk voor een aangename leeservaring. De eindgebruiker moet in staat zijn om zelf een kleurschema te kiezen.

Het bevoordelend effect van aanschouwelijkheid via afbeeldingen of schema's  wordt benadrukt in het onderzoek van \textcite{Rello2012b}. De visualisaties maken de tekstinhoud toegankelijk en hebben een significant effect op de leesbaarheid van een tekst. Bij de bevraagden was de fixatietijd lager en de leessnelheid sneller wanneer een tekst visuele schema's gebruikt. De impact op de begrijpelijkheid van een tekst verandert weinig tot niet.

\subsection{Samenvattend schema over aanpakken}

% todo

\subsection{Conclusie}

Scholieren met dyslexie in de derde graad van het middelbaar onderwijs kunnen moeite hebben bij het lezen van teksten. De ondersteuning kan op zowel syntactisch, lexicaal als visueel niveau gebeuren. Frequent woordgebruik, woordenschat korter dan zeven karakters, lettegrootte tussen 18 en 26 en een gepast lettertype -en stijl hebben een positief effect op deze doelgroep bij het lezen van teksten. Verbale parafrasering en het gebruik van grijstinten hebben een neutraal effect. Woordenschat langer dan zeven karakters, kleine lettergroottes en een cursief lettertype hebben een nadelig effect bij het lezen van teksten bij scholieren met dyslexie in de derde graad van het middelbaar onderwijs. Een adaptieve en gepersonaliseerde aanpak voor deze doelgroep is nodig.

\section{Wetenschappelijke artikelen}

% TODO Wetenschappelijke artikelen hebben een uniform formaat genaamd IMRAD. 

Wetenschappelijke artikelen zijn een communicatiemiddel voor en door onderzoekers en wetenschappers. Deze artikelen worden echter ingezet als leermiddel voor jongeren in de laatste graad van het middelbaar onderwijs, alsook het hoger onderwijs en verdere studies. Wetenschappelijke artikelen kennen een uniform formaat qua structuur, genaamd IMRAD. De gebruikte syntax en lexicale woordenschat verschilt echter. Deze sectie verduidelijkt de verschillende uitdagingen dat het lezen van een wetenschappelijk artikel met zich meebrent, alsook hoe docenten dit kunnen aanpakken in de derde graad van het middelbaar onderwijs. In deze sectie wordt de volgende onderzoeksvraag beantwoordt: "Wat zijn de specifieke kenmerken van wetenschappelijke artikelen?"

\subsection{Wetenschappelijke geletterdheid in Vlaanderen}

De \textit{Programme for International Student Assessment} of PISA-test\footnote{https://www.pisa.ugent.be/resultaten/pisa-2022} van OESO is een driejaarlijkse test bij vijftienjarigen. Deze test bestudeert de wiskundige en wetenschappelijke geletterdheid\footnote{“Het beheersen van vaardigheden om als kritische burger om te gaan met wetenschappelijke onderwerpen en ideeën.” volgens \textcite{DeMeyer2019}} van 15-jarigen in geïndustrialiseerde landen, wat op ongeveer 79 landen komt. 4822 Vlaamse scholieren van vijftien jaar namen deel aan deze test. Dit onderzoek baseert op de cijfers van 2018, aangezien de testen van 2022 pas eind 2023 worden gepresenteerd. Deze testen houden echter geen rekening met leer- en leesstoornissen, waaronder dyslexie en dyscalculie. Het is echter nodig om deze cijfers mee te geven, om een idee te geven waar de doelgroep staat voor de start van de derde graad middelbaar onderwijs. 

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=\linewidth]{img/oeso-graphic-pisa-trend-samenvatting.png}
	\end{center}
	\caption{Figuur van \textcite{DeMeyer2019}. Op alle PISA-domeinen scoren de Vlaamse vijftienjarigen in ASO, BSO en TSO significant slechter dan de eerste metingen. \textcite{DeMeyer2019} noemen dit een achteruitgang in alle onderwijsvormen.}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=\linewidth]{img/oeso-graphic-leesplezier.png}
	\end{center}
	\caption{Figuur van \textcite{DeMeyer2019}. Het leesplezier van Vlaamse 15-jarigen. Zij uitten zich uiterst negatief op stellingen over leesplezier. Volgens de enquète vond de helft van de scholieren begrijpend lezen enkel tijdsverlies en slechts 17\% gaf aan dat lezen één van hun favoriete hobby's is. Er is wel een significant verschil tussen de mening van jongens en meisjes, waar jongens negatiever antwoorden op lezen.}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=5cm]{img/oeso-graphic-wetenschappelijke-geletterdheid-2.png}
	\end{center}
	\caption{Figuur van \textcite{DeMeyer2019}. De wetenschappelijke geletterdheid bij vijftienjarigen op internationaal niveau. Vlaanderen scoort significant slechter dan acht deelnemende landen.}
\end{figure}


\subsection{Trends rond wetenschappelijke artikelen}
% inleiding over het formaat van teksten

De leesgraad van wetenschappelijke teksten volgt al sinds de tweede helft van de twintigste eeuw een stijgende trend \autocite{Hayes1992}. Meerdere onderzoeken in de voorbije tien jaar besluiten dat de complexe woordenschat en zinsbouw deze wetenschappelijke artikelen ontoegankelijk maakt voor doelgroepen naast onderzoekers \autocite{Ball2017, PlavenSigray2017, Jones2019}. 

% \textcite{Ball2017}

\textcite{PlavenSigray2017} onderzoekt de verschillende trends waarom wetenschappelijke artikelen alsmaar moeilijker te lezen worden. De relatie tussen de leesbaarheid van een abstract werd vergeleken met het jaar waarin het wetenschappelijk artikel werd gepubliceerd. De \textit{Flesch-Reading-Ease} of FRE score werd gebruikt om de leesgraad van een wetenschappelijk artikel te beoordelen. Om te bevestigen dat de relatie tussen de complexiteit van een abstract overeenstemt met die van de volledige tekstinhoud, werden er vergelijkingen gemaakt met zes verschillende wetenschappelijke journalen. De overeenkomst tussen de leesgraad van het abstract en de overige tekstinhoud in een wetenschappelijk artikel werd eerder bevestigd door \textcite{Dronberger1975}. Dat onderzoek benadrukte dat een abstract complexer werd geschreven, vergeleken met de rest van een wetenschappelijk artikel.

\begin{figure}[H]
	\includegraphics[width=\linewidth]{img/fre-ndc.png}
	\caption{Afbeelding uit \textcite{PlavenSigray2017}. Links wordt de evolutie per FRE-score getoond. Hoe hoger de score, hoe hoger de gemiddelde complexiteit van een tekst. Rechts wordt de evolutie volgens de NDC-score getoond. Hoe hoger de score, hoe lager de gemiddelde complexiteit van een tekst. Het onderzoek schat dat nu een kwart van alle wetenschappelijke artikelen gebruik maken van Engels op het niveau van een masterstudent, ofwel een FRE onder nul.}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=\linewidth]{img/ndc-number-of-authors.png}
	\caption{Afbeelding uit \textcite{PlavenSigray2017}. Horizontaal worden het aantal auteurs per wetenschappelijk artikel aangeduidt. Verticaal wordt de gemiddelde NDC-score weergegeven. HOe hoger de NDC-score, hoe hoger de vereiste leesgraad om de tekst te kunnen lezen.}
\end{figure}

De hoge leesgraad van wetenschappelijke artikelen beperkt volgens \textcite{PlavenSigray2017} twee aspecten: de toegankelijkheid en de herproduceerbaarheid.

\subsubsection{Toegankelijkheid}

Bronnen worden minder toegankelijk tot het algemene publiek. Wetenschappelijke artikels worden enkel toegankelijk tot mensen die wetenschappelijk geletterd zijn of een leesgraad daarboven hebben. \textcite{Ennals2010} zegt dat wetenschap ons de nauwkeurige kennis moet geven, omdat mensen zich zorgen maken dat moderne samenlevingen minder streng worden met feitelijke waarheden en deze vervangen door \textit{post-facts} die waar lijken te klinken. Wetenschappelijke inhoud moet volgens hem zo toegankelijk mogelijk worden gemaakt, zodat een zo breed mogelijk publiek de kern begrijpt.

\subsubsection{Reproduceerbaarheid}

Onbegrijpelijke en ontoegankelijke zinsstructuren hinderen ook vakexperten. Het herschrijven van abstracten vergroot de begrijpbaarheid bij academici volgens \textcite{Hartley1999, Snow2010}. De wetenschap bouwt voort op betrouwbare ontdekkingen en het reproduceren van experimenten is een belangrijke manier voor wetenschappers om vertrouwen te krijgen in hun besluiten. De inhoud van het wetenschappelijke artikel moet gecontroleerd kunnen worden. Voor de reproduceerbaarheid van onderzoeken is het volgens \textcite{McNutt2014} belangrijk dat de methodologie en resultaten begrijpelijk zijn. Een lage leesgraad en duidelijke zinsbouw beperkt het aantal misopvattingen en verwarringen bij onderzoekers. Experimenten uit \textcite{Hubbard2017} wijzen erop dat de bevraagde onderzoekers zowel de methodologie als de resultaten de twee componenten vonden die een hoge leesgraad vergden. 

% https://psychology.ucsd.edu/undergraduate-program/undergraduate-resources/academic-writing-resources/writing-research-papers/research-paper-structure.html#:~:text=A%20complete%20research%20paper%20in,%2C%20Discussion%2C%20and%20References%20sections.&text=Many%20will%20also%20contain%20Figures,have%20an%20Appendix%20or%20Appendices.

\subsection{Woordenschat en vakjargon}

Complexe processen, methoden en ideeën worden in wetenschappelijke artikelen verwoord met gebruik van grammatische embeddings, doordachte en abstracte woordenschat en naamwoordstijlen. De kenmerken van academische taal variëren afhankelijk van de discipline, het onderwerp en de vorm, maar er zijn gemeenschappelijke kenmerken die wetenschappelijke taal onderscheiden van taal van een lagere leesgraad. \autocite{Ennals2010, Snow2010}

Wetenschappelijke artikelen dienen volgens \textcite{PlavenSigray2017} in eerste instantie als uitwisseling van kennis tussen vakexperten. Daarnaast moet er rekening worden gehouden met de lengte wat een nadelig effect heeft op de beschikbare uitleg voor deze terminologie.

\textcite{Snow2010} beklemtoont dat deze zaken in het onderwijs moeten betrokken worden. STEM-vakken of vakken waar deze wetenschappelijke artikelen aan bod komen, moeten stil staan bij voldoende uitleg over de toegepaste grammatica en woordenschat voorzien tijdens de lessen.

\begin{figure}[H]
	\includegraphics[width=5cm]{img/fre-fog-per-sector.png}
	\caption{Afbeelding van \textcite{Murdos2014} Volgens deze grafiek scoren de wetenschappelijke artikels rond fysica gemiddeld het best op de FRE-score. Al scoren de wetenschappelijke artikels rond microbiologie gemiddeld het zwakst op de FRE-score, ze scoren gemiddeld beter op de FOG-score.}
\end{figure}

\subsection{Aanpak voor het lezen van wetenschappelijke artikelen}

Als reactie op een satirisch artikel van \textcite{Ruben2016}, bracht \textcite{Pain2016} het onderwerp bij wetenschappers aan het licht om zo verschillende tactieken te verzamelen om wetenschappelijke artikelen te begrijpen. Sommige wetenschappers zoeken direct onbekende woorden op of raadplegen extra informatiebronnen, terwijl andere wetenschappers hoofdstukken overslaan. Het is belangrijk om een balans te vinden tussen het begrijpen van de inhoud en het efficiënt gebruiken van de tijd. Sommige wetenschappers geven toe dat ze het soms opgeven als het te moeilijk wordt of als de literatuur net niet relevant is voor hun onderzoek. {Pain2016} bouwt verder op deze adviezen en bouwt een stappenplan op hoe (startende) lezers wetenschappelijke artikelen kunnen aanpakken.

\begin{enumerate}
	\item Lees de samenvatting en conclusie om een idee te krijgen van het doel en de uitkomst van het onderzoek.
	\item De figuren en tabellen in het artikel zijn cruciaal omdat deze een snelle en duidelijke weergave geven van de belangrijkste bevindingen.
	\item Focus op de nodige informatie en ga vervolgens terug om de technische details te begrijpen.
	\item Let op de beperkingen en interpretatie van de resultaten. Controleer of de onderzoeksvraag en -methode adequaat zijn.
	\item Controleer of de referenties relevant zijn en zoek naar andere artikelen over hetzelfde onderwerp.
	\item Overweeg welke stukken prikkelend, nieuw en relevant zijn voor eigen onderzoeksvragen en hypotheses.
	\item Maak aantekeningen en schrijf tijdens het lezen, zodat de lezer actief betrokken is bij het lezen van het artikel.
\end{enumerate}

Wetenschappelijke artikelen vereisen een selectieve leesstijl volgens de bevraagde onderzoekers in \textcite{Hubbard2017}. Bepaalde delen van een artikel worden geprioriteerd, zoals de abstract. De abstract en de discussie bepaalt of het artikel de moeite waard is voor de onderzoeker om te lezen. Sommige bevraagden adviseren om de methodologie te negeren en direct over te gaan naar de discussie of resultaten, terwijl andere onderzoekers aanbevelen om eerst de hypothesen van een artikel te achterhalen. Een artikel wordt nadrukkelijk meermaals gelezen, waarbij de lezer steeds in meer detail leest. Kritisch lezen is belangrijk, waarbij de conclusies worden beoordeeld en de data voor zichzelf spreekt. Er is geen standaardaanpak volgens \textcite{Hubbard2017}, maar de bevraagde onderzoekers bevelen tactieken aan zoals selectief, kritisch en met een specifiek doel voor ogen lezen.

\subsection{Conclusie}

Het lezen van wetenschappelijke artikelen kan overweldigend zijn, vooral bij onbekende vakgebieden, lange artikelen en technisch vakjargon. Nieuwe versies van een wetenschappelijk artikel moeten meer doelgroepen toelaten om over voldoende achtergrondinformatie te beschikken. De gebruikte syntax, woordenschat en compact formaat sluiten aan bij de mogelijke struikelblokken voor ee scholier met dyslexie in de derde graad van het middelbaar onderwijs. 

\section{Tekstvereenvoudiging}

Vereenvoudigde teksten worden geschreven om leerlingen te ondersteunen bij het begrijpen van specifieke taalkenmerken, het beperken van de hoeveelheid nieuwe woordenschat en het beheersen van de complexiteit van de tekst. Deskundigen zijn van mening dat vereenvoudigde teksten nuttig zijn voor startende en gevorderde lezers \autocite{Louwerse2007}. Samenvattingen van teksten bieden een oplossing om een snel zicht te krijgen over (lange) documenten, of om de kerninhoud van een tekst die al gelezen is opnieuw te prikkelen \autocite{McCombes2022}. Vereenvoudigen kan handmatig door de docent gebeuren, maar recente technologische ontwikkelingen laten de automatisatie van dit proces toe met een gelijkwaardig eindresultaat. Deze sectie beantwoordt de volgende onderzoeksvraag: "Welke aanpakken zijn er voor geautomatiseerde tekstvereenvoudiging?". Aansluitend hierop wordt de volgende subvraag beantwoordt: "Hoe worden teksten handmatig vereenvoudigd voor scholieren met dyslexie?"

\subsection{Manuele tekstvereenvoudiging}

Wetenschappelijke artikelen moeten informatie begrijpelijk weergeven voor een breed publiek, waaronder de scholieren die deze artikelen voorgeschoteld krijgen. Teksten vereenvoudigen heeft volgens \textcite{Crossley2012} drie algemene doelen, namelijk het illustreren van een specifiek taalkenmerk, ongekende woordenschat voor een doelgroep aan te passen en de hoeveelheid gegeven informatie onder controle te houden. \textcite{Crossley2012} wijst op twee soorten van handmatige tekstvereenvoudiging. Intuïtieve tekstvereenvoudiging is een methode waar de auteur die de transformatie uitvoert, wordt beïnvloed door persoonlijke vermoedens over wat een tekst beter leesbaar maakt. Structurele vereenvoudiging daarentegen vervangt vermoedens door het gebruik van woordenlijsten en leesbaarheidsformules zoals Flesch Reading Ease (FRE), Gunning Fog (FOG), SMOG-Cro (SMOG) en de Coleman-Liau Index (CLI).

% Er zijn gekende technieken dat leerkrachten kunnen toepassen om artikels te vereenvoudigen. \textcite{Dubay2004} haalt vier categorieën en principes aan die bijdragen tot een eenvoudigere tekst. (...) bewijst dat een eenvoudigere tekst aanleunt op vier pijlers, namelijk de lengte en het formaat, de woordenschat, grammatica en 

\subsubsection{Lengte en formaat}

De leesgraad van de woordenschat moet overeenstemmen met de syntactische leesgraad. vereenvoudigd. Vervolgens kan tekst naar een ander formaat worden omgezet, zoals \textit{post-itnotes}, \textit{postcards} of emails, om het begrijpelijker te maken. Dit wordt vooral ingezet in het lager onderwijs. De schrijf- en vertelstijl moet consistent blijven in het nieuwe formaat. Ten slotte moeten verwijswoorden worden aangepast om de tekst toegankelijker te maken voor meertalige lezers. Bijvoorbeeld door eenvoudige verwijswoorden zoals 'zij' of namen te gebruiken \autocite{Rijkhoff2022}. 

Een samenvatting verkort de lengte van een tekst. Kernzinnen en trefwoorden worden eerst in een tekst gemarkeerd en vervolgens op een nieuw blad geschreven. De kernzinnen worden achterhaald door woord- en zoektermfrequentie en anderzijds door het stellen van algemene vragen over het artikel. Trefwoorden achterhalen gebeurt gelijkaardig en deze zijn regelmatig af te leiden uit de inhoudstafel en titels. Voor deze twee methoden moet de persoon die een samenvatting maakt al vooraf de tekst meermaals gelezen hebben. Een alternatief op markeren is het parafraseren van de tekst. De geparafraseerde tekst blijft semantisch gelijk, maar het neemt een andere syntax, structuur en woordenschat aan \autocite{Rijkhoff2022}.

Volgens \textcite{Hollenkamp2020, McCombes2022} moet de samenvatting van een wetenschappelijk artikel altijd de volgende drie vragen kunnen beantwoorden: 

\begin{itemize}
	\item Waarom werd het onderzoek verricht? Welke achtergrondinformatie en context nam de onderzoeker in acht. Daarnaast moeten de geformuleerde hypotheses aan bod komen.
	\item Wat werd er geëxperimenteerd? Alle gebruikte methoden en resultaten moeten in een samenvatting terug te vinden zijn en enkel de noodzakelijke kwalitatieve waarden mogen aan bod komen.
	\item Welke conclusies trekken de onderzoeker(s) uit het onderzoek? De implicaties en beperkingen tijdens het onderzoek, alsook de aanradingen moeten in de samenvattingen aan bod komen.
\end{itemize}

\subsubsection{Woordenschat}

Moeilijke woorden kunnen op twee manieren beperkt worden. Eerst moet een tekst op maat zijn van het doelpubliek. De gehanteerde (vak)termen moeten begrijpelijk zijn voor iedereen binnen het doelpubliek. Deze leesgraad en voorkennis wisselt sterk af bij scholieren in de laatste graad middelbaar onderwijs. Als het niet mogelijk is om eenvoudigere synoniemen te gebruiken, dan komt het van pas om de woorden uit te leggen. Dit hoeft enkel te gebeuren bij de eerste keer dat deze woorden voorkomen \autocite{Bosmans2022a, Bosmans2022b}. \textcite{Case2008} haalt aan om homoniemen en homofonen te vervangen. % TODO aanvullen

\subsubsection{Grammatica}

Mensen proberen bij het schrijven wel vaak om iets kort en bondig te schrijven, al schrijven veel mensen nog steeds volgens hun gedachten. Dit leidt tot een omslachtige schrijfstijl en dit heeft een nadelig effect op de grammatica in een tekst. Tangconstructies, lange zinsaanlopen en voorzetselketens zijn vaak voorkomende boosdoeners volgens \textcite{Bosmans2022c}. Tangconstructies zijn zinsstructuren waarbij een bijwoordelijke bepaling of bijzin tussen het onderwerp en de persoonsvorm van een zin wordt geplaatst. Tangconstructies kunnen minder zwaar worden gemaakt door de twee grijpers van de tang dichter bij elkaar te brengen of door lange zinnen te splitsen. Aanvullende informatie kan beter kort worden gehouden en vooraan of achteraan in de zin worden geplaatst om onderbrekingen te voorkomen. \textcite{Rijnvis2020, Bosmans2022c} halen drie aanpakken aan om tangconstructies te vermijden:

\begin{itemize}
	\item De bijzin naar het begin of het einde van een zin plaatsen.
	\item De zin splitsen in twee kortere zinnen.
	\item Het onderwerp en de persoonsvorm dichter bij elkaar plaatsen door minder informatie tussen hen in te plaatsen.
\end{itemize}

Een lange zinsaanloop kan worden verkort om de aandacht van de lezer niet op de proef te stellen. Voorzetselketens kunnen worden vermeden door informatie over verschillende zinnen te verdelen. Voorzetseluitdrukkingen worden best vervangen door gewone voorzetsels \autocite{Bosmans2022c}.

\subsubsection{Pedagogische en onderwijsgerelateerde kritieken}

Al besluit het onderzoek van \textcite{Crossley2012} dat tekstvereenvoudiging een bevorderend effect heeft voor scholieren met afwisselende leesgraden, het onderzoek beklemtoont de unieke aanpakken per docent. Iedere docent heeft een eigen procedure om een vereenvoudigde tekst op maat te kunnen schrijven.

\subsection{Natural Language Processing}

Tekstvereenvoudiging is het proces waarin het technisch leesniveau en/of woordgebruik van een geschreven tekst wordt verminderd. Het resultaat van deze fase is een tekst die korter en aangenamer is, zonder het verlies van de kerninhoud. Binnen machinaal leren (ML) is tekstvereenvoudiging een zijtak van natuurlijke taalverwerking. \autocite{Siddharthan2006} Volgens \autocite{Siddharthan2014} bestaat een complete en geautomatiseerde tekstvereenvoudiging uit vier verschillende vereenvoudigingen. 

\textit{Natural Language Processing} (NLP) of natuurlijke taalverwerking is een brede term die zich richt op het verwerken en analyseren van menselijke taal door computers \autocite{Eisenstein2019}. NLP omvat verschillende technieken, zoals tekstanalyse, taalherkenning en -generatie, spraakherkenning en -synthese, en semantische analyse. Computers zijn in staat om op een menselijke manier te communiceren en begrijpen wat er wordt gezegd. De volgende begrippen worden aangehaald in \textcite{Sohom2019, Eisenstein2019} en zijn fundamenteel voor de concepten die volgen.

\subsubsection{Tokenisation}

Tokenisatie} splitst de stam of basisvorm van woorden in een tekst. Gebruikelijk zetten ontwikkelaars deze stap in om een woordenschat voor een taalmodel op te bouwen. Bij tokenisatie wordt er geen rekening gehouden met de betekenis achter ieder woord. Tokeniseren kan volgens \textcite{Menzli2023} op vier manieren:

\begin{itemize}
	\item Word-level tokenisation of WTL splitst de tekst op per woord.
	\item Character-level tokenisation of CLT splitst de tekst per karakter. 'Slimmer' wordt s-l-i-m-m-e-r. Deze vorm achterhaalt de semantiek van een tekst beter en laat de het. Nadelig hebben de karakters op zich weinig betekenis, alsook maakt deze vorm de inputlengte groter. \autocite{Ribeiro2018}
	\item Subword-level tokenisation splitst de tekst op in stukken op basis van de woordfrequentie. Veelvoorkomende woorden worden hele woorden getokeniseerd, terwijl zeldzamere woorden opgesplitst worden in kleinere stukken die kunnen worden gebruikt. De rest van de woorden in de relevante dataset te creëren. Dit biedt een voordeel ten opzichte van word-level tokenisation omdat het een balans biedt tussen WLT en CLT \autocite{Iredale2022}.
	\item Sentence tokenization splitst de tekst op per zin. \textcite{Fardeen2021} haalt aan dat de tokenizer ineffectief is tegen afkortingen, maar dit is afhankelijk volgens de gebruikte dataset. 
\end{itemize}

\begin{table}[h!]
	\centering
	\begin{tabular}{|l|c|c|c|}
		\hline
		Feature & spaCy & NLTK & Gensim \\
		\hline
		Word-level & X & X & X \\
		Character-Level & X & X &  \\
		Subword-Level & X &  & X \\
		Sentence-level & X & X & X \\
		\hline
	\end{tabular}
	\caption{Vergelijking van methodes voor tokenisatie met Spacy, nltk, en gensim.}
	\label{tab:nlp-features}
\end{table}

\subsubsection{Lemmatiseren en parsen}

Lemmatiseren in NLP bouwt verder op \textit{stemming}, maar de betekenis van ieder woord wordt in acht genomen. Voor het lemmatiseren bestaan er Nederlandstalige modellen, waaronder JohnSnow\footnote{https://nlp.johnsnowlabs.com/2020/05/03/lemma\_nl.html}. Bij \textbf{omgekeerd lemmatiseren} wordt er een afgeleide achterhaald vanuit de stam. Bijvoorbeeld voor het werkwoord 'zijn' zou dit 'is', 'was' of 'ben' zijn. Voor zelfstandige naamwoorden, zoals 'hond', is dit dan enkelvoud of meervoud \autocite{Eisenstein2019}.

Bij een \textbf{parsing}-fase wordt er een label aan ieder woord of zinsdeel toegekend. Voorbeelden van labels zijn zelfstandig naamwoord, bijwoord, werkwoord, bijzin of stopwoord. Het herkennen van zinsdelen wordt \textit{chunking} genoemd. Parsing heeft een dubbelzinnigheidsprobleem, want een 'plant' staat niet gelijk aan de vervoeging van werkwoord 'planten' \autocite{Eisenstein2019}.

% Sentimentanalyse is het achterhalen van de mening of gevoelens uit een tekst. de stemming of mening van een tekst te achterhalen op basis van het onderwerp. is een tak van Natural Language Understanding of NLU die de stemming, mening of gevoelens van de schrijver of spreker probeert te achterhalen ten opzichte van het onderwerp. % Dit kan lastig zijn omdat niet elke tekst een duidelijk positief of negatief sentiment heeft. 

\subsubsection{Sequence labeling en part-of-speech tagging}

Een machine moet de betekenis achter ieder token kunnen vatten. Hier komt \textit{sequence labeling} aan de pas volgens \textcite{Eisenstein2019}. Elk woord in een tekst wordt gekoppeld aan een \textit{Part-of-Speech} (PoS) of \textit{Named-Entity-Recognition} (NER) label. Deze NLP-fase achterhaalt de structuur van een tekst. PoS-tagging richt zich op grammaticale categorieën van woorden, terwijl NER-labeling instaat voor het herkennen van specifieke entiteiten in een tekst. 

Bij PoS-tagging worden de woorden in een zin geanalyseerd. Elk woord wordt gekoppeld aan een grammaticale categorie, zoals een zelfstandig naamwoord, werkwoord, bijvoeglijk naamwoord of bijwoord. \textit{PoS-tagging} helpt bij het achterhalen van de syntactische structuur van een zin. Deze taak komt van pas bij parsing en machinevertaling. \textit{PoS-tagging} wordt aanschouwelijk gemaakt op \ref{fig:pos}

Namen van personen, organisaties en locaties worden herkend en geclassificeerd met NER-labeling. Met NER-labeling wordt volgens \textcite{Jurafsky2014} specifieke informatie uit tekst gehaald, zoals het identificeren van de namen van personen, plaatsen of bedrijven die in nieuwsartikelen worden genoemd, of het extraheren van belangrijke data of getallen uit financiële rapporten. Dit wordt aanschouwelijk gemaakt \ref{fig:ner}. \textcite{Li2018} benoemt vier vormen voor NER-labeling:

\begin{itemize}
		\item \textit{Dictionary-based NER labeling} gebruikt vooraf gedefinieerde woordenboeken die de namen van de entiteiten bevatten. Het vergelijkt de woorden in de tekst met de woordenboeken en labelt ze als ze overeenkomen.
		\item \textit{Rule-based NER labeling} gebruikt vooraf gedefinieerde regels die gebaseerd zijn op syntactische of semantische patronen om de entiteiten te identificeren. Het past de regels toe op de tekst en labelt de woorden die aan de regels voldoen.
		\item \textit{Machine learning-based NER labeling} gebruikt statistische modellen zoals Hidden Markov Model (HMM) of Conditional Random Field (CRF) om te leren van gelabelde trainingsgegevens hoe ze entiteiten kunnen herkennen. Het gebruikt kenmerken zoals het woord zelf, omliggende PoS-labels en het hoofdlettergebruik om te beslissen welk label aan elk woord moet worden toegekend.
		\item Deep learning-based NER labeling gebruikt neurale netwerken zoals recurrent neural network (RNN) of convolutional neural network (CNN) om te leren van ongelabelde of gedeeltelijk gelabelde trainingsgegevens hoe ze entiteiten kunnen herkennen. Het gebruikt woordvectoren en niet-lineaire representaties om complexe relaties tussen woorden te modelleren.
\end{itemize}

% Ten slotte halen \textcite{Li2018} Python-bibliotheken aan om een pipeline voor NER-labeling mogelijk te maken. Spacy heeft deze functie ingebouwd. Standford NER-tagger is een tool die samen met het NLTK-pakket werkt.

\textcite{Poel2008} onderzocht \textit{PoS-tagging} met een neuraal netwerk voor Nederlandstalige teksten. Het model behaalde een nauwkeurigheid van 97,88\% voor bekende woorden en 41,67\% voor onbekende woorden. Het model gebruikte de Corpus Gesproken Nederlands (CGN) als trainingsdata.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=10cm]{img/poslabeling.png}
	\end{center}
	\caption{Voorbeeld van PoS-labeling op de Engelstalige zin "She sells seashells on the seashore". Afbeelding van \textcite{Bilisci2021} }
	\label{fig:pos}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=10cm]{img/nerlabeling.jpg}
	\end{center}
	\caption{Voorbeeld van sequence labeling op de Engelstalige zin "She sells seashells on the seashore". Afbeelding van \textcite{Bilisci2021} }
	\label{fig:ner}
\end{figure}


\subsubsection{Prompt engineering}

Large Language Models of LLM's zoals GPT-3, BERT en T5 genereren tekst en karakters op basis van de probabiliteit of waarschijnlijke uitkomst van een gegeven input. Deze modellen maken gebruik van een neuraal netwerk om patronen in de input te herkennen en deze patronen te gebruiken om voorspellingen te doen over de uitvoer \autocite{Liu2020}. Iedereen kan volgens \textcite{McFarland2023} een input of prompt schrijven. Deze tools zoals chatbots zijn ontworpen om zo intuïtief mogelijk te zijn voor een algemeen doelpubliek. Prompt engineering is een steeds belangrijkere vaardigheid die nodig is om effectief te communiceren met LLM’s, zoals ChatGPT \autocite{Harwell2023}.

\begin{figure}
	\begin{center}
			\includegraphics[width=8cm]{img/prompt-engineering-medium.png}
	\end{center}
	\caption{Afbeelding uit \textcite{McFarland2023}. Een illustratie over de werking en begeleiding van prompt engineering bij een taalmodel. }
\end{figure}

Deze prompts werken volgens \textcite{Liu2020} op dezelfde manier als bij mensen en kunnen worden gebruikt om werk te produceren dat is aangepast aan het doel. Text is momenteel het belangrijkste middel van communicatie tussen mens en AI.Een concrete en geoptimaliseerde prompt omvat een concrete scope, duidelijke vraagstelling, specifieke sleutelwoorden, de context en ten slotte gepersonaliseerde keuzes \autocite{McFarland2023}. Bij een zoekopdracht moeten voldoende parameters in de prompt worden opgenomen, zoals het type. Zo niet zal het model te algemeen blijven en mogelijks afwijken van de intentie van de gebruiker. Effectieve AI prompt engineering leidt tot hoogwaardige trainingsgegevens die het AI-model in staat stellen om nauwkeurige voorspellingen en beslissingen te maken \autocite{Liu2020}.

Prompt patterns is samen met prompt engineering naar boven gekomen en is vergelijkbaar met software patterns. Deze patronen zijn herbruikbare oplossingen voor veelvoorkomende problemen in een bepaalde context, waaronder vooral de interactie bij het werken met LLM's. \textcite{White2023} haalt vijf verschillende prompt patterns aan.

\begin{itemize}
\item	Intent-prompts waarbij een LLM een instructie krijgt met een specfiek verwacht antwoord.
\item	Restriction-prompts die het antwoord van een LLM inperkt. Deze pattern is noodzakelijk om een LLM binnen de lijnen te houden.
\item 	Contextualization-prompts verzekeren dat de output van een LLM relevant is. Een context wordt aan de LLM meegegeven.
\item	Expansion/reduction-prompts genereren een output dat beknopt is, maar met voldoende details. 
\end{itemize}

\subsubsection{Traditional en contextual word embeddings}

NLP-systemen en machines moeten woorden, grammatica en nuancering kunnen begrijpen. Embeddings transformeren woorden tot een numerieke representatie, waarop een machine deze representaties kan aanleren om nadien tekst te verwerken. Traditionele word embeddings bouwen een woordenschat op met unieke woorden. De betekenis achter ieder woord wordt niet opgevolgd. Voorbeelden van traditionele word embeddings zijn Word2Vec en Glove.

Contextual word embeddings lossen dit probleem op en houden rekening met de context waarin een woord wordt gebruikt. ELMo en BERT zijn voorbeelden van een model voor contextuele embedding. Deze vorm houdt de semantiek bij van een woord in een bepaalde context en is noodzakelijk wanneer een machine polysemantische woorden in een tekst moet begrijpen. Contextuele word embeddings worden vergkregen uit transformer-gebaseerde modellen. Ze worden verkregen door een volledige zin door te geven aan een pre-trained model.

BERT is een meertalig LLM, getraind op 110 miljoen parameters uit 104 verschillende talen\footnote{https://github.com/google-research/bert/blob/master/multilingual.md#list-of-languages}, waaronder Nederlands. Dit taalmodel kent alternatieven die verderbouwen op het oorspronkelijke BERT-model. Voor de Nederlandse taal zijn er twee, namelijk RobBERT en BERTje. Volgens (..) is RobBERT de krachtigste van de twee modellen, waar BERTje compacter is. Vervolgens bepaalt de \textit{Substitution Ranking} of SR-stap welke vervanging de beste is uit een set van kandidaten. SR gebeurt door gegenereerde substituties op basis van relevantie te rangschikken.

\section{De verschillende soorten tekstvereenvoudiging}

Tekstvereenvoudiging bestaat volgens \textcite{Siddharthan2014} uit vier soorten transformaties: lexicale, syntactische en semantische vereenvoudiging en samenvatten.

\begin{figure}[H]
	\begin{center}
			\includegraphics[width=5cm]{img/voorbeeld-manuele-vereenvoudiging.png}
	\end{center}
	\caption{Voorbeeld van tekstvereenvoudiging. Oorspronkelijke tekst uit Historia 5 bron toe te voegen}
\end{figure}

\subsection{Lexicale vereenvoudiging}

Bij \textit{lexical simplification} (LS) of lexicale vereenvoudiging worden complexe woorden vervangen door eenvoudigere synoniemen. Bijvoorbeeld, het woord 'adhesief' wordt vervangen door 'klevend'. \textcite{Kandula2010} haalt twee manieren aan om lexicale vereenvoudiging mogelijk te maken, namelijk het vervangen door een synoniem en het aanmaken of genereren van extra uitleg. De zinsstructuur verandert niet en er is garantie dat de kerninhoud en benadrukking in een tekst identiek blijft. Het doel van lexicale vereenvoudiging is om de moeilijkheidsgraad van de woordenschat in een zin of tekst te verlagen. 

% Dit is, volgens het aantal onderzoeken, de meest gekende vorm van vereenvoudiging en een noodzakelijke stap bij het vereenvoudigen van een tekst. Voor prevalente domeinen, zoals de onderwijs-, medische en financiële sector, zijn er onderzoeken vrij beschikbaar. 

\subsubsection{Complex Word Identification}

\textit{Complex word identification} of CWI is een gesuperviseerde NLP-taak. In een pipeline voor lexicale tekstvereenvoudiging is CWI de eerste stap. Moeilijke woorden of \textit{multi-word expressions} (MWE) in een tekst worden achterhaald  \autocite{Shardlow2013, Gooding2019}. Na CWI kan LS gebruikt worden om deze woorden te vervangen door eenvoudigere synoniemen of om verdere elaboratie te voorzien met behulp van voorbeelden of definities \autocite{Zeng2005, Kandula2010}. CWI is volgens \textcite{Shardlow2013} een cruciale stap, want een lage \textit{recall} van dit component zal een uitvoertekst geven waar moeilijke woorden niet worden vereenvoudigd. Het model zal moeilijke woorden laten staan.

\subsubsection{Substitutiegeneratie en ranking}

Substitutiegeneratie wordt gedaan door synoniemen te zoeken voor een doelwoord in lexicale databanken zoals WordNet, BERT, context2vec, nPIC of OOC. 

\begin{figure}[H]
	\includegraphics{img/lexical-simplification-pipeline.png}
	\caption{Afbeelding van \textcite{Althunayyan2021}. Deze pipeline wordt in meerdere onderzoeken rond lexicale vereenvoudiging toegepast, zoals \textcite{Paetzold2016, Bingel2018, Bulte2018}}
\end{figure}

% todo FrenLys

\subsection{Syntactische vereenvoudiging}

Syntactische vereenvoudiging verlaagt de leesgraad en complexiteit van een zin door de grammatica en zinsstructuur van een tekst aan te passen. Twee afzonderlijke zinnen kunnen samengevoegd worden tot één eenvoudigere zin. Zo worden complexe of onduidelijke zinsconstructies verminderd, terwijl de inhoud en betekenis van de tekst behouden blijft. Dergelijke transformaties zijn het vereenvoudigen van de syntax of door de zinnen korter te maken. Zinnen worden toegankelijker, zonder de kerninhoud of relevante inhoud te verliezen.

\textcite{Kandula2010} ontwikkelde een toepassing om medische informatie bij beschikbare biomedische bronnen te vereenvoudigen. Dit model verlaagt de leesgraad door syntactische vereenvoudiging op zinniveau toe te passen. Zinnen met meer dan tien woorden worden in het onderzoek als complex beschouwd en worden vereenvoudigd door drie modules. Na deze transformatie kan de oorspronkelijke zin ongewijzigd worden behouden of vervangen worden door twee of meer kortere zinnen. De architectuur van dit model omvat drie onderdelen: een \textit{Part of Speech (PoS) Tagger}, een \textit{Grammar Simplifier} en een \textit{Output Validator}. 

\begin{itemize}
	\item Voor de \textit{PoS Tagger}-fase gebruikten \textcite{Kandula2010} beschikbare functies uit het open-source pakket OpenNLP\footnote{https://opennlp.apache.org/}.
	\item De \textit{Grammar Simplifier} module splitst de lange zin in twee of meer kortere zinnen door POS-patronen te identificeren en een set transformatieregels toe te passen.
	\item De \textit{Output Validator} module controleert de output van de Grammar Simplifier op grammatica en leesbaarheid.
\end{itemize}  

% todo probleemstelling van lexicaal vereenvoudigen

\subsection{Conceptuele of semantische vereenvoudiging}

Conceptuele tekstvereenvoudiging deelt complexe concepten op in eenvoudigere delen, past duidelijke en bondige taal toe en vermijdt technische jargon en abstracte uitdrukkingen. Er wordt meer uitleg of voorbeelden gegeven, of dat niet-relevante delen van de tekst worden weggelaten. Na deze transformatie is de tekst beter te begrijpen, zonder het verlies aan betekenis of nauwkeurigheid. \textcite{Siddharthan2014} noemt deze transformatie een vorm van elaboratie of het uiteenzetten van een begrip.

\subsection{Overige vormen van vereenvoudiging}

Metaforen, \textit{short language} of \textit{slang} en idiomen kan de menselijke bedoeling achter een zin of paragraaf in de war brengen voor een machine. Pragmatische vereenvoudiging zet deze constructies om naar een letterlijke en duidelijke tekst \autocite{JavoureyDrevet2022}. Ten slotte is het mogelijk om het formaat van parafrases en alinea's aan te passen. Een opsomming of oplijsting benadrukt belangrijke punten en maakt een duidelijke structuur van een mogelijks complexe tekst. Een opsomming beklemtoont dezelfde tekst vergeleken met een doorlopende tekst volgens \textcite{Siddharthan2014, Hale2022}. 

\subsection{Tekstvereenvoudiging automatiseren}

Geautomatiseerde tekstvereenvoudiging is geen nieuw concept. Volgens onderzoeken van \textcite{Canning2000, Siddharthan2006} waren de eerste aanpakken op geautomatiseerde tekstvereenvoudiging gebouwd op rule-based modellen. Deze modellen bewerken de syntax door zinnen te splitsen, te verwijderen of de volgorde van de zinnen in een tekst aan te passen. Lexicale vereenvoudiging kwam hier niet aan de pas. Enkel bij recentere onderzoeken van \textcite{Coster2011, Bulte2018} werd het duidelijk hoe lexicale en syntactische vereenvoudiging gecombineerd kon worden.

\section{Samenvatten}

Teksten vereenvoudigen met lexicale, conceptuele en/of syntactische vereenvoudiging biedt geen garantie dat de tekstinhoud korter zal worden. Bij de drie soorten vereenvoudiging wordt er initieel enkel per zin gekeken. De vereenvoudiging houdt geen rekening met voorafgaande of opvolgende zinnen \autocite{Dubay2004}. Teksten machinaal samenvatten is geen nieuw concept. Het onderzoek van \textcite{Hahn2000} onderzoekt hoe teksten automatisch samengevat kunnen worden. Dit onderzoek haalt onder meer twee aanpakken aan hoe een machine teksten kan samenvatten, namelijk extraherend en abstraherend. Daarnaast reikt \textcite{Hahn2000} drie manieren aan welke inhoud er zeker in de samengevatte versie moet op te merken zijn:

\begin{itemize}
	\item Informatieve samenvattingen vervangen de oorspronkelijke tekst. Alles wat de lezer nodig heeft, dus hoofd- en bijzaken, zijn betrokken in de samengevatte tekst.
	\item Indicatieve samenvattingen behouden enkel een tekst met links die een lezer doorverwijzen naar andere bronnen. 
	\item Kritische samenvattingen of \textit{reviews} bestaan uit de kerninhoud van de oorspronkelijke tekst en een opiniestuk over die specifieke kerninhoud.
\end{itemize}

% Generiek en gebruikersgerichte samenvatting
Verder haalt \textcite{Hahn2000} ook het onderscheid tussen een generieke en een gebruikersgerichte samenvatting. Een generieke samenvatting staat niet stil bij speciale noden of interesses van de eindgebruiker. Daarnaast houdt een gebruikersgerichte samenvatting wel rekening met sleutelwoorden of thema's in een tekst. \textcite{Hahn2000} haalt aan dat technologieën zoals \textit{full-text-search} en gepersonaliseerde informatiefiltering het belang van gebruikersgerichte samenvatting naar voor duwen. \textcite{Hahn2000} omschrijft de architectuur van een samenvattingssysteem aan de hand van drie fases. Allereerst wordt de brontekst geanalyseerd. Daarna worden de \textit{salient points} of kernpunten in een tekst aangeduid. Deze punten zijn zinnen of tokens. Ten slotte worden de punten samengevoegd tot één uitvoertekst. De nadruk is verschillend per samenvattingsmethode.

\begin{figure}
	\includegraphics{img/summarization-mindmap.png}
	\caption{Afbeelding van \textcite{Chauchan2018}. De manier waarop teksten automatisch samengevat kunnen worden, is afhankelijk van drie verschillende domeinen.}
\end{figure}

\subsection{Extraherend samenvatten}

Bij deze vorm worden de belangrijkste zinnen gemarkeerd en vervolgens opnieuw neergeschreven.  Dit is het equivalent van handmatig zinnen markeren en vervolgens op een blanco papier neerschrijven. Het nadeel hiervan is dat de uitvoertekst niet samenhangend kan zijn na het samenvatten. Dit maakt de uitvoertekst minder aangenaam om te lezen. \textcite{Verma2020} onderzocht de verschillende manieren waarop een tekst extraherend kan worden samengevat. Zij halen drie grote componenten aan, namelijk:

\begin{itemize}
	\item Graafgebaseerd extraherend samenvatten
	\item Maximal Marginal Relevance
	\item Meta-heuristic-gebaseerd
\end{itemize}

\subsubsection{Graafgebaseerd extraherend samenvatten}

Graafgebaseerd extraherend samenvatten is een techniek die een document voorstelt als een graaf, waarbij de knopen zinnen en bogen de relatie tussen de zinnen representeren. Deze algoritmen achterhalen de kernzinnen in een tekst. Bijvoorbeeld kan het PageRank-algoritme, dat vaak wordt gebruikt voor het rangschikken van webpagina's in zoekmachines, worden gebruikt om de zinnen in de grafiek te rangschikken op basis van hun belangrijkheid.

\textcite{Parveen2015} raadt een graafgebaseerd systeem aan voor \textit{unsupervised learning}. Belangrijke zinnen worden met een lokaal minimum bepaald, alsook wordt redundantie vermeden. Deze methode kan significante resultaten opleveren bij het ophalen van kernzinnen uit zowel lange wetenschappelijke artikelen als korte nieuwsartikelen. Daarnaast vermeldt \textcite{Parveen2015} dat het systeem beter presteert wanneer coherentie wordt opgenomen en gecombineerd wordt met positionele informatie. % In toekomstig werk is \textcite{Parveen2015} van plan om meer taalkundige informatie in de entiteitsgrafiek op te nemen en beoordelingen van domeinexperts te verkrijgen om te zien of de redactiesamenvattingen als gouden samenvattingen kunnen worden gebruikt voor evaluatie.

\textcite{AbdelSalam2022} voerden een vergelijkend onderzoek uit rond SqueezeBERT en BERT. De compacte architectuur van SqueezeBERT kan ingezet worden voor real-time samenvatting. Dit is volgens \textcite{AbdelSalam2022} een interessant alternatief op het BERT-model. In vergelijking heeft de voorgestelde SqueezeBERT slechts ongeveer 62 miljoen parameters, terwijl het prestatieniveau nog steeds boven de 90\% van het BERT-baseline model blijft. De evaluatie gebeurde aan de hand van de ROUGE-score. De onderzoekers besluiten dat SqueezeBERT een goed alternatief is, vooral door het trainen met bijna de helft van de grootte van het oorspronkelijke model en minimale afbreuk in de prestaties bij het samenvatten. Daarnaast kan het gebruik van efficiënte netwerken, zoals \textit{grouped convolutional layers}, de NLP-downstream taken verbeteren. 

% \textcite{AbdelSalam2022} haalt verder aan dat er potentie is voor een productieversie van een SqueezeBERT-samenvatter, die minder parameters heeft dan DistilBERT met ongeveer 20\% en dezelfde ROUGE-1 score behoudt, terwijl het iets hogere ROUGE-2 en ROUGE-L scores behaalt. Hoewel de SqueezeBERT en DistilBERT iets lagere scores produceren in vergelijking met het BERT-baseline model, heeft SqueezeBERT als voordeel dat het minder trainingstijd en minder parameters heeft dan het baseline model met ~48,44\%. 

\subsubsection{Maximal Marginal Relevance}

Traditionele extraherende samenvattingssystemen bouwen verder op de door \textcite{Carbonell1998} ontworpen architectuur. Deze architectuur gebruikt een maximaal marginale relevantiescore of MMR. Deze architectuur houdt rekening met de diversiteit en de relevantie van de gemarkeerde zinnen. De relevantie van een zin in een tekst wordt bepaald door de mate waarin het taalmodel de belangrijkste informatie overbrengt van de tekst waarvan het afkomstig is. Om diversiteit aan tekstinhoud te waarborgen, wordt er gekeken naar de mate waarin de geselecteerde zinnen verschillen van de eerder geselecteerde zinnen in de samenvatting. Als een zin relevant is maar qua inhoud te veel overlapt met de eerder geselecteerde zinnen, dan heeft deze minder kans om in de geëxtraheerde samenvatting opgenomen te worden. Deze score kan doorgaans berekend worden met KeyBERT\footnote{https://maartengr.github.io/KeyBERT/api/mmr.html}.

Extraherend samenvatten met de MMR-methode is de methode bij uitstek voor ML-toepassingen. Onderzoekers bouwen verder op de architectuur die beschreven staat in \textcite{Carbonell1998}. In \textcite{McDonald2007} stelt de onderzoeker voor om het gulzige zoekalgoritme van MMR te vervangen door een globaal optimale formulering, waarbij het MMR-framework wordt uitgedrukt als een knapzakprobleem of NP-volledig probleem. Daarmee wordt er gewezen naar een \textit{integer linear programming} (ILP) \textit{solver} die gebruikt kan worden om de wiskundige functie van MMR te maximaliseren. De MMR-methode hield voordien enkel rekening met relevantie en diversiteit, maar niet met de optimale combinatie van zinnen die in een samenvatting moet worden opgenomen. De aanpak van \textcite{McDonald2007} vereist echter meer rekenkracht en tijd dan de standaard MMR-methode, maar het experiment van \textcite{McDonald2007} haalde wel aan dat deze methode leidde tot significant betere resultaten. \textcite{Lin2010} evalueerde dit MMR-algoritme. Bij de evaluatie van deze architectuur benadrukte zij de significant betere resultaten. 

\subsubsection{Metaheuristiek-gebaseerd}

Metaheuristieke samenvatting maakt gebruik van metaheuristieke optimalisatie-algoritmen zoals genetische algoritmen, \textit{simulated annealing} of zwermoptimalisatie om de belangrijkste zinnen in een tekst te achterhalen. Deze algoritmen zoeken volgens \textcite{Verma2020, Premjith2015} naar de beste combinatie van zinnen die de belangrijkste informatie in de tekst bevatten. De evaluatiefunctie in metaheuristieke samenvattingsalgoritmen kan gebaseerd zijn op verschillende criteria, zoals zinslengte, -relevantie en -verbanden. \textcite{Rani2021} benadrukt dat teksten samenvatten met een metaheuristieke methode regelmatig vastraakt in een lokaal optimum. Dit is een tekortkoming op andere methoden. Daarnaast wijst het onderzoek uit aan dat metaheuristieke methoden geen \textit{steepness} of extremen op een \textit{search space behaviour} aanduiden. Om de convergentie aanzienlijk te versnellen, moet er gebruik worden gemaakt van een optimalisatiestrategie gebaseerd op gradiënten. 

% gradienten: (een wiskundig concept dat de richting van de snelste toename aangeeft)
% convergentie: (het proces waarbij het algoritme naar de juiste oplossing toewerkt) -- Hierdoor wordt het algoritme efficiënter en sneller uitgevoerd.

\subsubsection{Experimenten over extraherend samenvatten}
% \subsubsection{title}

% todo https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1 --> voorbeeld van een pipeline

\textcite{McKeown1999} voerden experimenten uit op extraherende samenvattingen van nieuwsartikelen. De resultaten wijzen erop dat deze vorm vatbaar is op vooroordelen of \textit{bias} van de auteur. De zinnen worden genomen zoals ze zijn. \textcite{Hahn2000} bouwde verder op dit experiment. Zij voerden een experiment uit met een mix van \textit{knowledge-rich} en \textit{knowledge-poor} methoden, met significant positieve resultaten tot gevolg. De nadruk bij extraherend samenvatten ligt in het kiezen van de \textit{salient text units}. Deze punten zijn typisch in de vorm van zinnen. Er is nood aan een manier om de lexicale en statistische relevantie van een zin te kunnen aanduiden. Hiervoor haalt \textcite{Hahn2000} twee manieren aan:

\begin{itemize}
	\item Een lineair gewicht model. Iedere teksteenheid wordt gewogen op factoren zoals de \textit{location weight} en het aantal voorkomens.
	\item Een gewicht model op basis van de statistische opvallendheid van een eenheid. Zo wordt er rekening gehouden met de aanwezigheid van een woord in (sub)titels.
\end{itemize}

% resultaten lineair gewicht model
% resultaten statistische opvallendheid

\textcite{Nallapati2017} wilden de nauwkeurigheid van deze modellen overbruggen. Dit doen ze met \textit{SummaRuNNer}\footnote{https://github.com/hpzhao/SummaRuNNer}, een oplossing voor het extraherend samenvatten van teksten met een neuraal netwerk. De toepassing werd opgebouwd met PyTorch in  en bestaat uit een combinatie van drie modellen: een recurrent neuraal netwerk, een convolutioneel recurrent neuraal netwerk en een \textit{hiërarchical attention network}.

\subsection{Abstraherend samenvatten}

Extraherend samenvatten houdt geen rekening met de structuur van een tekst. De uitvoertekst is op het eerste zicht vrij machinaal. Kernzinnen achterhalen gebeurt bij geautomatiseerde samenvatting met zes features volgens \textcite{Khan2014}, namelijk de woordfrequentie, de plaats van een zin in de tekst, de \textit{cue method} of een woord dat de kerngedachte van een paragraaf benadrukt, titels, de lengte van de zin, de gelijkenissen tussen de zin en de rest van het document, het gebruik van \textit{proper nouns} en ten slotte de afstand tussen \textit{text units} waarin entiteiten voorkomen. Een tekst abstraherend samenvatten kan volgens \textcite{Khan2014} op twee manieren: semantisch en structuurgebaseerd. \textcite{Cao2022} deed verder onderzoek naar \textit{deep learning} methoden om abstraherende samenvattingen te automatiseren.

\subsubsection{Structuurgebaseerde benaderingen op abstraherend samenvatten}

Structuurgebaseerde benaderingen zoeken naar belangrijke informatie in de tekst en gebruiken regels om samenvattingen te maken. Ze worden vaak gecombineerd met andere methoden. \textcite{Khan2014} motiveert dat deze vorm ideaal is voor het samenvatten naar korte, samenhangende teksten met redundante zinnen. De linguïstische kwaliteit ligt laag en samengevatte zinnen kunnen volgens \textcite{Khan2014} grammaticale fouten bevatten, omdat een structuurgebaseerde aanpak niet afhankelijk is van de oorspronkelijke tekststructuur.

\subsubsection{Semantisch-gebaseerde benaderingen op abstraherend samenvatten}

De semantisch-gebaseerde benadering gebruikt de betekenis van de tekst om samenvattingen te maken. Deze samenvattingen zijn kort, duidelijk en bevatten veel informatie. Er zijn verschillende manieren om dit te doen. Deze aanpak toont vorderingen op structuurgebaseerd volgens \textcite{Khan2014}. Zo zijn de samenvattingen beknopt en bevatten voldoende kern- en deelzaken voor de lezer. De linguïstische kwaliteit is beter en er zijn minder redundante zinnen. Ten slotte worden er minder grammaticale fouten gemaakt, al is er wel de nood aan een extra parsingfase.

\subsubsection{Abstraherend samenvatten met deep learning}

\textit{Deep learning} voor abstraherend samenvatten kan met verschillende modellen zoals RNN’s (terugkerende neurale netwerken), CNN’s (convolutionele neurale netwerken) en sequence-to-sequence (Seq2Seq) modellen. Deze modellen kunnen leren om samenvattingen te maken door de betekenis van de tekst te begrijpen en nieuwe tekst te maken die de belangrijkste informatie overbrengt \autocite{Suleiman2020}. Om een abstraherende samenvatting met deep learning op te bouwen bestaan er verschillende modellen. Het Pegasus-model beschreven in \textcite{Zhang2020} handelt \textit{gap-sentences} af met pre-trained models voor samenvatting met NLP.  Dit model werd getrained en beoordeeld op samenvattingstaken zoals emails, patenten, rekeningen en ook wetenschappelijke artikelen \autocite{Zhang2020}.

\subsection{Hybride samenvatten}

In het best denkbare geval wordt abstraherende en extraherende samenvatting gecombineerd volgens \textcite{Hsu2018, Huang2019}. Zo omvat een pipeline voor hybride samenvatting twee onderdelen: een \textit{content selection} fase waarin de kernzinnen met extraherende samenvatting worden opgehaald en \textit{paraphrasing}-fase waarbij de gemarkeerde kernzinnen abstraherend worden samengevat. 

\subsection{Evaluatie}

Samenvattingen van lange documenten handmatig beoordelen vergt tijd en voldoende planning van een mens \autocite{Nenkova2004}. Met behulp van een vooraf geschreven samenvatting als referentietekst zorgen twee metrieken voor ondersteuning om een samenvatting automatisch te laten beoordelen. Samenvattingen beoordelen kan ook zonder referentietekst, al moeten verschillende factoren worden opgevolgd.

\subsubsection{Evaluatie met referentieteksten}

Onderzoeken bij het vergelijken van een teksttransformatie schakelen BLEU en ROUGE in. Deze twee metrieken meten de gelijkenis tussen een machine-gegenereerde tekst en een referentietekst. Deze referentietekst is gemaakt door de mens. ROUGE is recall-gebaseerd en gebaseerd op exacte \textit{token matches}. Deze aanpak impliceert dat er geen rekening wordt gehouden met synonieme zinnen of zinnen met een gelijke betekenis \autocite{Lin2004}. De ROUGE-modellen die verderbouwen houden rekening met deze tekortkomingen. ROUGE-2 van \textcite{Ganesan2018} voorziet dictionaries van synoniemen, zodat er rekening wordt gehouden met synonieme zinnen. ROUGE-G van \textcite{ShafieiBavani2018} gebruikt graafalgoritmen om lexicale en semantische matching mogelijk te maken. \textcite{Lin2004} beschrijft een Python-bibliotheek\footnote{https://github.com/pltrdy/rouge} dat de berekening van deze metriek vereenvoudigt.

BLEU volgt een gelijkaardige werking en beoordeelt de gelijkenis tussen een machine-gegenereerde tekst en een referentietekst, maar deze meting is precision-gebaseerd. BLEU introduceert een \textit{brevity penalty} of strafterm voor te korte teksten, om te voorkomen dat taalmodellen enkel veelvoorkomende woorden genereren die een hoge precisie opleveren met weinig zinvolle zinnen \autocite{Chiusano2022}. Voor de BLEU-metriek bestaat er ook een Python-bibliotheek\footnote{https://github.com/neural-dialogue-metrics/BLEU}. 

\begin{table}[!h]
	\centering
	\begin{tabular}{|c|p{5cm}|p{5cm}|}
		\hline
		Metriek & ROUGE & BLEU \\
		\hline
		Soort metriek & Recall-gebaseerd & Precision-gebaseerd \\
		\hline
		Nut en gebruik & Evalueert hoe goed een samenvatting de belangrijke inhoud van een referentiesamenvatting dekt & Evalueert hoe goed een gegenereerde samenvatting overeenkomt met een referentiesamenvatting \\
		\hline
		Te meten waarde & De overlap van n-grams (sequentie van n woorden) tussen de gegenereerde samenvatting en de referentiesamenvatting & De overlap van n-grams (sequentie van n woorden) tussen de gegenereerde samenvatting en de referentiesamenvatting \\
		\hline
		n-gram range & Meet meestal overlap van 1-4 grams & Kan overlap van 1-4 gram meten, of elk ander bereik van n-grams \\
		\hline
		Weging & Gewogen of ongewogen & Gewogen of ongewogen \\
		\hline
		Sterke punten & Goed voor het meten van de dekking van inhoud en de algehele kwaliteit van de samenvatting & Goed voor het meten van de vloeiendheid van zinnen en de grammaticale correctheid \\
		\hline
		Zwakke punten & Kan gevoelig zijn voor verschillen in woordvolgorde en zinsstructuur tussen de gegenereerde samenvatting en de referentiesamenvatting & Vangt de semantische overeenkomst tussen de gegenereerde samenvatting en de referentiesamenvatting niet op \\
		\hline
		Gebruik & Vaak gebruikt voor samenvattingstaken & Vaak gebruikt voor machinevertalingstaken \\
		\hline
	\end{tabular}
	\caption{Comparison of ROUGE and BLEU metrieken}
	\label{tab:rouge_bleu_comparison}
\end{table}


\subsubsection{Evaluatie zonder referentieteksten}

Een samengevatte tekst beoordelen zonder een referentietekst vereist volgens \textcite{Steinberger2009} meer subjectiviteit en menselijke betrokkenheid dan met een referentietekst. Deze soort kan handmatig gebeuren, maar ook semi-automatisch. De type tekst, de lengte en de complexiteit van de oorspronkelijke tekst zijn factoren die in acht moeten worden genomen bij het beoordelen van de samengevatte tekst. Daar moet er worden gekeken naar het doelpubliek en het formaat. De tekst- en inhoudskwaliteit van de samengevatte tekst moet worden beoordeeld. De tekstkwaliteit is de grammaticale correctheid, niet-redundantie van zinnen en woordenschat en coherente structuur \autocite{McCombes2022}. De inhoudskwaliteit wijst op de informatie dat wordt opgenomen in de samengevatte tekst. Dit omvat de relevantie met de doelgroep bij kern- en bijzaken of misleidende informatie door een misinterpretatie van het systeem \autocite{McCombes2022}.


\subsection{Tekstvereenvoudigingstechnieken voor scholieren met dyslexie.}

\textcite{Bingel2018} beschrijft een systeem voor dat gericht is op lexicale tekstvereenvoudiging en een embeddings-gebaseerde aanpak voor substitution generation. Tijdens de substitution selection maakt het systeem gebruik van een ongesuperviseerde boundary ranker om de synoniemen te filteren. De geselecteerde synoniemen worden vervolgens gerangschikt met behulp van een gesuperviseeerd SR-model. Daarnaast is het systeem in staat om het model te personaliseren op basis van gebruikersfeedback en maakt het gebruik van een seed-dataset van complex-simple overeenkomsten. Deze overeenkomsten houden rekening met de context van een woord in een zin en helpen bij de initiële vereenvoudiging van teksten. Alle gebruikersinformatie wordt met een PostgreSQL databank bijgehouden. Gebruikersinformatie wordt gekoppeld aan de demografische informatie informatie, om zo de ideale uitvoertekst te kunnen genereren. 

Het onderzoek van \textcite{DeBelder2010} richt zich op tekstvereenvoudiging voor kinderen. De doelgroep ligt echter jonger dan deze casus, maar het onderzoek haalt aan hoe de onderzoekers een methode opzetten voor lexicale en syntactische vereenvoudiging. \textcite{Bulte2018} werkte het aspect rond lexicale vereenvoudiging verder uit. Het resultaat van dit onderzoek was een \textit{pipeline} ontworpen om moeilijke woordenschat naar simpele synoniemen te vervangen. Eerst ging de tekstinhoud door een \textit{preprocessing}-fase, samen met het uitvoeren van WSE. Daarna werd de moeilijkheidsgraad van ieder token overlopen. De moeilijkheidsgraad is gebaseerd op de frequentie in SONAR500\footnote{https://taalmaterialen.ivdnt.org/download/tstc-sonar-corpus/} een corpus met eenvoudige Nederlandstalige woorden, en ook de Wablieft-corpus, een archief van nieuwsartikelen in eenvoudig Nederlands. Synoniemen werden teruggevonden met Cornetto\footnote{https://github.com/emsrc/pycornetto}, een lexicale databank met Nederlandstalige woorden, samen met een \textit{reverse lemmatization} fase. Lexicale vereenvoudiging is ingewikkeld wanneer er geen eenvoudigere synoniemen zijn. In dat geval blijft een moeilijk woord voor wat het is. Voor deze toepassing maakten de onderzoekers gebruik van LLM's samen met Wikipedia annotaties. Deze annotaties bevestigden of de gegeven informatie correct is. De resultaten van deze toepassingen vallen in lijn met andere huidige toepassingen van hun soort. De onderzoekers benadrukken dat deze toepassing ook voor andere doelgroeppen met een lagere leesgraad kunnen dienen, zoals L2-lezers.

\begin{figure}[H]
	\begin{center}
			\includegraphics[width=9cm]{img/dutch-simplification-dyslexia-pipeline.png}
	\end{center}
	\caption{Afbeelding uit \textcite{Bulte2018}. Deze pipeline omvat de stappen die de toepassing aflegt. }
\end{figure}

\begin{figure}[H]
	\begin{center}
			\includegraphics[width=9cm]{img/dutch-simplification-dyslexia-example.png}
	\end{center}
	\caption{Afbeelding uit \textcite{Bulte2018}. TODO}
\end{figure}


Al zijn er onderzoeken over lexicale, syntactische en semantische vereenvoudiging voor kinderen en scholieren met dyslexie, het aantal onderzoeken over samenvatten voor deze doelgroep is schaars. Zoals eerder aangehaald is er wel onderzoek gedaan naar de verschillende manieren om een tekst samen te vatten, maar er is geen toepassing of onderzoek dat dit concreet uitwerkt. 


\subsection{Conclusie}

Wetenschappelijke artikelen volgen een gelijke structuur. De inhoud in PDF- of afbeeldingvorm vergt voldoende cleaning-fasen. Het beoordelen van de samenvatting op basis van een referentietekst met de ROUGE-metriek wordt aangeraden, al kan deze beoordeling niet enkel machinaal gebeuren. Daarnaast is er input en bijsturing nodig van de mens omtrent een samenvatting op maat en de grammaticale, lexicale en semantische correctheid. Tools gericht op het lexicaal en adaptief vereenvoudigen van teksten voor kinderen en scholieren met dyslexie zijn reeds uitgewerkt. Methoden om menselijke en grammatisch correcte samenvatting op te bouwen zijn reeds beschikbaar. 

\section{Valkuilen en uitdagingen voor AI-ontwikkelaars bij tekstvereenvoudiging met AI}

AI en ML zijn volop in groei. NLP gebruikt AI en ML om menselijke taal te verwerken, terwijl NLU deze technologieën gebruikt om menselijke taal te begrijpen. Hoewel deze technologieën veelbelovend zijn, moeten AI-ontwikkelaars rekening houden met veelvoorkomende en genegligeerde uitdagingen en valkuilen \autocite{Sciforce2020, Roldos2020, Khurana2022}. Deze sectie beantwoordt de volgende onderzoeksvraag: "Met welke valkuilen bij taalverwerking met AI moeten ontwikkelaars rekening houden?"

\subsection{Uitdagingen voor softwarebedrijven}

Volgens het jaarlijks rapport van IBM behoren Natural Language toepassingen tot de duurste soort om te ontwikkelen. Ongeveer 54\% van de bevraagde IT-professionals vond de bijhorende kosten een obstakel bij het starten van de ontwikkeling voor NLP-toepassingen. Professionals halen verschillende pijlers aan, waaronder de kwaliteit en kwantiteit van de data, het trainen van de data, het gebrek van NLP-experten, de integratie en deployment van de taalmodellen en ten slotte de transparantie van het model. Gespecialiseerde modellen zijn use-case afhankelijk wat ze niet voor iedere toepassing bruikbaar maakt. Als oplossing kunnen softwarebedrijven partnerships afsluiten, investeren in NLP-talent, klein starten en stelselmatig opschalen, cloud-gebaseerde oplossingen aanreiken of de transparantie van een model benadrukken in hun specifieke toepassing \autocite{IBM2022}.

\subsection{Ambiguïteit, synoniemen en homoniemen}

\textit{Sequence Labeling} koppelt labels aan tokens in doorlopende tekst. Homoniemen kunnen echter roet in het eten gooien. Volgens \textcite{Roldos2020} heeft een machine moeite om de context van homoniemen te achterhalen. Bijvoorbeeld bij het woord ‘bank’ is het niet duidelijk voor de machine of het gaat over de geldinstelling of het meubel. \textit{Word Sense Disambiguation} of WSD is een NLP-taak waarbij de betekenis van een woord wordt bepaald. Deze bepaling gebeurt volgens \autocite{Eisenstein2019} op basis van de context waarin een woord gebruikt wordt. Deze taak is nodig binnen NLP om rekening te houden met homoniemen. WSD implementeren kan dictionary-gebaseerd, gesuperviseerde, semi-gesuperviseerd of niet-gesuperviseerd. PoS-tagging kan dit probleem aanpakken volgens \textcite{Liu2020} aan als een oplossing op dit probleem, samen met het gebruik van contextual embeddings. Spacy biedt een sense2vec\footnote{https://github.com/explosion/sense2vec} aan.

Bij het bouwen van NLP-systemen moeten zo veel mogelijke betekenissen en synoniemen van een woord worden opgenomen. Tekstanalysemodellen zijn niet foutloos, maar hoe meer relevante trainingsgegevens ze ontvangen, hoe beter ze synoniemen zullen begrijpen \autocite{Roldos2020}. \textcite{Dandekar2016} reikt twee methoden aan: \textit{candidate generation} door gebruik te maken van word embeddings, historical user data of lexicale synoniemen. Daarnaast is er ook een gesuperviseerde methode, namelijk \textit{synonym detection}. Aanvullend kunnen antoniemen volgens \textcite{Dandekar2016} op eenzelfde manier worden achterhaald met NLP ML.

Het onderzoek van \textcite{Sciforce2020} haalt aan dat het merendeel van NLP-toepassingen Engelstalige invoer gebruikt. Niet-Engelstalige toepassingen zijn zeldzaam. De opkomst van AI technologieën die twee datasets gebruiken, biedt een oplossing voor dit probleem. De software vertaalt eerst de oorspronkelijke tekst naar de gewenste taal, voordat de tekst wordt herwerkt. BERT maakt volgens \textcite{Roldos2020} gebruik van meertalige transformers, wat de impact van deze uitdaging kan dempen.

\subsection{Paternalisme en ethische overwegingen}

De doelstelling van ondersteunende toepassingen is om gelijke kansen te bieden aan iedere doelgroep. Tekstvereenvoudiging transformeert de oorspronkelijke tekst naar een tekst met een simpelere syntax, kortere zinnen, verminderde lexicale en semantische complexiteit en gereduceerd aantal zinnen. Volgens \textcite{Niemeijer2010} zijn de ethische overwegingen die samenhangen met tekstvereenvoudiging niet gemakkelijk te scheiden van de gebruikte technologie om het resultaat te bereiken. Het onderzoek van \textcite{Gooding2022} haalt pijlers aan waarmee ontwikkelaars en softwarebedrijven rekening moeten houden bij de ontwikkeling van adaptieve en ondersteunende leessoftware, voornamelijk toepassingen voor tekstvereenvoudiging. Ontwikkelaars moeten zich meer bewust worden van de behoeften en verwachtingen van de eindgebruiker bij het ontwikkelen van een tekstvereenvoudigingstoepassing. Haar onderzoek benadrukt de paternalistische of afhankelijke aard van assisterende toepassingen. Tekstvereenvoudiging omvat vier transformaties, maar niet iedere transformatie is vereist voor iedere gebruiker. Een adaptieve tekstvereenvoudigingstoepassing moet de eindgebruiker een keuze aanbieden om aan te passen wat vereenvoudigd wordt, afhankelijk van specifieke behoeften.

Software-ontwikkelaars verkiezen volgens \textcite{Punardeep2020} voor \textit{black-box} modellen bij de ontwikkeling en finetuning van een NLP-toepassing met AI. Al is het verschil qua nauwkeurigheid minimaal, de afweging wordt gemaakt bij de transparantie van het model. Na een transformatie wordt er niet aangegeven waarom specifieke transformaties werden uitgevoerd, bijvoorbeeld het vervangen van een woord door een eenvoudiger synoniem. \textcite{Xu2015} benadrukt dat toepassingen voor tekstvereenvoudiging meer rekening moeten houden met de doelgroep waarvoor ze worden ontwikkeld. White-box modellen zijn er in schaarse hoeveelheden. 

Om dit probleem op te lossen, is het belangrijk om de eindgebruiker, in dit geval scholieren met dyslexie in het derde graad middelbaar onderwijs, de keuze te geven. Zoals beschreven in \textcite{Gooding2022}, zijn er verschillende mogelijkheden. Bijvoorbeeld, de eindgebruiker moet de mogelijkheid hebben om te kiezen welke synoniemen de tekst lexicaal zullen aanpassen. Een alternatieve aanpak voor syntactische vereenvoudiging is om de scholier zelf zinnen te laten markeren die moeilijk te begrijpen zijn, zodat het systeem alleen de door de eindgebruiker aangegeven zinnen vereenvoudigt.

\subsection{Valkuilen bij prompt engineering}

Iedereen is in staat om een conversatie met een chatbot op te bouwen. Het gebruik van de API voor een doelgericht en doordacht antwoord vergt echter planning bij de ontwikkelaar. \textcite{Miszczak2023} waarschuwt voor 'garbage-in garbage-out'. De kwaliteit van de input kan de kwaliteit van de output bepalen. \textcite{Jiang2023} benoemt de misopvatting bij de intentie van de gebruiker als de voornaamste uitdaging voor een taalmodel dat input vereist. Volgens Jiang kan dit te wijten zijn aan de gebruiker die een onvolledige prompt of een prompt met onvoldoende context op een concreet antwoord schrijft. Daarnaast kan een gebrek aan trainingsdata ook aan de oorzaak liggen van een onnauwkeurige uitvoertekst of bias in het taalmodel. Andere factoren die \textcite{Miszczak2023} aanhaalt, zijn de afwisselende probabiliteit van de outputtekst en de meegegeven parameters die het model beïnvloeden, zoals de temperature dat de creativiteit van het model beïnvloedt. Als oplossing kan de prompt als een conditionele expressie worden opgebouwd, zodat het taalmodel enkel met zekerheid een antwoord teruggeeft.

\subsection{Evaluatie en interpretatie}

ROUGE en BLEU zijn twee metrieken die geen rekening houden met de semantiek van de tekst. Twee zinnen met een identieke semantiek kunnen een lage score opleveren als er geen overlap is tussen de oorspronkelijke en de samengevatte tekst. Daarnaast kan een tekst grammaticaal fout zijn en nog steeds een goede tot uitstekende score hebben. Deze beperkingen van de ROUGE en BLEU scores kunnen worden opgelost door gebruik te maken van verwante metrieken, zoals ROUGE-L, ROUGE-SU en METEOR. Deze scores houden wel rekening met aanvullende factoren zoals zinsemantiek -of overeenkomsten. ROUGE, BLEU en de verwante metrieken zijn geen vervanging op menselijke evaluatie. Zowel machinale als menselijke beoordeling moet worden overwogen bij het onderzoeken van een samenvattingsmethode \autocite{Raj2017, Tatman2019}.

Er is geen algemene consensus bij onderzoekers over de ideale evaluatiemetriek(en) voor tekstvereenvoudiging -en samenvatting. Er is volgens \textcite{Fabbri2020} nood aan een mix tussen machinale en geautomatiseerde evaluatie, alsook evaluatie door de mens en met voorkeur in die volgorde. \textcite{Iskender2021} zien menselijke evaluatie niet als een gulden standaard bij het beoordelen van een samengevatte tekst. Ze stimuleren verder onderzoek naar nieuwe standaarden en best practices voor betrouwbare menselijke beoordeling op samengevatte teksten. Het onderzoek onderzocht niet of er verschillende resultaten zijn bij de beoordeling van extraherende en abstraherende samenvattingen. De beste samengevatte versie van een tekst achterhalen met menselijke feedback vergt de juiste methode. De doelgroep waarvoor een tekst wordt samengevat, moeten nauw in het proces worden opgenomen \autocite{Iskender2021}.


\section{Beschikbare software voor tekstvereenvoudiging}

% inleiding voor welke software
Dyslexie is een veelvoorkomende aandoening die de lees- en schrijfvaardigheden van scholieren kan belemmeren. Om deze scholieren te ondersteunen, worden er verschillende softwareprogramma's en tools ontwikkeld. In dit hoofdstuk zal worden gekeken naar mogelijke nationale en internationale software die specifiek is ontworpen om scholieren met dyslexie te helpen bij het lezen van teksten. Er zal met name worden gekeken naar de beschikbare software in Vlaamse middelbare scholen, chatbots, zoals Bing AI en ChatGPT, en software die speciaal is ontwikkeld om dyslexie te ondersteunen bij het lezen. Deze sectie beantwoordt de volgende onderzoeksvraag: "Welke toepassingen, tools en modellen zijn er beschikbaar om Nederlandstalige geautomatiseerde tekstvereenvoudiging met AI mogelijk te maken?"

\subsection{Momenteel ingezet in het onderwijs}

In het middelbaar onderwijs wordt lees- en studieondersteuning voor scholieren met dyslexie enkel in de vorm van voorleessoftware voorzien \autocite{DeCraemer2018, OnderwijsVlaanderen2023}. \textcite{OnderwijsVlaanderen2023} leent licenties voor de volgende softwarepakketten uit:

\begin{itemize}
	\item SprintPlus
	\item Kurzweil3000
	\item Alinea Suite
	\item IntoWords
	\item TextAid
\end{itemize}

Naast luister- en schrijfopties kunnen scholieren deze toepassingen gebruiken om zinnen te markeren om deze zinnen vervolgens samen te vatten. Enkel de gemarkeerde zinnen worden betrokken in de samengevatte versie, dus de zinnen blijven lexicaal, syntactisch en semantisch identiek. Alle vermelde softwarepakketten bieden echter geen onafhankelijke samenvat- of vereenvoudigfunctie aan. \textcite{Tops2018} benadrukt de handige aspecten van deze software, maar deze software moet zo vroeg mogelijk in een schoolcarriére worden ingezet. Zo raken de scholieren snel vertrouwd met het gebruik, wat kan leiden tot een optimaal gebruik in verdere studies. Volgens \textcite{Tops2018} is het te laat om deze software pas in het hoger onderwijs te introduceren.

\subsection{Proof-of-concepts en online webapplicaties}

Online zijn er tools beschikbaar om teksten generiek samen te vatten. Resoomer, Paraphraser en Scholarcy zijn oorspronkelijk Engelstalige tools, met ondertussen de mogelijkheid om een abstraherende samenvatting te maken van Nederlandstalige teksten. De taalmodellen waar deze applicaties op werken, is niet gekend. Daarnaast zijn er ook geen API's beschikbaar om mee te werken. Gepersonaliseerde toepassingen zijn er in mindere mate. \textcite{Bingel2018} omschrijft een proof-of-concept voor een webtoepassing dat teksten vereenvoudigd, met oog op mensen met dyslexie. Deze software noemt nu Hero en bevindt zich in betafase.

% De assumptie is dat dit gericht kan zijn op de Nederlandse taal, of een anderstalig model en nadien vertaald naar het Nederlands.

Toepassingen om wetenschappelijke artikelen te vereenvoudigen zijn schaars, maar er zijn enkele gratis en betalende toepassingen beschikbaar. SciSpace\footnote{https://typeset.io/} is gratis. Scholarcy\footnote{https://www.scholarcy.com/?ref=theresanaiforthat} is betalend. 

\begin{figure}
	\includegraphics{img/typeset-example.png}
	\caption{Schermafbeelding van SciSpace.}
\end{figure}}

\subsection{GPT-3}

% uitleg over gpt
\textit{Generative Pretrained Transformer 3} of GPT-3 is een taalmodel ontworpen door OpenAI. Dit taalmodel werkt met een tweestapsleerparadigma. Pre-training gebeurt ongesuperviseerd met een language modelling objective. Vervolgens wordt het taalmodel gesuperviseerd gefine-tuned. Over drie versies heen is het model aanzienlijk vergroot, van anderhalf miljard parameters bij GPT-2 naar 175 miljard parameters bij GPT-3. Het model is getraind op niet-gecategoriseerde data van het internet en gebruikt datasets waaronder Common Crawl, WebText2, Books1, Books2, and Wikipedia. Dit taalmodel steunt op \textit{Reinforcement Learning from Human Feedback} of RLHF \autocite{Radford2019, Li2022}.

\begin{figure}[H]
	\includegraphics[width=10cm]{img/chatgpt-example-simplification-gooding.png}
	\caption{Afbeelding van Gooding 2022. De invoertekst is een paragraaf uit een niet-vermeld boek van de Russische schrijver Dostoevsky. Het resultaat van de meegegeven prompt is een transformatie dat iedere vorm van vooraf aangehaalde vereenvoudiging weergeeft. Lexicale, conceptuele en syntactische vereeenvoudiging worden op de invoertekst toegepast.}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=10cm]{img/chatgpt-example-different-versions-gooding.png}
	\caption{Afbeelding van Gooding 2022. Gooding haalt verder aan dat modellen zoals ChatGPT op twee vlakken de leesbaarheid van een tekst kan bevorderen. Allereerst door het verlenen van verschillende mogelijke versies van een vereenvoudigingstaak.}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=10cm]{img/chatgpt-example-evaluation-gooding.png}
	\caption{Afbeelding van Gooding 2022.}
\end{figure}

\textcite{Lisowski2023} vergelijkt de twee OpenAI taalmodellen met een \textit{mixed-methods} onderzoek. Al blijken de twee heel gelijkaardig, het experiment benadrukt dat het ChatGPT-model gericht is op conversationele doeleinden met voorkeur als chatbot, terwijl GPT-3 een ML-model is bedoeld om met hoogstens één prompt te werken. De grootte van het GPT-3 model met 175 miljard parameters imposanter dan Chat-GPT. Daarnaast is de limiet bij het meest recente GPT-3 model is 4000 tokens. Verder haalt Lisowski aan dat de kwaliteit bij beide modellen sterk afhankelijk is van de invoer. De prompts moeten concreet genoeg zijn, om zo niet af te wijken van wat de gebruiker wilt \autocite{Lisowski2023}. Deze twee API's zijn nu vrij beschikbaar voor ontwikkelaars als betalende API \autocite{Brockman2023}.

\subsubsection{Beschikbare GPT-3 engines}

De documentatie van OpenAI\footnote{https://platform.openai.com/docs/} reikt vier verschillende engines voor het GPT-3 taalmodel aan, namelijk Davinci, Curie, Babbage en Ada. In Maart 2023 voegde een vijfde engine zich toe, namelijk GPT-3 Turbo wat de basis is achter Chat-GPT \autocite{Brockman2023}.

\begin{itemize}
	\item Davinci-003 is het meest recente model en is in staat om alles te doen wat de andere engines in staat zijn. Het model maakt gebruik van text de invoertekst eventueel kan aanvullen, mocht de invoertekst afgebroken zijn. Deze aanvulling kan in vraag worden gesteld. Aanvullend geeft aan dat deze engine de meest menselijke antwoorden geeft op basis van foutenmarge. De andere engines kwamen niet in de buurt. \textcite{Binz2023} vult aan dat deze engine de meest \textit{menselijke} antwoorden teruggeeft. Daarom is deze engine geschikt voor taken zoals essays schrijven, vragen beantwoorden of code genereren.
	\item Curie is in staat om zinnen met nuance te verwerken, maar maakt een grote sprong terug qua menselijke interpretatie vergeleken met Davinci. Deze engine wordt ingezet voor taken zoals tekstclassificatie, samenvatting of vertaling.
	\item Ada is niet in staat om zinnen met nuance te verwerken. Deze engine wordt aangeraden voor taken zoals het aanvullen van tekst of het aanmaken van labels.
	\item Babbage is de minst krachtige en kan ook geen zinnen met nuance verwerken, maar het is de snelste engine. Deze engine toekennen aan eenvoudige taken zoals sentiment analyse of het achterhalen van keywords is volgens de documentatie \textit{best practice}.
\end{itemize} 

\begin{figure}
	\begin{center}
		\includegraphics{img/chatgpt-engines-mean-regret.png}
		\caption{Afbeelding van \textcite{Binz2023}. Dit toont de \textit{mean regret} aan tussen de vier engines en de menselijke antwoorden.}
	\end{center}
\end{figure}

\subsubsection{Tools met GPT-3}

\textcite{Mottesi2023} haalt lees- en schrijftools aan die gebruik maken van de GPT-3 API. Jasper AI is een chatbot bestemd voor customer support en een virtueel assistent voor e-commerce. ChatSonic is een tool gericht om social media posts of nieuwsartikelen te generere op basis van een kernzin of kernwoord. 

Verschillende artikels vermelden de mogelijkheden voor het gebruik van GPT-3 en ChatGPT in het onderwijs. \textcite{Roose2023} haalt zo de hoge toegankelijkheid, engagement bij scholieren en granulaire personalisatie aan dat het GPT-3 model toe in staat is. \textcite{Garg2022} ziet in GPT-3 en ChatGPT een portaalfunctie, om scholieren te helpen bij het opzoeken van nieuwe informatie tijdens de les en bij het instuderen.

\subsubsection{Vergelijking met andere taalmodellen}

De architectuur tussen GPT-3 en BERT is volgens \textcite{Mottesi2023} het meest opvallende verschil. GPT-3 is een autoregressief model en houdt daarmee enkel rekening met de linkercontext bij het voorspellen of genereren van tekst. BERT daarentegen is bidirectioneel en neemt zowel de linker- als de rechtercontext in overweging. De bidirectionele werking is geschikt voor sentimentanalyse waarbij begrip van de volledige zincontext noodzakelijk is. GPT-3 heeft toegang tot meer informatie (45TB) dan BERT (3TB), wat het een voordeel kan geven bij het samenvatten of het vertalen. Ten slotte zijn er ook verschillen in grootte. Hoewel beide modellen erg groot zijn, GPT-3 is aanzienlijk groter dan de voorganger vanwege de uitgebreide trainingsdatasetgrootte \autocite{Brown2020}.


\begin{figure}[H]
	\includegraphics{img/graph-language-models.png}
	\caption{Afbeelding van \textcite{Simon2021}. De evolutie van pre-trained taalmodellen wordt hier weergegeven tot eind 2022. De performantie van de modellen ten opzichte van de grootte volgt een lineaire functie.}
\end{figure}

% todo Uit General Language Understanding Evaluation (GLUE) benchmarks van (..) werden GPT-3 en verwante BERT-modellen tegen elkaar gestaafd. 

\textcite{Li2022} benadrukt dat GPT-3 voor simpele taken \textit{overkill} is. Taken buiten het genereren van teksten, zoals sentimentanalyse en -classificatie, worden beter met een kleinschaliger taalmodel zoals BERT en verwante modellen uitgevoerd. Deze keuze beïnvloedt het budget, want GPT-3 is een API waar per token wordt betaald, terwijl BERT gratis en open-source is. \textcite{Strubell2019, Simon2021} halen de ecologische effecten aan van ontwikkelaars die te snel voor deze modellen grijpen. Er is een bewezen effect kleinere modellen, gebruik van Cloud-infrastructuur en ten slotte een geschikte model finetuning bijdragen tot efficiëntere alsook minder klimaatbelastende effect.


\subsubsection{GPT-3 voor samenvattingen}

Onderzoek naar OpenAI's ChatGPT en GPT-3 modellen bevindt zich in een vrij vroeg stadium, al zijn er wel enkele vergelijkende onderzoeken die de kracht en zwaktes van deze technologieën aantonen. Het experiment van \textcite{Goyal2022} achterhaalt het gebruik van \textit{zero-shot} samenvattingen buiten generieke samenvattingen. Het onderzoek staat stil bij de impact van prompt-gebaseerde modellen voor het automatisch samenvatten van nieuwsartikelen. Daarnaast maakte het onderzoek gebruik van text-davinci-002 als case study. Uit het experiment besluiten de onderzoekers dat \textit{zero-shot} samenvattingen met GPT-3 beter presteren dan \textit{fine-tuned} modellen, en dat bestaande automatische metrieken zoals BLEU, ROUGE en BERTScore niet geschikt zijn om \textit{zero-shot} samenvattingen te beoordelen. Verder blijkt dat zero-shot samenvattingen meer coherentie en relevantie hebben voor trefwoord-gebaseerde samenvattingen, terwijl aspect-gebaseerde samenvattingen nog vaak blijven te falen.

\subsubsection{GPT-3 finetuning}

\begin{tabular}{|c|p{7cm}|p{5cm}|}
	\hline
	Parameter & Omschrijving & Mogelijke waarden \\
	\hline
	model & Het GPT-3 model om te gebruiken & davinci, curie, babbage, ada, text-davinci-002, text-curie-001, text-babbage-001, text-ada-001, davinci-codex \\
	\hline
	temperature & De gulzigheid van een generatief model. Een lagere waarde zal conservatieve en voorspelbare tekst teruggeven. Hogere waarden zullen meer gevarieerde en onverwachtse tekst teruggeven, wat beter werkt bij creatieve toepassingen. & Een kommagetal tussen 0 en 1. \\
	\hline
	max\_tokens & Het maximaal aantal tokens (woorden of subwoorden) dat het generatief model kan teruggeven. & Een getal tussen 1 and 2048. \\
	\hline
	top\_p & Vergelijkbaar met temperature, maar deze waarde onderhoudt de probability distribution voor common tokens. Hoe lager de waarde, hoe waarschijnlijker de woordenschat dat het model zal overwegen bij het genereren van tekst. Een hoge waarde is toepasselijker wanneer een toepassing gericht is op nauwkeurigheid en correctheid. & Een kommagetal tussen 0 en 1. \\
	\hline
	stop & Een tekstwaarde (woord/symbool) tot waar het model zal genereren. When the model generates a string that matches any of the specified strings, it stops generating text. & Een lijst van string-waarden, of een enkele string. \\
	\hline
	presence\_penalty & Factor die bepaalt hoe regelmatig woorden voorkomen. & Een kommagetal tussen 0 en 1 \\
	\hline
\end{tabular}

\subsection{Bing AI}

Microsoft en OpenAI werken nauw samen. Zo maakt het conversationele taalmodel van Bing ook gebruik van GPT-3. Deze chatbot bouwt verder en biedt zo verwijzingen en referenties aan naar andere websites. Deze verwijzingen zijn volgens mogelijk door de Prometheus-technologie van Microsoft \autocite{Ribas2023}.

Prometheus is een eigen technologie die door Bing is ontwikkeld. Het AI-model is volgens \textcite{Ribas2023} de eerste van zijn soort die de Bing-index-, ranking- en antwoordresultaten combineert met het redeneervermogen van OpenAI’s GPT-modellen. Prometheus maakt gebruik van de kracht van Bing en GPT om iteratief via een component genaamd \textit{Bing Orchestrator} een set interne queries te genereren met als doel binnen gegeven gesprekscontext een nauwkeurig antwoord op gebruikersqueries te bieden \autocite{Ribas2023}.

\begin{figure}[H]
	\includegraphics[width=6cm]{img/bing-ai-prometheus.png}
	\caption{Afbeelding van \textcite{Ribas2023}.}
\end{figure}

Bing AI is nu in testfase met wachtlijst en bestaat in de vorm van een webpagina en een browserextensie voor Microsoft Edge. Onderzoek naar deze chatbot staat nog in de kinderschoenen en er is nood aan onderzoek naar de credibiliteit en correctheid van de verwijzingen. Deze chatbot gebruikt een combinatie van extraherende en abstraherende samenvattingen. In tegenstelling tot GPT-3 is er geen officiële API beschikbaar. Daarnaast is de limiet ook lager met 2000 tokens per bericht tijdens een conversatie. 

\begin{figure}[H]
	\includegraphics{img/bing-ai-chatbot-example.png}
	\caption{In deze afbeelding wordt er een online wetenschappelijk artikel meegegeven. Er wordt geen titel of onderwerp meegegeven, maar de Bing AI chatbot is in staat om een abstraherende samenvatting te maken van het artikel. Daarna geeft de chatbot verder uitleg over een bepaald onderwerp en geeft het extra referenties mee.}
\end{figure}


Het bedrijf DuckDuckGo dat instaat voor de gelijknamige zoekmachine probeert een gelijkaardig initiatief. Met \textit{DuckAssist} biedt de onderneming een eigen AI-oplossing aan om een algemene doelgroep te ondersteunen bij het opzoeken van (nieuwe) informatie. Zij halen informatie direct uit enkel Wikipedia pagina's \autocite{Weinberg2023}. Daarnaast maakt dit DuckAssist ook gebruik van het GPT-3 model. Nadelig heeft deze toepassing voorlopig beschikking tot een kleinere zoekruimte dan Bing AI, wat gebruik maakt van meer sites inclusief onderzoekssites zoals ResearchGate \autocite{Mcauliffe2023}. Deze beperkte zoekruimte reduceert de kans op incorrecte of foutieve informatie volgens \textcite{Weinberg2023}, al is dit eerder een intuïtie van het bedrijf.


\subsection{Meta LLaMa}

Ten slotte is \textit{\textit{Large Language Model Meta AI}} of LLaMa) van Meta een generatief taalmodel in dezelfde lijn als de vooraf vermelde taalmodellen. Meta omschrijft LLaMa als een "kleiner foundation model". Het doel van Meta is om een even groot taalmodel als GPT-3 te lanceren met minder rekenkracht en nodige middelen. Dit taalmodel staat in de kinderschoenen en is nog niet beschikbaar in de vorm van online webtoepassing of online API \autocite{Hern2023, Touvron2023}. LLaMa toont potentieel, want bij het experiment van \textcite{Touvron2023} is LLaMa sterker dan GPT-3 en soortgenoten, terwijl het van tien keer minder parameters gebruik maakt.

\subsection{Samenvattend schema AI NLP-modellen}

\subsection{Conclusie}

Experten halen het GPT-3 model en ChatGPT aan als de toekomst voor gepersonaliseerde en adaptieve uitleg aan scholieren. Bing AI biedt een extra dat revolutionair kan zijn bij het opzoeken van uitleg voor zoektermen, zonder het verlies aan bronvermelding. Huidige toepassingen staan mogelijks in een spreekwoordelijke schaduw eenmaal leessoftware voor scholieren met dyslexie worden ontwikkeld met AI. De mogelijkheden van GPT-3 zijn eindeloos en toepassingen die hiervan gebruik maken, kunnen in het onderwijs ingezet worden als ondersteunende software.

\section{Conclusie}

De noden van scholieren met fonologische dyslexie in de derde graad van het middelbaar gaan verder dan gewoon moeizaam lezen.  Het ontcijferen en automatiseren van woordeherkenning gebeurt langzaam. Er zijn bewezen voordelen van manuele tekstvereenvoudiging en adaptieve visuele weergaven op kinderen en jongeren met dyslexie. % todo

De leesbaarheid van wetenschappelijke artikelen bevindt zich in een neergaande trend. Het formaat, gebruik van vakjargon en ingewikkelde woordenschat en ten slotte de moeizame syntax en zinsbouw sluiten een algemene doelgroep uit bij het lezen van wetenschappelijke artikelen. Enkel wetenschappelijk geletterden zijn in staat om deze artikelen te lezen. Het uniforme formaat van een wetenschappelijk artikel biedt kansen aan voor een geautomatiseerde aanpak tot het vereenvoudigen van een tekst.

Experten halen meerdere bewezen tactieken aan om teksten automatisch te vereenvoudigen op maat voor een scholier met dyslexie. Handmatig worden teksten vereenvoudigd aan de hand van leesbaarheidsformules of intuïtie. Zinnen moeten lexicaal, syntactisch en semantisch worden vereenvoudigd. Teksten samenvatten maakt de tekst korter zonder het verlies van de kernboodschap. Voor deze vier transformaties zijn er taalmodellen beschikbaar in de vorm van API's of open-source software.

Huidige software dat de overheid uitleent aan scholieren met dyslexie in het middelbaar onderwijs dient vooral als voorleessoftware en bevat nu geen functie dat teksten kan vereenvoudigen. Nieuwe en opkomende technologieën zoals het GPT-3 taalmodel bieden de mogelijkheid wel aan. De ontwikkeling van tools met dit taalmodel is in opmars, maar ontwikkelaars moeten bewust zijn dat andere taalmodellen zoals BERT voor taken zoals semantische analyse minder rekenkracht vereisen voor eenzelfde en soms beter resultaat. 

% Onderzoeksvragen beantwoorden.
% wat moet een applicatie zeker hebben om scholieren met dyslexie te ondersteunen?
% brengt GPT-3 hier een meerwaarde? -- hoe inzetten?


% 
% 
% 
% 
% 