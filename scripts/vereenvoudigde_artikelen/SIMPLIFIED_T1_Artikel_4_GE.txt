Over de impact van kunstmatige intelligentie op banen en seksuele discriminatie wordt veel gedebatteerd. De huidige paper onderzoekt het mogelijke verband tussen kunstmatige intelligentie en seksuele discriminatie. De paper levert ook bewijs dat discriminatie nog steeds een belangrijke vorm van discriminatie isHoewel volgens de federale wetgeving discriminatie op grond van geslacht op het werk illegaal is, komt dergelijke discriminatie nog steeds voor op het werkveld en is het altijd verborgen gebleven onder de norm.Zo heeft 42% van de vrouwen in de Verenigde Staten tijdens het werk te maken gehad met discriminatie op grond van geslacht.Een van de doelen van het creëren van AI is om te helpen met diversiteit, om problemen als discriminatie en racisme op te lossen. Of het werkt zoals mensen voorspelden, is echter nog een vraagteken.Het probleem is dat als AI en automatisering niet op een genderverantwoordelijke manier worden gebruikt, dit de reeds bestaande gendervooroordelen kan versterken. Dit kan leiden tot verdere discriminatieVanwege een betere productiviteit en lagere kosten en arbeidskrachten, is het niet moeilijk voor te stellen dat AI-technologie in de toekomst dieper zou worden betrokken bij productie en banen in het algemeen.Automatisering in banen kan vrouwen helpen betere beslissingen te nemen over hun leven. Big data en algoritmen in computers kunnen helpen bij het nemen van beslissingenDe bezorgdheid over het vervangen van banen, het geautomatiseerde aanwervingssysteem, het vrijgeven van privacy-informatie aan het publiek, slecht geselecteerde trainingsgegevens, het probleem met het ontwerp van algoritmen en het probleem als gevolg van gegevensongelijkheid zouden allemaal seksuele discriminatie veroorzaken of beïnvloeden.De veranderingen veroorzaakt door kunstmatige intelligentie zullen waarschijnlijk leiden tot sociale orde, rechtvaardigheid en gelijkheid. Om dit te laten gebeuren, moeten bedrijven en overheden actie ondernemen.De eerste stap is het identificeren van de oorzaak van het probleemAutomation is een bedrijf dat maakt en verkooptHet effect van de inwerkingtreding van de wetHoewel de wereld wordt geconfronteerd met een ongekende groei in zowel banen als economie, heeft automatisering nog steeds een groot potentieel om tal van banen te vervangen, en vooral die technologieën zijn repetitief en hebben in vergelijking daarmee weinig menselijke interactie.De automatiseringskosten zouden ook een van de overwegingen zijn.Er wordt een hoog vervangingspercentage verwacht voor werknemers die betrokken zijn bij voorspelbare taken en activiteiten.De vraag is wat dit betekent voor vrouwen en meisjes en hoe dit zich verhoudt tot discriminatie op grond van geslacht.Hoewel er een grotere kans is dat het werk van vrouwen vatbaar is voor gedeeltelijke automatisering dan dat het volledig wordt vervangen.McKinsey's toekomstige voorspelling van vrouwentradities tegen 2030 stelt dat ongeveer 40 miljoen tot 160 miljoen vrouwen mogelijk moeten overstappen van beroep en vaardigheden om aan het werk te blijven.4Dit aantal bevestigde ook de behoefte aan hoger onderwijs en verschillende vaardigheden voor succes.Het is 7 tot 24 procent van de vrouwen dat momenteel werkt, vergeleken met het bereik van 8 tot 28 procent voor mannen.Vrouwen kunnen profiteren van overgangsmogelijkheden om hun huidige aandeel in de werkgelegenheid te behouden.Als ze dat niet kunnen, kan de ongelijkheid tussen mannen en vrouwen op het werk verergeren.Veel vrouwen zouden te maken kunnen krijgen met een steeds groter wordende loonkloof ten opzichte van mannen als ze de noodzakelijke overgang niet kunnen maken.Sinds we het over automatisering hebben, zou het STEM-veld in de toekomst een grotere kans hebben op arbeidsvereisten.Uit de gegevens van 2019 bleek echter dat vrouwen slechts 27% van de werknemers in STEM-gekwalificeerde sectoren uitmaken, om nog maar te zwijgen van het feit dat vrouwen gemiddeld 19% minder verdienden dan mannen. Om nog maar te zwijgen, aangezien 78% van de AI-professionals mannen zijn, worden algoritmen gemaakt met door mannen gedomineerde ervaringen.Dergelijke gendervooroordelen kunnen aanzienlijk nadelig zijn voor vrouwelijke werkgevers of cv's.Hoewel robotisering en automatisering op het werkveld beide geslachten zouden beïnvloeden, is het waarschijnlijk dat gendervooroordelen een rol spelen en vrouwen onevenredig treffen.Volgens een rapport van het Women's Institute zouden vrouwen in risicovolle automatiseringssectoren meer te lijden kunnen hebben onder discriminatieHet gebrek aan mobiliteit en flexibiliteit kan voor bedrijven ook een reden zijn om vrouwen werkloos te maken of onderhandelingsposities in te krimpen.De risico's bij automatisering zijn reëel. Ze groeien exponentieel. Het internet isDe Amerikaanse Equal Employment Opportunity Commission onderzoekt ten minste twee gevallen van algoritmen die mogelijk discriminerend zijn voor bepaalde groepen sollicitanten. [6] De Commissie onderzoekt de beweringenOm seksuele discriminatie te voorkomen, moet het onderwijssysteem vanaf het begin veranderen om discriminatie te stoppen, meer kansen en ondersteuning te bieden aan het STEM-veld en toekomstige banenaanvullingen als gevolg van automatisering.Het probleem is dat het cellulaire immuunsysteem geenBig data-analyse en algoritmen zouden ook van invloed zijn op discriminatie in beroepen, het zou het traditionele wervingsproces kunnen omdraaien.Omdat de applicatie is gebaseerd op het verzamelen van big data, is het heel gemakkelijk te begrijpen.Als een AI-toepassing wordt getraind op biasgegevens, zijn de algoritmen waarschijnlijk vertekend.Dit gaat niet alleen over cijfers, school of capaciteiten. Het betekent ook dat mensen niet alleen maar goede cijfers willen halenIn de inhoud van het verzamelen van meer soorten gegevens, zouden de metadata van de sociale media-inhoud, familieleden, alles wat op afstand relevant is, allemaal een tweesnijdend zwaard zijn.Alle online informatie kan worden gebruikt om personen te identificeren, maar de privacywet is niet ontworpen om na te gaan welke persoonlijke informatie deze moet beschermen en hoe deze moet worden beschermd[7].De rekruteringstool die Amazon sinds 2014 heeft ontwikkeld, zou een van de voorbeelden kunnen zijn.Het programma werd vermoedelijk gebruikt om de cv's van sollicitanten te bekijken om te zoeken naar de mensen met de beste capaciteiten.Hoewel het doel was om een ​​genderneutraal systeem te creëren, werd het resultaat overwegend door mannen gedomineerd.Het systeem van Amazon heeft cv's die het woord 'vrouwen' bevatten automatisch gedowngraded in hun sollicitaties. Het probleem is dat veel mensen het woord "Amazon hernoemde de tool na de controverse, maar de tool werd nog steeds gebruikt door recruiters om kandidaten te evalueren. [8,9] Het bedrijf is niet helemaal duidelijk over wat de tool wel of niet deed. Het probleem is nog steeds een punt van zorg voor bedrijven die de tool gebruiken om te wervenDit zou geen uitzondering zijn, andere bedrijven die AI-automatisering gebruiken, zouden met hetzelfde probleem worden geconfronteerd.Ondanks deze zorgen zijn er nog steeds meer bedrijven die hard aan het werk zijn om meer delen van werving en aanwerving te automatiseren.De softwareontwikkelaars van het bedrijf zouden het systeem actief moeten monitoren om ervoor te zorgen dat zoiets niet gebeurt.Wanneer de omvang van het kunstmatige-intelligentiesysteem enorm is en de software achter een dashboard verborgen beslissingen neemt, bestaat de kans op ernstige juridische problemen.Het is onwettig om een ​​werknemer of kandidaat te discrimineren op grond van ras, huidskleur, religie, geslacht (inclusief genderidentiteit, seksuele geaardheid en zwangerschap), nationale afkomst, leeftijd (40 jaar of ouder), handicap of genetische informatie.Het is ook onwettig om wraak te nemen op een persoon omdat hij of zij heeft geklaagd over discriminatie, een aanklacht wegens discriminatie heeft ingediend of heeft deelgenomen aan een onderzoek naar of een rechtszaak over discriminatie op het werk.[10]Wanneer de informatie echter onbedoeld wordt opgenomen en beoordeeld door bedrijven, zou dit vanwege het verantwoordelijkheidsprobleem meerdere vragen oproepen. IMPACT ALS ALGORITMEN Algoritmen zouden kunnen leidenWanneer we op Google naar 'CEO' zoeken, levert het overwegend mannelijke afbeeldingen op, we zeggen tegen onszelf dat Google alleen maar de wereld voor ons weerspiegelt - een wereld waar discriminatie bestaat.Wij zijn van mening dat de Google-bots die het web doorzoeken kleuren- en genderblind zijn.We vertrouwen erop dat de algoritmen die onze zoekopdrachten beantwoorden objectiever zijn dan mensen.Het is onmogelijk om aan te voeren dat het zoekalgoritme van Google en de bijbehorende platformen voor het weergeven van advertenties inherent bevooroordeeld zijn.Hoewel ze mogelijk zijn ontworpen om vooringenomenheid te verminderen, drijven de meeste wervingsalgoritmen standaard nog steeds in de richting van vooringenomenheid. Dit betekent dat wanneer een kandidaat wordt aangenomenUit een recent onderzoek van Northeastern University en USC bleek dat breed gerichte advertenties op Facebook voor posities van kassamedewerkers in supermarkten werden getoond aan een publiek van 85% vrouwen.(11) Dit komt omdat het gemiddeldeAdvances in Social Science, Education and Humanities Research, volume 554 859 algoritmen introduceren vertekening in het systeem zonder menselijke tussenkomst.Om diversiteit in invoergegevens te waarborgen, zou het verzamelen van meer trainingsgegevens, specifiek met gevoelige groepen, oneerlijkheid helpen voorkomen.Google versterkt ook seksuele discriminatie met behulp van het algoritme en het laat zien dat AdFisher, een geautomatiseerde tool die onderzoekt hoe gebruikersgedrag, Google-advertenties en advertentie-instellingen op elkaar inwerken, discriminatie op grond van geslacht kan detecteren.AdFisher is een open source-tool waarmee onderzoekers een hypothesegestuurd ontwerp van online advertentiecampagnes kunnen testen. Het kan rennenAdvertentie-instellingen is een functie van Facebook waarmee een gebruiker kan bepalen hoe advertenties in zijn profiel worden weergegeven. Deze functie is niet overal beschikbaarWanneer u het geslacht op vrouwelijk instelt, krijgt u minder exemplaren van een advertentie met betrekking tot goedbetaalde banen dan wanneer u deze op mannen instelt.Enkele mogelijke redenen kunnen zijn dat Google het systeem expliciet programmeert om de advertentie minder vaak aan vrouwen te laten zien.Het targeting-algoritme van Google reageert op dit verschil, dus advertenties worden meer aan mannen dan aan vrouwen getoond. Google ontdekte bijvoorbeeld dat mannen eerder op deze advertentie klikken dan vrouwen.Meer concurrentie voor advertenties voor vrouwen zorgt ervoor dat de adverteerder minder advertentieruimtes voor vrouwen wint.Sommige derden (bijvoorbeeld een hacker) manipuleren het advertentie-ecosysteem. Dit betekent datEen onderzoekspaper gebaseerd op een veldtest van een advertentie die bedoeld was om vacatures en opleidingen in STEM (wetenschap, technologie, engineering en wiskunde) te promoten. Voor het onderzoek is gebruik gemaakt van administratieve gegevens vanDe advertentie was bedoeld om genderneutraal te zijn en was neutraal getarget.Deze advertentie is getest in 191 landen over de hele wereld.Empirisch gezien werd de advertentie echter aan 20% meer mannen getoond dan aan vrouwen.[12]Veel factoren dragen ertoe bij dat het resultaatalgoritme probeert het aantal klikken te maximaliseren, waardoor advertenties meer aan mannen dan aan vrouwen worden getoond, of vrouwen bezoeken minder snel websites met advertenties erop.Het probleem is dat vrouwen al op veel manieren worden gediscrimineerd, zelfs in STEM-richtingen. algoritmen zijn ontworpen om het voor vrouwen moeilijker te maken om STEM-vakken te betreden, en zo het aantal seksuele discriminatie te verhogen. De algoritmen zelfOm diversiteit in invoergegevens te waarborgen, zou het verzamelen van meer trainingsgegevens, specifiek met gevoelige groepen, oneerlijkheid helpen voorkomen.SUGGESTION
Companies should invest in training and reskilling, provide possible training and apprenticeship programs for women.Also, companies and the government could consider reskilling opportunities for mid career women or women returning to the workforce.Companies should subsidize transition costs, government or corporate reskilling subsidies for targeted occupations and sectors.Community and governments could provide childcare subsidies for parents undergoing reskilling or pursuing higher education.Governments could invest in digital platforms, industry partnerships with massive open online courses.Companies should increase transparency on labour demand trends, contribute to more technical school or university curriculums co-created with industry, invest in informational campaigns targeting women.
Data testing: Put in place AI development standards, testing procedures, controls, and other technical governance elements designed to make sure the data used in training AI applications are thoroughly vetted and certified against a biased perspective before the application goes into production.Output testing: Establish testing requirements and controls around the outputs produced or decisions made by the AI.
Review and challenge these outputs and decisions against a biased perspective to make sure they represent fair and positive outcomes that are in line with expectations and do not adversely and unfairly impact any group of people.Development teams: Make sure AI design and development teams are diverse and include female data scientists, programmers, designers, and other key team members who influence how an AI application is developed.Set targets and put in place training, recruiting, and rotation programs to move toward this target.
CONCLUSION
Since automation is the major trend in the future, companies and the government should be double careful with the use of it.The effect of biased data, algorithms in the workforce could turnover the equality in the workforce.Thus companies must develop and deploy AI applications in a responsible manner that proactively seeks to identify and eliminate existing societal biases so they are not encoded and amplified in the digital world.Toward this goal, these are some future suggestions for companies and the government.It is important to note that, even though the focus of this essay is gender bias, AI applications can and often do suffer from different types of societal biases, for example, around race, ethnicity, and religion.As a result, companies should expand the above efforts and measures to make sure the AI applications they put in place do not hurt any group of people.
AI has the potential to mitigate the corporate gender and leadership gaps by removing bias in recruiting,
Advances in SocialOver de impact van kunstmatige intelligentie op banen en seksuele discriminatie wordt veel gedebatteerd. De huidige paper onderzoekt het mogelijke verband tussen kunstmatige intelligentie en seksuele discriminatie. De paper levert ook bewijs dat discriminatie nog steeds een belangrijke vorm van discriminatie isHoewel volgens de federale wetgeving discriminatie op grond van geslacht op het werk illegaal is, komt dergelijke discriminatie nog steeds voor op het werkveld en is het altijd verborgen gebleven onder de norm.Zo heeft 42% van de vrouwen in de Verenigde Staten tijdens het werk te maken gehad met discriminatie op grond van geslacht.Een van de doelen van het creëren van AI is om te helpen met diversiteit, om problemen als discriminatie en racisme op te lossen. Of het werkt zoals mensen voorspelden, is echter nog een vraagteken.Het probleem is dat als AI en automatisering niet op een genderverantwoordelijke manier worden gebruikt, dit de reeds bestaande gendervooroordelen kan versterken. Dit kan leiden tot verdere discriminatieVanwege een betere productiviteit en lagere kosten en arbeidskrachten, is het niet moeilijk voor te stellen dat AI-technologie in de toekomst dieper zou worden betrokken bij productie en banen in het algemeen.Automatisering in banen kan vrouwen helpen betere beslissingen te nemen over hun leven. Big data en algoritmen in computers kunnen helpen bij het nemen van beslissingenDe bezorgdheid over het vervangen van banen, het geautomatiseerde aanwervingssysteem, het vrijgeven van privacy-informatie aan het publiek, slecht geselecteerde trainingsgegevens, het probleem met het ontwerp van algoritmen en het probleem als gevolg van gegevensongelijkheid zouden allemaal seksuele discriminatie veroorzaken of beïnvloeden.De veranderingen veroorzaakt door kunstmatige intelligentie zullen waarschijnlijk leiden tot sociale orde, rechtvaardigheid en gelijkheid. Om dit te laten gebeuren, moeten bedrijven en overheden actie ondernemen.De eerste stap is het identificeren van de oorzaak van het probleemAutomation is een bedrijf dat maakt en verkooptHet effect van de inwerkingtreding van de wetHoewel de wereld wordt geconfronteerd met een ongekende groei in zowel banen als economie, heeft automatisering nog steeds een groot potentieel om tal van banen te vervangen, en vooral die technologieën zijn repetitief en hebben in vergelijking daarmee weinig menselijke interactie.De automatiseringskosten zouden ook een van de overwegingen zijn.Er wordt een hoog vervangingspercentage verwacht voor werknemers die betrokken zijn bij voorspelbare taken en activiteiten.De vraag is wat dit betekent voor vrouwen en meisjes en hoe dit zich verhoudt tot discriminatie op grond van geslacht.Hoewel er een grotere kans is dat het werk van vrouwen vatbaar is voor gedeeltelijke automatisering dan dat het volledig wordt vervangen.McKinsey's toekomstige voorspelling van vrouwentradities tegen 2030 stelt dat ongeveer 40 miljoen tot 160 miljoen vrouwen mogelijk moeten overstappen van beroep en vaardigheden om aan het werk te blijven.4Dit aantal bevestigde ook de behoefte aan hoger onderwijs en verschillende vaardigheden voor succes.Het is 7 tot 24 procent van de vrouwen dat momenteel werkt, vergeleken met het bereik van 8 tot 28 procent voor mannen.Vrouwen kunnen profiteren van overgangsmogelijkheden om hun huidige aandeel in de werkgelegenheid te behouden.Als ze dat niet kunnen, kan de ongelijkheid tussen mannen en vrouwen op het werk verergeren.Veel vrouwen zouden te maken kunnen krijgen met een steeds groter wordende loonkloof ten opzichte van mannen als ze de noodzakelijke overgang niet kunnen maken.Sinds we het over automatisering hebben, zou het STEM-veld in de toekomst een grotere kans hebben op arbeidsvereisten.Uit de gegevens van 2019 bleek echter dat vrouwen slechts 27% van de werknemers in STEM-gekwalificeerde sectoren uitmaken, om nog maar te zwijgen van het feit dat vrouwen gemiddeld 19% minder verdienden dan mannen. Om nog maar te zwijgen, aangezien 78% van de AI-professionals mannen zijn, worden algoritmen gemaakt met door mannen gedomineerde ervaringen.Dergelijke gendervooroordelen kunnen aanzienlijk nadelig zijn voor vrouwelijke werkgevers of cv's.Hoewel robotisering en automatisering op het werkveld beide geslachten zouden beïnvloeden, is het waarschijnlijk dat gendervooroordelen een rol spelen en vrouwen onevenredig treffen.Volgens een rapport van het Women's Institute zouden vrouwen in risicovolle automatiseringssectoren meer te lijden kunnen hebben onder discriminatieHet gebrek aan mobiliteit en flexibiliteit kan voor bedrijven ook een reden zijn om vrouwen werkloos te maken of onderhandelingsposities in te krimpen.De risico's bij automatisering zijn reëel. Ze groeien exponentieel. Het internet isDe Amerikaanse Equal Employment Opportunity Commission onderzoekt ten minste twee gevallen van algoritmen die mogelijk discriminerend zijn voor bepaalde groepen sollicitanten. [6] De Commissie onderzoekt de beweringenOm seksuele discriminatie te voorkomen, moet het onderwijssysteem vanaf het begin veranderen om discriminatie te stoppen, meer kansen en ondersteuning te bieden aan het STEM-veld en toekomstige banenaanvullingen als gevolg van automatisering.Het probleem is dat het cellulaire immuunsysteem geenBig data-analyse en algoritmen zouden ook van invloed zijn op discriminatie in beroepen, het zou het traditionele wervingsproces kunnen omdraaien.Omdat de applicatie is gebaseerd op het verzamelen van big data, is het heel gemakkelijk te begrijpen.Als een AI-toepassing wordt getraind op biasgegevens, zijn de algoritmen waarschijnlijk vertekend.Dit gaat niet alleen over cijfers, school of capaciteiten. Het betekent ook dat mensen niet alleen maar goede cijfers willen halenIn de inhoud van het verzamelen van meer soorten gegevens, zouden de metadata van de sociale media-inhoud, familieleden, alles wat op afstand relevant is, allemaal een tweesnijdend zwaard zijn.Alle online informatie kan worden gebruikt om personen te identificeren, maar de privacywet is niet ontworpen om na te gaan welke persoonlijke informatie deze moet beschermen en hoe deze moet worden beschermd[7].De rekruteringstool die Amazon sinds 2014 heeft ontwikkeld, zou een van de voorbeelden kunnen zijn.Het programma werd vermoedelijk gebruikt om de cv's van sollicitanten te bekijken om te zoeken naar de mensen met de beste capaciteiten.Hoewel het doel was om een ​​genderneutraal systeem te creëren, werd het resultaat overwegend door mannen gedomineerd.Het systeem van Amazon heeft cv's die het woord 'vrouwen' bevatten automatisch gedowngraded in hun sollicitaties. Het probleem is dat veel mensen het woord "Amazon hernoemde de tool na de controverse, maar de tool werd nog steeds gebruikt door recruiters om kandidaten te evalueren. [8,9] Het bedrijf is niet helemaal duidelijk over wat de tool wel of niet deed. Het probleem is nog steeds een punt van zorg voor bedrijven die de tool gebruiken om te wervenDit zou geen uitzondering zijn, andere bedrijven die AI-automatisering gebruiken, zouden met hetzelfde probleem worden geconfronteerd.Ondanks deze zorgen zijn er nog steeds meer bedrijven die hard aan het werk zijn om meer delen van werving en aanwerving te automatiseren.De softwareontwikkelaars van het bedrijf zouden het systeem actief moeten monitoren om ervoor te zorgen dat zoiets niet gebeurt.Wanneer de omvang van het kunstmatige-intelligentiesysteem enorm is en de software achter een dashboard verborgen beslissingen neemt, bestaat de kans op ernstige juridische problemen.Het is onwettig om een ​​werknemer of kandidaat te discrimineren op grond van ras, huidskleur, religie, geslacht (inclusief genderidentiteit, seksuele geaardheid en zwangerschap), nationale afkomst, leeftijd (40 jaar of ouder), handicap of genetische informatie.Het is ook onwettig om wraak te nemen op een persoon omdat hij of zij heeft geklaagd over discriminatie, een aanklacht wegens discriminatie heeft ingediend of heeft deelgenomen aan een onderzoek naar of een rechtszaak over discriminatie op het werk.[10]Wanneer de informatie echter onbedoeld wordt opgenomen en beoordeeld door bedrijven, zou dit vanwege het verantwoordelijkheidsprobleem meerdere vragen oproepen. IMPACT ALS ALGORITMEN Algoritmen zouden kunnen leidenWanneer we op Google naar 'CEO' zoeken, levert het overwegend mannelijke afbeeldingen op, we zeggen tegen onszelf dat Google alleen maar de wereld voor ons weerspiegelt - een wereld waar discriminatie bestaat.Wij zijn van mening dat de Google-bots die het web doorzoeken kleuren- en genderblind zijn.We vertrouwen erop dat de algoritmen die onze zoekopdrachten beantwoorden objectiever zijn dan mensen.Het is onmogelijk om aan te voeren dat het zoekalgoritme van Google en de bijbehorende platformen voor het weergeven van advertenties inherent bevooroordeeld zijn.Hoewel ze mogelijk zijn ontworpen om vooringenomenheid te verminderen, drijven de meeste wervingsalgoritmen standaard nog steeds in de richting van vooringenomenheid. Dit betekent dat wanneer een kandidaat wordt aangenomenUit een recent onderzoek van Northeastern University en USC bleek dat breed gerichte advertenties op Facebook voor posities van kassamedewerkers in supermarkten werden getoond aan een publiek van 85% vrouwen.(11) Dit komt omdat het gemiddeldeAdvances in Social Science, Education and Humanities Research, volume 554 859 algoritmen introduceren vertekening in het systeem zonder menselijke tussenkomst.Om diversiteit in invoergegevens te waarborgen, zou het verzamelen van meer trainingsgegevens, specifiek met gevoelige groepen, oneerlijkheid helpen voorkomen.Google versterkt ook seksuele discriminatie met behulp van het algoritme en het laat zien dat AdFisher, een geautomatiseerde tool die onderzoekt hoe gebruikersgedrag, Google-advertenties en advertentie-instellingen op elkaar inwerken, discriminatie op grond van geslacht kan detecteren.AdFisher is een open source-tool waarmee onderzoekers een hypothesegestuurd ontwerp van online advertentiecampagnes kunnen testen. Het kan rennenAdvertentie-instellingen is een functie van Facebook waarmee een gebruiker kan bepalen hoe advertenties in zijn profiel worden weergegeven. Deze functie is niet overal beschikbaarWanneer u het geslacht op vrouwelijk instelt, krijgt u minder exemplaren van een advertentie met betrekking tot goedbetaalde banen dan wanneer u deze op mannen instelt.Enkele mogelijke redenen kunnen zijn dat Google het systeem expliciet programmeert om de advertentie minder vaak aan vrouwen te laten zien.Het targeting-algoritme van Google reageert op dit verschil, dus advertenties worden meer aan mannen dan aan vrouwen getoond. Google ontdekte bijvoorbeeld dat mannen eerder op deze advertentie klikken dan vrouwen.Meer concurrentie voor advertenties voor vrouwen zorgt ervoor dat de adverteerder minder advertentieruimtes voor vrouwen wint.Sommige derden (bijvoorbeeld een hacker) manipuleren het advertentie-ecosysteem. Dit betekent datEen onderzoekspaper gebaseerd op een veldtest van een advertentie die bedoeld was om vacatures en opleidingen in STEM (wetenschap, technologie, engineering en wiskunde) te promoten. Voor het onderzoek is gebruik gemaakt van administratieve gegevens vanDe advertentie was bedoeld om genderneutraal te zijn en was neutraal getarget.Deze advertentie is getest in 191 landen over de hele wereld.Empirisch gezien werd de advertentie echter aan 20% meer mannen getoond dan aan vrouwen.[12]Veel factoren dragen ertoe bij dat het resultaatalgoritme probeert het aantal klikken te maximaliseren, waardoor advertenties meer aan mannen dan aan vrouwen worden getoond, of vrouwen bezoeken minder snel websites met advertenties erop.Het probleem is dat vrouwen al op veel manieren worden gediscrimineerd, zelfs in STEM-richtingen. algoritmen zijn ontworpen om het voor vrouwen moeilijker te maken om STEM-vakken te betreden, en zo het aantal seksuele discriminatie te verhogen. De algoritmen zelfOm diversiteit in invoergegevens te waarborgen, zou het verzamelen van meer trainingsgegevens, specifiek met gevoelige groepen, oneerlijkheid helpen voorkomen.De regering moet de opleiding en omscholing van vrouwen in de particuliere sector ondersteunen.De overheid en bedrijven zouden ook moeten overwegen om vrouwen in het midden van hun loopbaan en vrouwen die weer aan het werk gaan, om te scholen.De particuliere sector zou moeten betalen voor transitiekosten, overheids- of bedrijfsomscholingssubsidies voor specifieke beroepen en sectoren.De gemeenschap en regeringen zouden subsidies kunnen verstrekken aan ouders die een omscholing volgen of hoger onderwijs volgen.Governments could invest in digital platforms, industry partnerships with massive open online courses.bedrijven moeten de transparantie over trends in de vraag naar arbeid vergroten, bijdragen aan meer leerplannen voor technische scholen of universiteiten die in samenwerking met het bedrijfsleven zijn ontwikkeld, investeren in voorlichtingscampagnes gericht op vrouwen.