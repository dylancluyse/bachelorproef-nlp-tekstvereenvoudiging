Sinds het einde van de 20e eeuw hebben technologische ontwikkelingen nieuwe mogelijkheden gecreëerd voor het verzamelen en analyseren van data. Data-analyse is belangrijker dan ooit geworden. Als laatsteDe politie maakt al geruime tijd gebruik van machine learning-technieken in hun onderzoeken. Het gebruik van big data en de toenemende mogelijkheden van kunstmatige intelligentie (AI) in de 21e eeuw heeft dat welHet probleem is dat het belangrijkste is omDe politie gebruikt verschillende technologieën om mensen te volgen en vast te leggen, waaronder kunstmatige intelligentie en gezichtsherkenningssystemen. Deze technologieën kunnenDeze systemen zijn ontworpen om de meest relevante informatie uit grote hoeveelheden data te halen. Ze zijn in staat om: (i) gestructureerde en ongestructureerde gegevens te classificeren, op te slaan, te combineren en te doorzoeken; (ii) vergelijk vastgelegde gegevens met andere gegevens en vindHet probleem is dat het cellulaire immuunsysteem geen bescherming biedtalgoritmen voor machine learning gebruiken om te proberen patronen en bruikbare kennis in big data-sets te voorspellen.Ondanks de toegenomen regulering3, die tot doel heeft de democratische waarborgen van algoritmische surveillance te waarborgen, lijkt dit eerder het gebruik ervan te stimuleren.Het gebruik van 'intelligent' cameratoezicht is sterk toegenomen in België, maar ook in andere Europese landen. Bijvoorbeeld de forse stijgingDit roept de vraag op of de huidige controlemechanismen voldoende zijn om alle burgers te beschermen tegen de mogelijke gevolgen van het gebruik van algoritmisch toezicht door de politie.Het gebruik van algoritmisch toezicht bij de politie wordt steeds belangrijker. De huidige controle- en handhavingsmechanismen voor het gebruik van algoritmisch toezicht door de politie zijn niet robuust genoeg. Dit artikel suggereert dat een meerDe vraag of het bestaande structurele kader voor de behandeling van hiv/aids voldoende is om een ​​voldoende niveau van bescherming te bieden, is een fundamentele vraag op het gebied van hiv/aids-onderzoek. In de eersteIn het eerste deel zal ik kijken naar de huidige mechanismen voor het afdwingen van controle door de lens van relationele ethiek om te onderzoeken hoe we hiervan kunnen leren om controlemechanismen te heroverwegen. Het tweede gedeelte,algoritmisch toezicht bij de politie is een belangrijke sociaal-technische ontwikkeling op het gebied van politiewerk. Het is een reeks nieuwe technologieën die van invloed zijnDe versnippering en privatisering van de politie, 2) de democratisering van het toezicht, en 3) de toename van collectieve schade en sociale gevolgen maken allemaal deel uit vanDeze ontwikkelingen overlappen elkaar en zijn met elkaar verweven en moeten niet als afzonderlijke ontwikkelingen worden gezien.De hervorming van de politie is al lang een vast onderdeel van het regeringsbeleid. Het is gevormd door veranderingenSinds het einde van de 20e eeuw is de particuliere sector een belangrijke partner in de strijd tegen de criminaliteit in het Westen. In de afgelopen jaren is de rol van de particuliere sector in de politieDit komt grotendeels door de toegenomen macht en groei van de private sector en bezuinigingen in de publieke sector.De opkomst van big data en kunstmatige intelligentie in de 21e eeuw heeft geleid tot een toenemende macht van technologiebedrijven door onder meer 'surveillance capitalism', waarin dataverzameling een economische motor wordt voor bedrijven.Politiewerk wordt steeds meer platform policing, waarbij de politie gebruik maakt van digitale platformen en digitale opsporingstechnologie.8 Dit betekent dat de politieHet publiek is in toenemende mate afhankelijk geworden van de technologie-infrastructuur van technologiebedrijven, wat heeft geleid tot een verschuiving van de machtsverhoudingen van de publieke naar de private sector. Deze verschuiving heeft een negatieve invloed op transparantie en controle. Ten tweede kan een 'democratisering' van het toezicht worden herkend door een verschuiving van gericht toezicht naar grootschalig toezichtHet feit dat een veel groter deel van de bevolking nu onder toezicht staat, betekent dat de staat meer macht heeft dan ooit tevoren. Dit vergroot het risico op een toename van het vermogen vanWaar grootschalige surveillancepraktijken vroeger vooral door inlichtingendiensten12 of binnen een specifieke context zoals op de luchthaven werden uitgevoerd, spelen politiediensten, maar ook technologiebedrijven,In België bijvoorbeeld de forse uitbreiding van het gebruik van 'intelligente' camerabewaking voor allerlei doeleinden13, die verder werd aangewakkerd door de coronapandemie.14 Andere voorbeelden zijn de infiltratie van het versleutelde Encrochat-netwerk15, de gezichtsherkenningssoftware van Clearview AI , of de dataverzamelingspraktijken van Europol16 die door sommigen worden vergeleken met surveillancepraktijken van de Amerikaanse NSA.17 Denk ten slotte aan het gebruik van de spionagesoftware Pegasus om data te verzamelen van de mobiele telefoons van activisten, politici en journalisten over de hele wereld.Een big data-analyse is een analyse van grote datasets die inzichten uit de data haalt. Het gaat meestal om watEr worden dus op het eerste gezicht geen persoonsgegevens verwerkt.20 Wij gebruiken de volgende taal:Het resultaat is een toename van sociale stratificatie, resulterend in een ongelijke verhouding tussen sociale groepen.Omdat big data onregelmatigheden en anomalieën in datasets reproduceert, kan het leiden tot uitkomsten die een onevenredige impact hebben op bepaalde groepen of gemeenschappen. BijvoorbeeldDit kan dan leiden tot een cumulatief nadeel (discriminatie en oneerlijke behandeling) van bepaalde groepen in de samenleving, omdat deze, vaak kwetsbare, groepen bovengemiddeld het doelwit zijn van deze technologieën.Dit geldt vooral voor de politie: Predictive policing is een vorm vanDe politie wordt vaak teruggestuurd naar dezelfde wijken, ongeacht de criminaliteit.22 Dit komt doordat de steekproeffout erg laag is en omdat de criminaliteitDit leidt tot overpolitie en stigmatisering van bepaalde buurten en gemeenschappen die al het doelwit zijn.23 Deze risico's van discriminatie en stigmatisering door het gebruik van big data-analyses worden ook bevestigd in de uitspraak in Nederland over het gebruik van SyRI, een algoritmischDe uitspraak laat ook zien hoe big data-technologie ons kan helpen de wereld beter te begrijpen.Het draagt ​​bij aan de strafbaarstelling van armoede en ontbering en aan de toename van de ongelijkheid in de samenleving.24 Het verhoogt ook de mate van discriminatie en stigmatisering.Hier gaan we een grote beslissing nemenDrie socio-technische ontwikkelingen hebben de huidige controlemechanismen onder druk gezet: veranderingen in regeltechnologie, de opkomstDit artikel is een bijdrage aan het geredigeerde deel "Observations on the Control of Climate Change", dat zojuist is gepubliceerd. Ik begin met nadenken overIk doe dit vanuit de lens van relationele ethiek. Met andere woorden, ik zie relaties alsDit document biedt een uitgebreide analyse van de veranderende aard van controle- en handhavingsmechanismen in het digitale tijdperk. Het laat zienDe vraag rijst of het bestaande wettelijke kader volstaat om deze drie ontwikkelingen het hoofd te bieden en effectieve democratische waarborgen te bieden. Het antwoord is nee. De huidige situatie vraagt ​​eromHet huidige wettelijke kader wordt vandaag gevormd door de regels inzake gegevensbescherming.De controlemiddelen die momenteel worden gebruikt voor de verwerking van gegevens door middel van kunstmatige intelligentie (AI) zijn vaak beperkt in omvang. Dit document beschrijft een set van best practices voor het identificeren, vastleggen en opslaan van de personenbezogene gegevens die nodig zijn voor de verwerking vanDe focus ligt grotendeels op informatiebeveiliging en formele naleving van het wettelijk kader.Het Europees Hof voor de Rechten van de Mens heeft onlangs opgeroepen tot een meer alomvattende aanpak van de bescherming van grondrechten.25 Deze oproep tot een completere en completereDe manier waarop deze instrumenten in België werken is niet erg democratisch, omdat burgers en het maatschappelijk middenveld er niet bij betrokken zijn.Daarnaast is de politie niet verplicht om DPIA’s te publiceren conform de Richtlijn Politie en Justitie.Dit maakt publieke controle moeilijker.Er zijn ook geen normen waaraan DPIA’s moeten voldoen.Er zijn geen standaardprofielen voor functionarissen voor gegevensbescherming.Het huidige wettelijk kader betreft enkel toepassingen van algoritmisch toezicht die 'persoonsgegevens' verzamelen en verwerken.De Europese Unie heeft ondertussen een voorstel voor een AI-wet gepubliceerd die een tweeledig doel heeft: hetDe Commissie zal met de lidstaten samenwerken om ervoor te zorgen dat de Europese Unie de grondrechten van het individu beschermt tegen de nadelige effecten van AGI, evenals de harmonisatie van de regelgeving van de lidstaten omDe nadelige gevolgen van AI zijn onderverdeeld in risicocategorieën van laag naar hoog en naast risico's voor het individu spreekt de verordening ook over risico's voor de samenleving.De voorgestelde verordening is hoopvol, zowel wat betreft de inhoud als de handhaving ervan.Het geeft aan dat de lidstaten een of meer nationale bevoegde autoriteiten moeten aanwijzen om toezicht te houden op de toepassing en implementatie van AI en op te treden als officieel contactpunt voor het publiek en andere actoren.De verordening stelt ook dat “risicovolle autonome AI-toepassingen” moeten worden geregistreerd in een openbare EU-brede database en dat ze alleen op de Europese markt worden toegelaten als ze voldoen aan “bepaalde verplichte vereisten en een voorafgaande conformiteitsbeoordeling ondergaan”.28 De Commissie geeft ook aan dat er een systeem komt om risicovolle autonome AI-toepassingen te registreren in een openbare EU-brede database en dat ze alleen op de Europese markt worden toegelaten als ze voldoen aan “bepaalde verplichte eisen”.Hoe deze toetsen in de praktijk zullen worden toegepast en gehandhaafd, is nog onduidelijk.De Europese Unie heeft zich gecommitteerd aan de uitvoering van de milieu- en sociale doelstellingen van de Europese Unie.Ook op democratisch vlak schiet de regeling tekort, omdat burgers of het maatschappelijk middenveld niet betrokken zijn bij deze mechanismen.Bovendien zouden burgers geen klacht kunnen indienen bij de nationale toezichthoudende autoriteit als zij menen dat de wet niet wordt nageleefdIk stel een herinterpretatie voor van het idee van 'relationeel' politiewerk, geïnspireerd door de Ubuntu-filosofie, om na te gaan hoe technologie een nieuwe manier kan bieden om naar de controle van informatie te kijken. De reinterDe Ubuntu-filosofie is ontstaan ​​in Afrika bezuiden de Sahara en verspreidde zich naar Europa en het Midden-Oosten.31 Het verschilt van de traditionele rationele ethiek in de zin dat, in tegenstelling tot de rationele Kantiaanse ethiek, personen menselijke waardigheid hebben omdat ze het vermogen hebben om op een respectvolle manier met elkaar om te gaan. collectieve manier. Vanuit deze visie zijn mensenrechtenschendingen gericht op het ernstig aantasten van het vermogen van mensen tot gemeenschappelijke relaties, opgevat als identiteit en solidariteit; en menselijke waardigheid moet worden gezien als het menselijk vermogen om op een gemeenschappelijke manier met anderen om te gaan.Verschillende computerwetenschappers stellen een fundamentele verschuiving voor in het denken over algoritmische rechtvaardigheid en bestuur van AI van rationele ethiek naar relationele ethiek. Volgens Birhane dwingt relationele ethiek ons ​​om onze onderliggende werkhypothesen te heroverwegen. Dwingt ons om hiërarchische machtsasymmetrieën in twijfel te trekken, en brengt ons ertoe de bredere, contingente en onderling verbonden achtergrond te beschouwen waaruit algoritmische systemen voortkomen (en worden ingezet) in het proces van bescherming van het welzijn vanDeze visie gaat ervan uit dat de schade en het onrecht veroorzaakt door algoritmische systemen niet los kunnen worden gezien van de ethische principes van technologie en de sociale, politieke en economische structuren die deze vormen. Het verwerpt daarom de bewering dat alleen algoritmen verantwoordelijk zijn voor deDe Europese Unie heeft zich ertoe verbonden het Europese veiligheids- en rechtssysteem tot stand te brengen in overeenstemming met de internationale verdragen. Dit is echter niet gehaald. Wat nodig is, isOok het politiewerk zou vanuit dezelfde ethische principes moeten vertrekken.De politiemissie moet worden heroverwogen op een relationele manier, als het beschermen van collectieve veiligheid.Veiligheid wordt vaak geïnterpreteerd als bescherming tegen criminaliteit en handhaving van de openbare orde.Het gaat vaak niet eens meer om veiligheid, maar om politieke motieven om te laten zien dat er serieus wordt opgetreden tegen criminaliteit.Het is een vorm van surveillancetheater.37 Vanuit een collectieve visie op veiligheid die de veiligheid van alle burgers beoogt te waarborgen, zou meer aandacht moeten komen voor andere oorzaken van onveiligheid.Veiligheid is meer dan alleen bescherming tegen criminaliteit, gezonde voeding, schoon water, huisvesting, basisinkomen, gezondheidszorg, onderwijs en werk, maar ook geen onderwerp zijn van discriminatie, intimidatie, haat, geweld en onevenredige overheidscontrole.Sociale en economische rechten zijn vaak niet opgenomen in het veiligheidsbeleid.38 In dit document wordt betoogd dat een allesomvattendeHet internet is de afgelopen decennia enorm veranderd. Het heeft mensen in staat gesteld dingen te doen die ooit onmogelijk waren, bijvoorbeeld om democratie uit te oefenen. Internet heeft het echter ook mogelijk gemaakt dat mensen inbreken in systemen die niet van hen zijn, bijvoorbeeldgeblokkeerd.39 De deuropening wasAangezien het, zeker in het huidige politieke klimaat, onwaarschijnlijk is dat veiligheid wordt gezien als sociale zekerheid, moet de vraag worden gesteld hoe de mazen van het net zo verfijnd kunnen worden dat controlemechanismen ervoor zorgen dat de meest kwetsbaren in de samenleving worden beschermd.De vraag of algoritmen in staat zijn mensenrechten op te sporen en te handhaven, is een centrale vraag in de 21e eeuw. Het is een fundamentele vraag in de criminologie en in de antropologie, en een die tot veel discussie heeft geleid in deDit onderzoek richt zich op de bescherming van betrokkenen onder de Europese Wet bescherming persoonsgegevens. Het rationele kader is gebaseerd op het machtigen van betrokkenen die individueel hun rechten kunnen beschermen door middel van verzoeken omNiet alle betrokkenen zijn gelijk.Ze hebben verschillende inzichten, kennisniveaus, daadkracht, neiging om hun gegevens vrij te geven en individuele kwetsbaarheden.Individuele gegevensbeschermingsrechten gaan niet alleen over het recht op toegang tot informatie; ze hebben ook betrekking op de rechten van de meest kwetsbaren in de samenleving, die vaak het moeilijkst te beschermen zijn.40 Controle moet dus verder gaan dan louter technische oplossingen en formele naleving van de wet, naar een praktijk die rekening houdt met de dynamische historische context en maatschappelijke -technische praktijken waarin de technologie is ingebed, aandacht heeft voor de machtsverhoudingen van de verschillende betrokken actoren, en waarin de bescherming van de meestDeze relationele controle impliceert het betrekken van de (belangen van) anderen.De meest kwetsbare mensen zijn degenen die het meest worden getroffen door de bewaking van hun privéleven door algoritmen die zijn geprogrammeerd om hen te allen tijde te bewaken. DezeDe Commissie benadrukt ook de noodzaak van transparantie in haar werk om vooroordelen en fouten die tot mensenrechtenschendingen leiden, te voorkomen.Volgens het FIRM weten mensen in België momenteel vaak niet voor welke beslissingen de overheid algoritmen gebruikt.Daarnaast is niet altijd duidelijk hoe een algoritme persoonsgegevens verwerkt.Dit betekent dat moet worden nagedacht over hoe controlemechanismen kunnen worden herwerkt om hiermee rekening te houden.De toenemende macht van technologiebedrijven heeft veel te maken met het probleem van ongelijkheid. Als asymmetrische machtsverhoudingenZe kunnen collectieve en maatschappelijke schade voorkomen door te voorkomen dat individuen tegen hun eigen belangen stemmen.Voordat een besluit wordt genomen om te investeren in (het ontwerp van) een bepaalde technologie door de politie, moet een democratische evidence-based proportionaliteitstoets worden uitgevoerd.Deze toets betrekt burgers bij de beslissingen.Deze test besteedt ook aandacht aan de toenemende macht van de staat en private partners, alsook aan collectieve en maatschappelijke schade.Deze test moet gebaseerd zijn op wetenschappelijke en objectieve analyse.Een orgaan als de Onafhankelijke Raad voor het Regeringsbeleid (WRR)43 zou hier een rol kunnen spelen door in nauwe samenwerking met universiteiten en het maatschappelijk middenveld beleidsgericht onderzoek te doen.Dit orgaan zou dan bijvoorbeeld onderzoek kunnen doen naar de collectieve en maatschappelijke schade van algoritmisch toezicht en naar innovatieve controle- en handhavingsmechanismen.Het WRR AI-rapport stelt een structuur voor waar beleidsdirecteuren, toezichthouders en uitvoeringsorganisaties regelmatig met elkaar in contact kunnen komen en van elkaar kunnen leren over uiteenlopende onderwerpen.Dit centrum dient politiek verankerd te zijn, zodat indien nodig snel beleid gemaakt kan worden.is.44Zeker wanneer het gaat over grootschalige surveillance door politiediensten zou de bevolking betrokken moeten worden bij beslissingen om hun legitimiteit te bewaren.45Volgens het recente WRR-rapport over AI zal steeds vaker debat nodig zijn over de doelen die de samenleving wil nastreven en de vraag waar, waarvoor en onder welke condities de samenleving AI wil gebruiken.Methoden die hiervoor gebruikt kunnen worden, zijn bijvoorbeeld het organiseren van publieke debatten, openbare raadplegingen46, burgerjury’s, maar ook bijvoorbeeld de ondersteuning van citizen-science initiatieven.47 Door het publiek te betrekken als actieve deelnemers aan het proces, kan de overheid leren van de expertise van burgers.48 Vanuit de relationele ethiek is het dan wel van essentieel belang dat kwetsbare groepen en gemeenschappen een significante stem krijgen in beslissingsmakingsprocessen en dat dit niet enkel ‘voor de show’ is.Samenvattend biedt relationele controle interessante pistes aan om huidige controlemechanismen te herdenken, op een manier die rekening houdt met de sociaal-technische ontwikkelingen beschreven in de aanvang van deze bijdrage.In deze bijdrage heb ik gereflecteerd over de vraag of huidige controle- en handhavingsmechanismen voor algoritmische surveillance herdacht zouden moeten worden.Eerst heb ik drie sociotechnische ontwikkelingen besproken die huidige controlemechanismen onder druk zetten.Nadien heb ik gekeken naar welke lessenwe kunnen trekken als we controle- en handhavingsmechanismen voor algoritmische surveillance bekijken vanuit de relationele ethiek.Een voorlopig antwoord op de vraag is dat de drie socio-technische ontwikkelingen aangeven dat het huidig kader niet volstaat om deze ontwikkelingen op te vangen.Deze eerste exploratie van relationele ethiek om op een andere manier na te denken over controle en handhaving van gebruik van algoritmische surveillance door de politie, geeft aan dat ‘rationele’ controlemechanismen tekortschieten.Het relationele kader biedt interessante pistes om verder over de vooropgestelde vraag na te denken.Het antwoord in deze bijdrage blijft evenwel voorlopig, omdat verder (empirisch) onderzoek noodzakelijk zal zijn om hier beter inzicht in te krijgen.Sinds het einde van de 20ste eeuw zijn er als gevolg van technologische ontwikkelingen nieuwe mogelijkheden ontstaan om data te verzamelen en te analyseren. 
De opkomst van ‘big data’ en de toegenomen mogelijkheden van artificiële intelligentie (AI) in de 21ste eeuw zijn met veel interesse omarmd door de politie.
Het gebruik van deze technologieën door de politie kan worden beschreven als algoritmische surveillance.Dit zijn algoritmische systemen die 1. gebruik maken van op regels gebaseerde algoritmen om gestructureerde en ongestructureerde gegevens te classificeren, op te slaan, te combineren en te doorzoeken, om vastgelegde gegevens te vergelijken met andere gegevens en overeenkomsten te vinden;en 2.gebruik maken van machine-lerende algoritmes om patronen en bruikbare kennis in big data sets trachten te voorspellen op basis van de patronen die in de vastgelegde gegevens zijn gevonden.Ondanks de toegenomen regelgeving3, die als doel heeft de democratische waarborgen te garanderen van algoritmische surveillance, lijkt dit het gebruik ervan eerder te stimuleren.Denk bijvoorbeeld aan de significante toename van het gebruik van ‘intelligent’ cameratoezicht in België, maar ook elders in Europa.5Dit roept de vraag op of de huidige controlemechanismen voldoende zijn om alle burgers te beschermen tegen de mogelijke gevolgen van het gebruik van algoritmische surveillance door de politie.Het doel van deze bijdrage is om na te denken over de vraag of huidige controle en handhavingsmechanismen voor het gebruik van algoritmische surveillance door de politie herdacht zouden moeten worden.Om tot een (voorlopig) antwoord op die vraag te komen zal ik in het eerste deel van het artikel drie socio-technische ontwikkelingen bespreken die het huidig kader onder druk zetten.In het tweede deel zal ik huidige controleren handhavingsmechanismen bekijken door de bril van de relationele ethiek om te exploreren hoe we hieruit kunnen leren om controlemechanismen te herdenken.Als gevolg van de opkomst van algoritmische surveillance in het politiewerk kunnen drie sociotechnische ontwikkelingen geïdentificeerd worden die het traditionele controle- en handhavingskader onder druk zetten: 1)de fragmentatie en privatisering van politiewerk, 2) de democratisering van surveillance, en 3) de toename van collectieve schade en sociale gevolgen.Deze ontwikkelingen zijn overlappend en verstrengeld en moeten niet als losstaande ontwikkelingen worden gezien.Ten eerste, fragmentatie en privatisering van politiewerk is niet nieuw.Sinds het einde van 20ste eeuw is er in het Westen een stijging van de samenwerking met de private sector en spelen private spelers een steeds grotere rol in politiewerk.Dit is in belangrijke mate het gevolg van de toegenomen macht en groei van de private sector en bezuinigingen in de publieke sector.6De technologische ontwikkelingen van big data en AI in het begin van de 21ste eeuw hebben geleid tot de toenemende macht van technologiebedrijven door onder meer ‘surveillance kapitalisme’, waarbij gegevensverzameling een economische drijfveer wordt voor bedrijven.Politiewerk wordt in toenemende mate platform policing, waarbij de politie gebruikt maakt van digitale platformen en digitale opsporingstechnologie.8Dit heeft als gevolg dat de politie steeds afhankelijker wordt van infrastructuur van technologiebedrijven9 en leidt tot verschuivende machtsverhoudingen van de publieke naar de private sector, wat een negatieve invloed heeft op transparantie en controle.10 Ten tweede, kan er een ‘democratisering’ van surveillance worden herkend door een verschuiving van aandacht voor gerichte surveillance naar grootschalige surveillance.11Hierdoor staat nu een veel groter deel van de bevolking onder surveillance waardoor het risico op toename van de macht van de staat maar ook van private actoren steeds groter wordt.Waarbij grootschalige surveillancepraktijken vroeger vooral werden uitgevoerd door intelligentiediensten12 of binnen een bepaalde context zoals op het vliegveld, spelen politiediensten maar ook technologiebedrijven hierin een steeds grotere rol.Denk bijvoorbeeld in België aan de significante uitbreiding van het gebruik van ‘intelligent’ cameratoezicht voor allerlei doeleinden13, wat nog meer werd aangewakkerd door de coronapandemie.14 Andere voorbeelden zijn de infiltratie van het versleutelde Encrochat-netwerk15, de gezichtsherkenningssoftware van Clearview AI dat ook uitgeprobeerd is door de federale politie in België16, of de dataverzamelingspraktijken van Europol17 die door sommige vergeleken worden met surveillance praktijken van de Amerikaanse NSA.18 Denk ten slotte aan het gebruik van de spionagesoftware Pegasus om data te verzamelen van mobiele telefoons van activisten, politici en journalisten over de hele wereld.19 Ten derde is er steeds meer sprake van collectieve en sociale schade naast individuele schade.Een belangrijk kenmerk van big data-analyses is dat ze op geaggregeerd niveau plaatsvinden.Er worden dus op het eerste gezicht geen persoonsgegevens verwerkt.20Een van de gevolgen is een toename van sociale stratificatie, met een ongelijke verhouding tussen maatschappelijke groepen als gevolg.Doordat big data onregelmatigheden en afwijkingen in datasets reproduceert kan dit leiden tot uitkomsten die een onevenredige impact hebben voor bepaalde groepen of gemeenschappen.Sinds het einde van de 20ste eeuw zijn er als gevolg van technologische ontwikkelingen nieuwe mogelijkheden ontstaan om data te verzamelen en te analyseren. 
