De impact van AI op banen en seksuele discriminatie
INVOERING
De definitie van seksuele discriminatie zou een vorm van discriminatie kunnen zijn dat een persoon anders of ongelijk wordt behandeld vanwege zijn geslacht/geslacht.Hoewel volgens de federale wetgeving discriminatie op grond van geslacht op het werk illegaal is, komt dergelijke discriminatie nog steeds voor op het werkveld en is het altijd verborgen gebleven onder de norm.Zo heeft 42 % van de vrouwen in de Verenigde Staten tijdens het werk te maken gehad met discriminatie op grond van geslacht[2]. Vrouwen in de Verenigde Staten zijn dat bijvoorbeeldEen van de doelen van het creëren van AI is om te helpen met diversiteit, om problemen als discriminatie en racisme op te lossen, maar of het werkt zoals mensen voorspelden, is nog steeds een vraagteken.De zorg is dat als AI en automatisering niet worden gebruikt op een genderverantwoordelijke manier, dit de reeds bestaande gendervooroordelen zou kunnen versterken.Vanwege een betere productiviteit en lagere kosten en arbeidskrachten, is het niet moeilijk voor te stellen dat AI-technologie in de toekomst dieper zou worden betrokken bij productie en banen in het algemeen.Automatisering, big data en algoritmen kunnen grote gevolgen hebben voor vrouwen in banen. Automatisering kan bedrijven ook in staat stellen om beter te targetenDe bezorgdheid over het vervangen van banen, het geautomatiseerde aanwervingssysteem, het vrijgeven van privacy-informatie aan het publiek, slecht geselecteerde trainingsgegevens, het probleem met het ontwerp van algoritmen en het probleem als gevolg van gegevensongelijkheid zouden allemaal seksuele discriminatie veroorzaken of beïnvloeden.

De zorg voor het vervangen van banen natuurlijkBedrijven en overheden zouden actie moeten ondernemen om het hoofd te bieden aan veranderingen veroorzaakt door AI om sociale orde, rechtvaardigheid en gelijkheid te waarborgen.2.2.2.2.2.2.AUTOMATION'SUBICOLASANOEFFECTIEVE EVALUDE: Dit is een zeerHoewel de wereld wordt geconfronteerd met een ongekende groei in zowel banen als economie, heeft automatisering nog steeds een groot potentieel om tal van banen te vervangen, en vooral die technologieën zijn repetitief en hebben in vergelijking daarmee weinig menselijke interactie.De automatiseringskosten zouden ook een van de overwegingen zijn. Automatisering vereist het gebruik van meer geavanceerde software,Een meerderheid van de werknemers met voorspelbare taken en activiteiten zou dus een hoog vervangingspercentage hebben. Dus een meerderheid van de werknemers die betrokken zijn bij voorspelbare taken enHoe gaat het zich dan verhouden tot discriminatie op grond van geslacht. Hoe gaat het zich verhouden tot discriminatie op grond van geslacht? HoeHoewel er een grotere kans is dat het werk van vrouwen vatbaar is voor gedeeltelijke automatisering dan dat het volledig wordt vervangen. Maar zelfs als vrouwen er wat van verliezenVolgens McKinsey's toekomstige voorspelling van vrouwentradities tegen 2030 zouden ongeveer 40 miljoen tot 160 miljoen vrouwen moeten overstappen van beroep en vaardigheden om aan het werk te blijven[3].Dit aantal bevestigde ook de behoefte aan hoger onderwijs en verschillende vaardigheden voor succes. Het stelde ook vast dat het hoger onderwijs vaardigheden zou moeten omvatten dieHet is 7 tot 24 procent van de vrouwen dat momenteel werkt, vergeleken met het bereik van 8 tot 28 procent voor mannen.Als vrouwen profiteren van overgangsmogelijkheden, kunnen ze hun huidige aandeel in de werkgelegenheid behouden. Als ze deze kansen benutten, kunnen ze toenemenAls ze dat niet kunnen, kan de ongelijkheid tussen mannen en vrouwen op het werk verergeren. Als ze dat niet kunnen, kan genderongelijkheid op het werk leiden totAls ze de noodzakelijke overgang niet kunnen maken, zouden veel vrouwen dus te maken kunnen krijgen met een steeds groter wordende loonkloof ten opzichte van mannen. Dit impliceert dat vrouwen een lager loon zouden moeten accepterenSinds we het over automatisering hebben, zou het STEM-veld in de toekomst een grotere kans hebben op arbeidsvereisten. Maar sinds we het over automatisering hebben, zou het STEM-veld dat wel doenUit de gegevens van 2019 bleek echter dat vrouwen slechts 27% uitmaken van de werknemers in STEM-gekwalificeerde sectoren, om nog maar te zwijgen van het feit dat vrouwen gemiddeld 19% minder verdienen dan mannen[4].
Om nog maar te zwijgen, aangezien 78% van de AI-professionals mannen zijn, worden algoritmen gemaakt met door mannen gedomineerde ervaringen.Dergelijke gendervooroordelen kunnen aanzienlijk nadelig zijn voor vrouwelijke werkgevers of cv's. Dit soort vooringenomenheid kan bijzonder schadelijk zijn voorHoewel robotisering en automatisering op het werkveld beide geslachten zouden beïnvloeden, is het waarschijnlijk dat gendervooroordelen een rol spelen en vrouwen onevenredig treffen.Vrouwen die oververtegenwoordigd zijn in bepaalde automatiseringssectoren met een hoog risico zouden dat wel kunnen
meer lijden. Ze moeten oplossingen bedenken die dat wel doenOok het gebrek aan mobiliteit en flexibiliteit kunnen voor bedrijven redenen zijn om vrouwen werkloos te maken of
onderhandelingsposities verminderen[5]. Ook het gebrek aan mobiliteit kan een factor zijnDe risico's bij automatisering zijn reëel. Automatisering is een van de belangrijkste onderdelen vanDe Amerikaanse Equal Employment Opportunity Commission onderzoekt in ieder geval
twee zaken waarbij sprake was van algoritmen die discriminerend zouden kunnen zijn voor bepaalde groepen sollicitanten[6]. Dat vraagt ​​de Amerikaanse Equal Employment Opportunity Commission aan deNaar
seksuele discriminatie te voorkomen, het onderwijssysteem moet vanaf het begin veranderen om discriminatie te stoppen,
meer kansen en ondersteuning bieden voor STEM-veld, en toekomstige baanaanvullingen veroorzaakt door automatisering.3.3.3.3.3.3.DE IMPACT VAN BIG DATA
Big data-analyse en algoritmen zouden ook van invloed zijn op discriminatie in beroepen, het zou de traditionele kunnen veranderen
huurproces.Omdat de applicatie is gebaseerd op het verzamelen van big data. Het betekent dat de machine kan voorspellenAls een AI-toepassing op vooringenomenheid wordt getraind
gegevens, zouden de algoritmen waarschijnlijk bevooroordeeld zijn. Als een AI-toepassing op vooringenomenheid is getraind, zijn de resultatenEen goed cijfer, school of capaciteiten zouden niet alleen de enige zijn
meting. Een goed cijfer, school of capaciteiten nietIn de inhoud van het verzamelen van meer soorten gegevens, de metadata van de inhoud van sociale media, familie
leden, zou alles wat ook maar enigszins relevant is een tweesnijdend zwaard zijn.Alle informatie online kon worden gebruikt
om individuen te identificeren, maar de privacywet is niet ontworpen om na te gaan welke persoonlijke informatie het zou moeten zijn
beschermen en hoe te beschermen[7].De rekruteringstool die Amazon sinds 2014 heeft ontwikkeld, zou een van de voorbeelden kunnen zijn. Het bedrijf heeft een gedetailleerde tool ontwikkeld die werkgevers kunnen gebruikenHet programma werd vermoedelijk gebruikt om de cv's van sollicitanten te bekijken om te zoeken naar de mensen die er het beste in zijn
vermogen. De baan was zogenaamd bedoeld om sollicitanten te testenHoewel het de bedoeling is om een ​​genderneutraal systeem te creëren, is het resultaat er gekomen
overwegend mannelijk gedomineerd. Hoewel het de bedoeling is om eenDe reden hierachter is dat het systeem van Amazon automatisch is gedowngraded
de cv's met het woord 'vrouwen' in hun sollicitaties.
De reden erachter is dat Amazon'sHet bedrijf ontbond het team en
kondigde aan dat de tool "nooit werd gebruikt door Amazon-recruiters om kandidaten te evalueren. [8,9]" Het is echter moeilijk
om hun woorden te bevestigen en zich zorgen te maken over de mogelijkheid dat bedrijven deze gediscrimineerde gegevens gebruiken
werven en aannemen.Dit zou geen uitzondering zijn, andere bedrijven die AI-automatisering gebruiken, zouden met hetzelfde probleem worden geconfronteerd. Dit zou echter geen uitzondering zijn, andere bedrijvenOndanks deze zorgen zijn er nog steeds meer bedrijven die hard aan het werk zijn om meer delen van werving en aanwerving te automatiseren. Dit zijn wervingsmanagers, trainers en ander ondersteunend personeel.De softwareontwikkelaars van het bedrijf zouden het systeem actief moeten monitoren om ervoor te zorgen dat zoiets gebeurt
gebeurde niet. In plaats daarvan zouden de onderzoekers moeten kijken naar deOver het algemeen werkt AI efficiënter dan het menselijk brein, maar als het systeem enorm is,
en de software beslissingen achter een dashboard verdoezeld neemt, zouden er zorgen zijn over het potentieel voor
ernstige juridische problemen hier.Hoewel het volgens de wetten van de EEOC (Equal Employment Opportunity Commission) illegaal is
discrimineren tegen iemand (sollicitant of werknemer) vanwege ras, huidskleur, religie, geslacht
(inclusief genderidentiteit, seksuele geaardheid en zwangerschap), nationaliteit, leeftijd (40 jaar of ouder), handicap of
genetische informatie.Het is ook illegaal om wraak te nemen op een persoon omdat hij of zij heeft geklaagd
discriminatie, een aanklacht wegens discriminatie heeft ingediend of heeft deelgenomen aan een onderzoek naar discriminatie op het werk of
rechtszaak[10]. Het is ook illegaal om wraak te nemen op eenWanneer de informatie echter onbedoeld wordt opgenomen en beoordeeld door bedrijven, zou dit verhogen
meerdere vragen vanwege het verantwoordelijkheidsprobleem.
IMPACT VAN ALGORITMEN
Algoritmen kunnen leiden tot gendervooroordelen. Wanneer deWanneer we op Google naar "CEO" zoeken, komt het overwegend mannelijk terug
afbeeldingen, zeggen we tegen onszelf dat Google alleen maar de wereld voor ons weergeeft "een wereld waar discriminatie bestaat".Wij zijn van mening dat de Google-bots die het web doorzoeken kleuren- en genderblind zijn. Wij geloven dat deze bots zijn ontworpen om te pronkenWe vertrouwen de algoritmen die
het beantwoorden van onze zoekopdrachten is objectiever dan mensen. We vertrouwen op de algoritmen die ons daartoe in staat stellenDat zou je onmogelijk kunnen beargumenteren
Het zoekalgoritme van Google en de bijbehorende platformen voor advertentieweergave zijn inherent bevooroordeeld.
Men zou onmogelijk zo'n claim kunnen maken, gegevenHoewel ze mogelijk zijn ontworpen om vooringenomenheid te verminderen, drijven de meeste wervingsalgoritmen standaard nog steeds in de richting van vooringenomenheid. Deze algoritmen volgen echter niet altijd een setIn
een recente studie van Northeastern University en USC, breed gerichte advertenties op Facebook voor supermarktkassier
posities werden getoond aan een publiek van 85% vrouwen[11]. In dit geval echterDit zou een typisch geval kunnen zijn waar
Vooruitgang in onderzoek op het gebied van sociale wetenschappen, onderwijs en geesteswetenschappen, volume 554
859
algoritmen introduceren bias in het systeem zonder menselijke tussenkomst. Dit kan eenOm diversiteit in invoergegevens te waarborgen, zou het verzamelen van meer trainingsgegevens, specifiek met gevoelige groepen, oneerlijkheid helpen voorkomen. Bijvoorbeeld als de trainingsgegevens gevoelig zijnAls we het over een ander bedrijf hebben, versterkt Google ook seksuele discriminatie met behulp van het algoritme en het laat zien dat AdFisher, een geautomatiseerde tool die onderzoekt hoe gebruikersgedrag, de advertenties van Google en advertentie-instellingen op elkaar inwerken.

Als je het over een ander bedrijf hebt,AdFisher kan browsergebaseerde experimenten uitvoeren en gegevens analyseren met behulp van machine learning en significantietests. Het biedt tools om te testen hoe goed deDe advertentie-instellingen waren ondoorzichtig over sommige functies van het profiel van een gebruiker, waaronder het bieden van enige keuze voor advertenties. Maar het belangrijkste punt was dat de gebruiker werd gegevenWanneer u het geslacht op vrouwelijk instelt, krijgt u minder exemplaren van een advertentie met betrekking tot goedbetaalde banen dan wanneer u deze op mannen instelt.Enkele mogelijke redenen kunnen zijn dat Google het systeem expliciet programmeert om de advertentie minder vaak aan vrouwen te laten zien. Als alternatief kunnen enkele mogelijke redenen zijn dat het systeemMannelijke en vrouwelijke consumenten reageren verschillend op advertenties en het targetingalgoritme van Google reageert op het verschil (Google heeft bijvoorbeeld geleerd dat mannen eerder op deze advertentie klikken dan vrouwen).

Mannelijke en vrouwelijke consumenten reagerenMeer concurrentie voor advertenties voor vrouwen zorgt ervoor dat de adverteerder minder advertentieruimtes voor vrouwen wint. Dit leidt tot meer concurrentie voor adverteerders om aan te biedenSommige derden (bijvoorbeeld een hacker) manipuleren het advertentie-ecosysteem. Vaak wilden ze een betere advertentie makenEen onderzoek gebruikt gegevens van een veldtest van een advertentie die bedoeld was om vacatures en opleidingen in STEM (Science, Technology, Engineering en Math) te promoten. Een onderzoeksteam van de universiteit gebruikte soortgelijke methodes om te vergelijkenDe advertentie was bedoeld om genderneutraal te zijn en was neutraal getarget. Het zou gaan over gender-Deze advertentie is getest in 191 landen over de hele wereld. Het vergeleek het vermogen van mensen om te multitasken en om te multitaskenHoe empirisch ook, de advertentie werd echter aan 20% meer mannen dan vrouwen getoond[12]. Hoe empirisch ook, de advertentie toonde 20%Veel redenen hebben ertoe bijgedragen dat dit resultaatalgoritme probeerde het aantal klikken te maximaliseren, waardoor advertenties meer aan mannen dan aan vrouwen werden getoond, of vrouwen bezoeken minder snel websites met advertenties erop.Alle resultaten wijzen op hetzelfde punt: omdat een woord vrouwen al vrijlaat voor lagere lonen / niet voor STEM-banen, zou de seksuele discriminatie van deze algoritmen een grotere kans creëren om te verhogen in plaats van te verminderen.To ensure diversity in input data, collecting more training data specifically with sensitive groups would help with unfairness.
SUGGESTION
Companies should invest in training and reskilling, provide possible training and apprenticeship programs for women.Also, companies and the government could consider reskilling opportunities for mid career women or women returning to the workforce.Companies should subsidize transition costs, government or corporate reskilling subsidies for targeted occupations and sectors.Community and governments could provide childcare subsidies for parents undergoing reskilling or pursuing higher education.Governments could invest in digital platforms, industry partnerships with massive open online courses.Companies should increase transparency on labour demand trends, contribute to more technical school or university curriculums co-created with industry, invest in informational campaigns targeting women.
Data testing: Put in place AI development standards, testing procedures, controls, and other technical governance elements designed to make sure the data used in training AI applications are thoroughly vetted and certified against a biased perspective before the application goes into production.Output testing: Establish testing requirements and controls around the outputs produced or decisions made by the AI.
Review and challenge these outputs and decisions against a biased perspective to make sure they represent fair and positive outcomes that are in line with expectations and do not adversely and unfairly impact any group of people.Development teams: Make sure AI design and development teams are diverse and include female data scientists, programmers, designers, and other key team members who influence how an AI application is developed.Set targets and put in place training, recruiting, and rotation programs to move toward this target.
CONCLUSION
Since automation is the major trend in the future, companies and the government should be double careful with the use of it.The effect of biased data, algorithms in the workforce could turnover the equality in the workforce.Thus companies must develop and deploy AI applications in a responsible manner that proactively seeks to identify and eliminate existing societal biases so they are not encoded and amplified in the digital world.Toward this goal, these are some future suggestions for companies and the government.It is important to note that, even though the focus of this essay is gender bias, AI applications can and often do suffer from different types of societal biases, for example, around race, ethnicity, and religion.As a result, companies should expand the above efforts and measures to make sure the AI applications they put in place do not hurt any group of people.
AI has the potential to mitigate the corporate gender and leadership gaps by removing bias in recruiting,
Advances in SocialDe impact van AI op banen en seksuele discriminatie
INVOERING
De definitie van seksuele discriminatie zou een vorm van discriminatie kunnen zijn dat een persoon anders of ongelijk wordt behandeld vanwege zijn geslacht/geslacht.Hoewel volgens de federale wetgeving discriminatie op grond van geslacht op het werk illegaal is, komt dergelijke discriminatie nog steeds voor op het werkveld en is het altijd verborgen gebleven onder de norm.Zo heeft 42 % van de vrouwen in de Verenigde Staten tijdens het werk te maken gehad met discriminatie op grond van geslacht[2]. Vrouwen in de Verenigde Staten zijn dat bijvoorbeeldEen van de doelen van het creëren van AI is om te helpen met diversiteit, om problemen als discriminatie en racisme op te lossen, maar of het werkt zoals mensen voorspelden, is nog steeds een vraagteken.De zorg is dat als AI en automatisering niet worden gebruikt op een genderverantwoordelijke manier, dit de reeds bestaande gendervooroordelen zou kunnen versterken.Vanwege een betere productiviteit en lagere kosten en arbeidskrachten, is het niet moeilijk voor te stellen dat AI-technologie in de toekomst dieper zou worden betrokken bij productie en banen in het algemeen.Automatisering, big data en algoritmen kunnen grote gevolgen hebben voor vrouwen in banen. Automatisering kan bedrijven ook in staat stellen om beter te targetenDe bezorgdheid over het vervangen van banen, het geautomatiseerde aanwervingssysteem, het vrijgeven van privacy-informatie aan het publiek, slecht geselecteerde trainingsgegevens, het probleem met het ontwerp van algoritmen en het probleem als gevolg van gegevensongelijkheid zouden allemaal seksuele discriminatie veroorzaken of beïnvloeden.

De zorg voor het vervangen van banen natuurlijkBedrijven en overheden zouden actie moeten ondernemen om het hoofd te bieden aan veranderingen veroorzaakt door AI om sociale orde, rechtvaardigheid en gelijkheid te waarborgen.2.2.2.2.2.2.AUTOMATION'SUBICOLASANOEFFECTIEVE EVALUDE: Dit is een zeerHoewel de wereld wordt geconfronteerd met een ongekende groei in zowel banen als economie, heeft automatisering nog steeds een groot potentieel om tal van banen te vervangen, en vooral die technologieën zijn repetitief en hebben in vergelijking daarmee weinig menselijke interactie.De automatiseringskosten zouden ook een van de overwegingen zijn. Automatisering vereist het gebruik van meer geavanceerde software,Een meerderheid van de werknemers met voorspelbare taken en activiteiten zou dus een hoog vervangingspercentage hebben. Dus een meerderheid van de werknemers die betrokken zijn bij voorspelbare taken enHoe gaat het zich dan verhouden tot discriminatie op grond van geslacht. Hoe gaat het zich verhouden tot discriminatie op grond van geslacht? HoeHoewel er een grotere kans is dat het werk van vrouwen vatbaar is voor gedeeltelijke automatisering dan dat het volledig wordt vervangen. Maar zelfs als vrouwen er wat van verliezenVolgens McKinsey's toekomstige voorspelling van vrouwentradities tegen 2030 zouden ongeveer 40 miljoen tot 160 miljoen vrouwen moeten overstappen van beroep en vaardigheden om aan het werk te blijven[3].Dit aantal bevestigde ook de behoefte aan hoger onderwijs en verschillende vaardigheden voor succes. Het stelde ook vast dat het hoger onderwijs vaardigheden zou moeten omvatten dieHet is 7 tot 24 procent van de vrouwen dat momenteel werkt, vergeleken met het bereik van 8 tot 28 procent voor mannen.Als vrouwen profiteren van overgangsmogelijkheden, kunnen ze hun huidige aandeel in de werkgelegenheid behouden. Als ze deze kansen benutten, kunnen ze toenemenAls ze dat niet kunnen, kan de ongelijkheid tussen mannen en vrouwen op het werk verergeren. Als ze dat niet kunnen, kan ongelijkheid tussen mannen en vrouwen leiden tot werkloosheid enAls ze de noodzakelijke overgang niet kunnen maken, zouden veel vrouwen dus te maken kunnen krijgen met een steeds groter wordende loonkloof ten opzichte van mannen. Dit impliceert dat vrouwen een lager loon zouden moeten accepterenSinds we het over automatisering hebben, zou het STEM-veld in de toekomst een grotere kans hebben op arbeidsvereisten. Maar sinds we het over automatisering hebben, zou het STEM-veld dat wel doenUit de gegevens van 2019 bleek echter dat vrouwen slechts 27% uitmaken van de werknemers in STEM-gekwalificeerde sectoren, om nog maar te zwijgen van het feit dat vrouwen gemiddeld 19% minder verdienen dan mannen[4].
Om nog maar te zwijgen, aangezien 78% van de AI-professionals mannen zijn, worden algoritmen gemaakt met door mannen gedomineerde ervaringen.Dergelijke gendervooroordelen kunnen aanzienlijk nadelig zijn voor vrouwelijke werkgevers of cv's. Dit soort vooringenomenheid kan bijzonder schadelijk zijn voorHoewel robotisering en automatisering op het werkveld beide geslachten zouden beïnvloeden, is het waarschijnlijk dat gendervooroordelen een rol spelen en vrouwen onevenredig treffen.Vrouwen die oververtegenwoordigd zijn in bepaalde automatiseringssectoren met een hoog risico zouden dat wel kunnen
meer lijden. Ze moeten oplossingen bedenken die dat wel doenOok het gebrek aan mobiliteit en flexibiliteit kunnen voor bedrijven redenen zijn om vrouwen werkloos te maken of
onderhandelingsposities verminderen[5]. Ook het gebrek aan mobiliteit kan een factor zijnDe risico's bij automatisering zijn reëel. Automatisering is een van de belangrijkste onderdelen vanDe Amerikaanse Equal Employment Opportunity Commission onderzoekt in ieder geval
twee zaken waarbij sprake was van algoritmen die discriminerend zouden kunnen zijn voor bepaalde groepen sollicitanten[6]. Dat vraagt ​​de Amerikaanse Equal Employment Opportunity Commission aan deNaar
seksuele discriminatie te voorkomen, het onderwijssysteem moet vanaf het begin veranderen om discriminatie te stoppen,
meer kansen en ondersteuning bieden voor STEM-veld, en toekomstige baanaanvullingen veroorzaakt door automatisering.3.3.3.3.3.3.DE IMPACT VAN BIG DATA
Big data-analyse en algoritmen zouden ook van invloed zijn op discriminatie in beroepen, het zou de traditionele kunnen veranderen
huurproces.Omdat de applicatie is gebaseerd op het verzamelen van big data. Het betekent dat de machine kan voorspellenAls een AI-toepassing op vooringenomenheid wordt getraind
gegevens, zouden de algoritmen waarschijnlijk bevooroordeeld zijn. Als een AI-toepassing op vooringenomenheid is getraind, zijn de resultatenEen goed cijfer, school of capaciteiten zouden niet alleen de enige zijn
meting. Een goed cijfer, school of capaciteiten nietIn de inhoud van het verzamelen van meer soorten gegevens, de metadata van de inhoud van sociale media, familie
leden, zou alles wat ook maar enigszins relevant is een tweesnijdend zwaard zijn.Alle informatie online kon worden gebruikt
om individuen te identificeren, maar de privacywet is niet ontworpen om na te gaan welke persoonlijke informatie het zou moeten zijn
beschermen en hoe te beschermen[7].De rekruteringstool die Amazon sinds 2014 heeft ontwikkeld, zou een van de voorbeelden kunnen zijn. Het bedrijf heeft een gedetailleerde tool ontwikkeld die werkgevers kunnen gebruikenHet programma werd vermoedelijk gebruikt om de cv's van sollicitanten te bekijken om te zoeken naar de mensen die er het beste in zijn
vermogen. De baan was zogenaamd bedoeld om sollicitanten te testenHoewel het de bedoeling is om een ​​genderneutraal systeem te creëren, is het resultaat er gekomen
overwegend mannelijk gedomineerd. Hoewel het de bedoeling is om eenDe reden hierachter is dat het systeem van Amazon automatisch is gedowngraded
de cv's met het woord 'vrouwen' in hun sollicitaties.
De reden erachter is dat Amazon'sHet bedrijf ontbond het team en
kondigde aan dat de tool "nooit werd gebruikt door Amazon-recruiters om kandidaten te evalueren. [8,9]" Het is echter moeilijk
om hun woorden te bevestigen en zich zorgen te maken over de mogelijkheid dat bedrijven deze gediscrimineerde gegevens gebruiken
werven en aannemen.Dit zou geen uitzondering zijn, andere bedrijven die AI-automatisering gebruiken, zouden met hetzelfde probleem worden geconfronteerd. Dit zou echter geen uitzondering zijn, andere bedrijvenOndanks deze zorgen zijn er nog steeds meer bedrijven die hard aan het werk zijn om meer delen van werving en aanwerving te automatiseren. Dit zijn wervingsmanagers, trainers en ander ondersteunend personeel.De softwareontwikkelaars van het bedrijf zouden het systeem actief moeten monitoren om ervoor te zorgen dat zoiets gebeurt
gebeurde niet. In plaats daarvan zouden de onderzoekers moeten kijken naar deOver het algemeen werkt AI efficiënter dan het menselijk brein, maar als het systeem enorm is,
en de software beslissingen achter een dashboard verdoezeld neemt, zouden er zorgen zijn over het potentieel voor
ernstige juridische problemen hier.Hoewel het volgens de wetten van de EEOC (Equal Employment Opportunity Commission) illegaal is
discrimineren tegen iemand (sollicitant of werknemer) vanwege ras, huidskleur, religie, geslacht
(inclusief genderidentiteit, seksuele geaardheid en zwangerschap), nationaliteit, leeftijd (40 jaar of ouder), handicap of
genetische informatie.Het is ook illegaal om wraak te nemen op een persoon omdat hij of zij heeft geklaagd
discriminatie, een aanklacht wegens discriminatie heeft ingediend of heeft deelgenomen aan een onderzoek naar discriminatie op het werk of
rechtszaak[10]. Het is ook illegaal om wraak te nemen op eenWanneer de informatie echter onbedoeld wordt opgenomen en beoordeeld door bedrijven, zou dit verhogen
meerdere vragen vanwege het verantwoordelijkheidsprobleem.
IMPACT VAN ALGORITMEN
Algoritmen kunnen leiden tot gendervooroordelen. Wanneer deWanneer we op Google naar "CEO" zoeken, komt het overwegend mannelijk terug
afbeeldingen, zeggen we tegen onszelf dat Google alleen maar de wereld voor ons weergeeft "een wereld waar discriminatie bestaat".Wij zijn van mening dat de Google-bots die het web doorzoeken kleuren- en genderblind zijn. Wij geloven dat deze bots zijn ontworpen om te pronkenWe vertrouwen de algoritmen die
het beantwoorden van onze zoekopdrachten is objectiever dan mensen. We vertrouwen op de algoritmen die ons daartoe in staat stellenDat zou je onmogelijk kunnen beargumenteren
Het zoekalgoritme van Google en de bijbehorende platformen voor advertentieweergave zijn inherent bevooroordeeld.
Men zou onmogelijk zo'n claim kunnen maken, gegevenHoewel ze mogelijk zijn ontworpen om vooringenomenheid te verminderen, drijven de meeste wervingsalgoritmen standaard nog steeds in de richting van vooringenomenheid. Deze algoritmen volgen echter niet altijd een setIn
een recente studie van Northeastern University en USC, breed gerichte advertenties op Facebook voor supermarktkassier
posities werden getoond aan een publiek van 85% vrouwen[11]. In dit geval echterDit zou een typisch geval kunnen zijn waar
Vooruitgang in onderzoek op het gebied van sociale wetenschappen, onderwijs en geesteswetenschappen, volume 554
859
algoritmen introduceren bias in het systeem zonder menselijke tussenkomst. Dit kan eenOm diversiteit in invoergegevens te waarborgen, zou het verzamelen van meer trainingsgegevens, specifiek met gevoelige groepen, oneerlijkheid helpen voorkomen. Bijvoorbeeld als de trainingsgegevens gevoelig zijnAls we het over een ander bedrijf hebben, versterkt Google ook seksuele discriminatie met behulp van het algoritme en het laat zien dat AdFisher, een geautomatiseerde tool die onderzoekt hoe gebruikersgedrag, de advertenties van Google en advertentie-instellingen op elkaar inwerken.

Als je het over een ander bedrijf hebt,AdFisher kan browsergebaseerde experimenten uitvoeren en gegevens analyseren met behulp van machine learning en significantietests. Het biedt tools om te testen hoe goed deDe advertentie-instellingen waren ondoorzichtig over sommige functies van het profiel van een gebruiker, waaronder het bieden van enige keuze voor advertenties. Maar het belangrijkste punt was dat de gebruiker werd gegevenWanneer u het geslacht op vrouwelijk instelt, krijgt u minder exemplaren van een advertentie met betrekking tot goedbetaalde banen dan wanneer u deze op mannen instelt.Enkele mogelijke redenen kunnen zijn dat Google het systeem expliciet programmeert om de advertentie minder vaak aan vrouwen te laten zien. Als alternatief kunnen enkele mogelijke redenen zijn dat het systeemMannelijke en vrouwelijke consumenten reageren verschillend op advertenties en het targetingalgoritme van Google reageert op het verschil (Google heeft bijvoorbeeld geleerd dat mannen eerder op deze advertentie klikken dan vrouwen).

Mannelijke en vrouwelijke consumenten reagerenMeer concurrentie voor advertenties voor vrouwen zorgt ervoor dat de adverteerder minder advertentieruimtes voor vrouwen wint. Dit leidt tot meer concurrentie voor adverteerders om aan te biedenSommige derden (bijvoorbeeld een hacker) manipuleren het advertentie-ecosysteem. Vaak wilden ze een betere advertentie makenEen onderzoek gebruikt gegevens van een veldtest van een advertentie die bedoeld was om vacatures en opleidingen in STEM (Science, Technology, Engineering en Math) te promoten. Een onderzoeksteam van de universiteit gebruikte soortgelijke methodes om te vergelijkenDe advertentie was bedoeld om genderneutraal te zijn en was neutraal getarget. Het zou gaan over gender-Deze advertentie is getest in 191 landen over de hele wereld. Het vergeleek het vermogen van mensen om te multitasken en om te multitaskenHoe empirisch ook, de advertentie werd echter aan 20% meer mannen dan vrouwen getoond[12]. Hoe empirisch ook, de advertentie toonde 20%Veel redenen hebben ertoe bijgedragen dat dit resultaatalgoritme probeerde het aantal klikken te maximaliseren, waardoor advertenties meer aan mannen dan aan vrouwen werden getoond, of vrouwen bezoeken minder snel websites met advertenties erop.Alle resultaten wijzen op hetzelfde punt: omdat een woord vrouwen al vrijlaat voor lagere lonen / niet voor STEM-banen, zou de seksuele discriminatie van deze algoritmen een grotere kans creëren om te verhogen in plaats van te verminderen.Om diversiteit in invoergegevens te waarborgen, zou het verzamelen van meer trainingsgegevens, specifiek met gevoelige groepen, oneerlijkheid helpen voorkomen.SUGGESTIE
Bedrijven moeten investeren in opleiding en omscholing, en mogelijk voorzien in opleidings- en stageprogramma's voor vrouwen.Bedrijven en de overheid zouden ook kunnen overwegen om herscholingsmogelijkheden te overwegen voor vrouwen in het midden van hun carrière of vrouwen die weer aan het werk gaan.Bedrijven moeten transitiekosten, overheids- of bedrijfsomscholingssubsidies subsidiëren voor specifieke beroepen en sectoren. Ze mogen de transitiekosten niet afsnijdenDe gemeenschap en de overheid zouden subsidies voor kinderopvang kunnen verstrekken aan ouders die een omscholing volgen of een hogere opleiding volgen. De gemeenschap en de overheid kunnen ouders ook stimulerenOverheden zouden kunnen investeren in digitale platforms, branchepartnerschappen met massale open online cursussen. Ze kunnen ook proberen bedrijven te overtuigen om te adopteren