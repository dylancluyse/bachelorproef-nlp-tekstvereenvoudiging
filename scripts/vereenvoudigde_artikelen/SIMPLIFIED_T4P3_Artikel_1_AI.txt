Sinds het einde van de 20ste eeuw zijn er nieuwe mogelijkheden ontstaan om data te verzamelen en analyseren door technologische ontwikkelingen. 'Big data' en AI zijn interessant voor de politie. De politie gebruikt algoritmen om gegevens te classificeren, vergelijken en patronen te voorspellen in grote datasets. Ondanks regelgeving lijkt het gebruik van algoritmische surveillance juist toe te nemen. Dit roept de vraag op of de huidige controlemechanismen voldoende bescherming bieden aan burgers. Dit artikel bespreekt drie ontwikkelingen die het huidige kader onder druk zetten. Het tweede deel bekijkt controlemechanismen vanuit de relationele ethiek om te herdenken. Algoritmische surveillance brengt drie ontwikkelingen met zich mee: fragmentatie en privatisering van politiewerk, democratisering van surveillance en toename van collectieve schade. Deze ontwikkelingen zijn verweven en overlappen elkaar. Samenwerking met de private sector in politiewerk is sinds de 20ste eeuw toegenomen. Dit is grotendeels te wijten aan de groeiende macht van de private sector en bezuinigingen in de publieke sector. Technologische ontwikkelingen zoals big data en AI hebben geleid tot de opkomst van technologiebedrijven die gegevensverzameling als economisch motief hebben. Politiewerk evolueert naar platform policing, waarbij digitale platformen en opsporingstechnologie worden gebruikt. Hierdoor wordt de politie steeds afhankelijker van technologiebedrijven, wat resulteert in machtsverschuivingen van publiek naar privaat en negatieve gevolgen heeft voor transparantie en controle. Daarnaast is er een verschuiving van gerichte naar grootschalige surveillance, waardoor een groter deel van de bevolking onder toezicht komt te staan en het risico op machtsmisbruik door de staat en private actoren toeneemt. Politiediensten en technologiebedrijven spelen een steeds grotere rol in grootschalige surveillancepraktijken. Voorbeelden hiervan zijn het gebruik van 'intelligent' cameratoezicht in België voor diverse doeleinden, infiltratie van het Encrochat-netwerk, gezichtsherkenningstechnologie van Clearview AI getest door de federale politie in België, en dataverzamelingspraktijken van Europol die vergeleken worden met die van de Amerikaanse NSA. Spionagesoftware Pegasus wordt gebruikt om data te verzamelen van mobiele telefoons wereldwijd. Collectieve en sociale schade neemt toe naast individuele schade. Big data-analyses kunnen leiden tot sociale stratificatie en discriminatie. Predictive policing zorgt voor overpolicing en stigmatisering van bepaalde wijken. Het gebruik van SyRI in Nederland heeft sociale gevolgen en draagt bij aan armoedecriminalisering en ongelijkheid. Huidige controlemechanismen worden uitgedaagd door sociotechnische ontwikkelingen. Het juridisch kader en de controle-instrumenten zijn beperkt in hun bescherming van fundamentele rechten. Meer nadruk op bescherming van rechten is nodig. De instrumenten werken in België weinig democratisch, zonder betrokkenheid van burgers. De politie hoeft DPIA's niet te publiceren, wat publieke controle bemoeilijkt. Er zijn geen standaarden voor DPIA's of functionarissen voor gegevensbescherming. Het huidige wettelijke kader is beperkt tot persoonsgegevensverwerking door algoritmische surveillance. De EU heeft een AI-wetvoorstel gepubliceerd voor bescherming en harmonisatie van regelgeving. De verordening noemt nadelige gevolgen en risico's voor individuen en de samenleving, maar definieert ze niet. Controle- en handhavingsmechanismen worden versterkt in de voorgestelde verordening, maar details zijn vaag. Er zal een systeem worden opgezet voor registratie en beoordeling van hoogrisico-AI-toepassingen. Democratische betrokkenheid en klachtenprocedures ontbreken in de verordening. Relationele ethiek kan nieuwe perspectieven bieden voor controle in de algoritmische politiepraktijk. Ubuntufilosofie komt uit Afrikaanse filosofie ten zuiden van de Sahara. Het verschilt van rationele ethiek doordat menselijke waardigheid voortkomt uit relaties met anderen. Mensenrechtenschendingen schaden gemeenschappelijke betrekkingen en menselijke waardigheid. Computerwetenschappers stellen een verschuiving voor naar relationele ethiek in AI-bestuur. Relationele ethiek onderzoekt machtsasymmetrieën en bredere achtergronden van algoritmische systemen. Schade en onrechtvaardigheid zijn verbonden met technologie en sociale structuren. Hoe kan dit samengaan met grootschalige surveillance en samenwerking met de private sector? Het politie- en justitie-apparaat moet dezelfde ethiek hanteren. Veiligheid wordt nu te eng geïnterpreteerd als misdaadpreventie en handhaving. Vaak draait het om politieke motieven en het tonen van hard optreden. 'Surveillance theater' is een vorm van schijnveiligheid. Veiligheid gaat verder dan criminaliteitsbestrijding: gezondheid, discriminatie, haat, geweld, controle. Sociale en economische rechten ontbreken vaak in veiligheidsbeleid. Encryptie is cruciaal om mensenrechten te beschermen tegen belemmering van democratische controle. Hoe kunnen controlemechanismen de meest kwetsbaren beschermen? Het rationele controle-kader van gegevensbescherming is ontoereikend en negeert kwetsbare groepen. Controle moet rekening houden met context, machtsrelaties en bescherming van kwetsbaren. Relationele controle betrekt de belangen van de meest kwetsbaren in het beleid. Transparantie is cruciaal om vooroordelen en fouten te vermijden. Mensen weten vaak niet welke beslissingen algoritmen beïnvloeden. Controlemechanismen moeten herzien worden met aandacht voor machtsrelaties en schade. Democratische proportionaliteitstoets moet voor technologie-investeringen worden uitgevoerd, inclusief burgers. Onafhankelijke instanties zoals de WRR kunnen beleidsgericht onderzoek verrichten. Een AI-coördinatiecentrum kan zorgen voor interactie en beleidsontwikkeling. Bij grootschalige surveillance moet de bevolking betrokken worden voor legitimiteit. Debatten en raadplegingen kunnen hiervoor worden georganiseerd. Kwetsbare groepen moeten een echte stem krijgen in besluitvorming. Relationele controle herdenkt huidige mechanismen en neemt sociaal-technische ontwikkelingen in overweging. Huidige controlemechanismen zijn niet voldoende voor deze ontwikkelingen. Relationele ethiek biedt interessante perspectieven, maar verder onderzoek is nodig.