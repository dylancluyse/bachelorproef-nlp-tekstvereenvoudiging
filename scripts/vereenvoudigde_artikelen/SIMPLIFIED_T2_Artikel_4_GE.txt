De impact van AI op banen en seksuele discriminatieINLEIDINGDe definitie van seksuele discriminatie zou een vorm van discriminatie kunnen zijn dat een persoon anders of ongelijk wordt behandeld vanwege zijn geslacht/geslacht.Hoewel volgens de federale wetgeving discriminatie op grond van geslacht op het werk illegaal is, komt dergelijke discriminatie nog steeds voor op het werkveld en is het altijd verborgen gebleven onder de norm.Zo heeft 42% van de vrouwen in de Verenigde Staten tijdens het werk te maken gehad met discriminatie op grond van geslacht[2].Een van de doelen van het creëren van AI is om te helpen met diversiteit, problemen als discriminatie en racisme op te lossen, maar of het werkt zoals mensen voorspelden, is nog steeds een vraagteken.De zorg is dat als AI en automatisering niet op een genderverantwoordelijke manier worden gebruikt, dit de reeds bestaande gendervooroordelen zou kunnen versterken.Vanwege een betere productiviteit en lagere kosten en arbeidskrachten, is het niet moeilijk voor te stellen dat AI-technologie in de toekomst dieper zou worden betrokken bij productie en banen in het algemeen.Automatisering, big data en algoritmen kunnen grote gevolgen hebben voor vrouwen in banen.De bezorgdheid over het vervangen van banen, het geautomatiseerde aanwervingssysteem, het vrijgeven van privacy-informatie aan het publiek, slecht geselecteerde trainingsgegevens, het probleem met het ontwerp van algoritmen en het probleem als gevolg van gegevensongelijkheid zouden allemaal seksuele discriminatie veroorzaken of beïnvloeden.Bedrijven en overheden zouden actie moeten ondernemen om het hoofd te bieden aan veranderingen veroorzaakt door AI om sociale orde, rechtvaardigheid en gelijkheid te waarborgen.2.3.2.2AUTOMATISERING AUTOMEFFECT.EFFECT .EFFHoewel de wereld wordt geconfronteerd met een ongekende groei in zowel banen als economie, heeft automatisering nog steeds een groot potentieel om tal van banen te vervangen en vooral die technologieën zijn repetitief en hebben in vergelijking daarmee weinig menselijke interactie.De automatiseringskosten zouden ook een van de overwegingen zijn.Een meerderheid van de werknemers met voorspelbare taken en activiteiten zou dus een hoog vervangingspercentage hebben.Hoe gaat het zich dan verhouden tot discriminatie op grond van geslacht.Hoewel er een grotere kans is dat het werk van vrouwen vatbaar is voor gedeeltelijke automatisering dan dat het volledig wordt vervangen.Volgens McKinsey's toekomstige voorspelling van vrouwentradities tegen 2030, zouden ongeveer 40 miljoen tot 160 miljoen vrouwen moeten overstappen van beroep en vaardigheden om aan het werk te blijven.Dit aantal bevestigde ook de behoefte aan hoger onderwijs en verschillende vaardigheden voor succes.Het is 7 tot 24 procent van de vrouwen dat momenteel werkt, vergeleken met het bereik van 8 tot 28 procent voor mannen.Als vrouwen profiteren van overgangsmogelijkheden, kunnen ze hun huidige aandeel in de werkgelegenheid behouden.Als ze dat niet kunnen, kan de ongelijkheid tussen mannen en vrouwen op het werk verergeren.Veel vrouwen zouden te maken kunnen krijgen met een steeds groter wordende loonkloof ten opzichte van mannen. Als ze dus niet de noodzakelijke overgang naar de arbeidsmarkt kunnen maken, zullen veel vrouwenSinds we het over automatisering hebben, zou het STEM-veld in de toekomst een grotere kans hebben op arbeidsvereisten.Uit de gegevens van 2019 bleek echter dat vrouwen slechts 27% van de werknemers in STEM-gekwalificeerde sectoren uitmaakten, om nog maar te zwijgen van het feit dat vrouwen gemiddeld 19% minder verdienden dan mannen[4]. Om nog maar te zwijgen van het feit dat 78% van de AI-professionals mannen zijn , worden algoritmen gemaakt met door mannen gedomineerde ervaringen.Dergelijke gendervooroordelen kunnen aanzienlijk nadelig zijn voor vrouwelijke werkgevers of cv's.Hoewel robotisering en automatisering op het werkveld beide geslachten zouden beïnvloeden, is het waarschijnlijk dat gendervooroordelen een rol gaan spelen en vrouwen onevenredig zwaar zullen treffen.Vrouwen die oververtegenwoordigd zijn in bepaalde automatiseringssectoren met een hoog risico zouden meer kunnen lijden.Het gebrek aan mobiliteit en flexibiliteit kan voor bedrijven ook een reden zijn om vrouwen werkloos te maken of onderhandelingsposities in te krimpen[5].De risico's bij automatisering zijn reëel. We moeten ons voorbereidenDe Amerikaanse Equal Employment Opportunity Commission onderzoekt ten minste twee gevallen van algoritmen die kunnen worden gediscrimineerd ten opzichte van bepaalde groepen sollicitanten[6].Om seksuele discriminatie te voorkomen, moet het onderwijssysteem vanaf het begin veranderen om discriminatie te stoppen, meer kansen en ondersteuning te bieden aan STEM-veld en toekomstige baanaanvullingen veroorzaakt door automatisering.3.3.2.3DE IMPACT VAN BIG DATA Big data-analyse en algoritmen zouden ook van invloed zijn op discriminatie in beroepen, het zou het traditionele wervingsproces kunnen omdraaien.Omdat de applicatie is gebaseerd op het verzamelen van big data.Als een AI-toepassing is getraind op biasdata, zijn de algoritmen waarschijnlijk vertekend.Een goed cijfer, school of capaciteiten zijn niet alleen de enige maatstaf.In de inhoud van het verzamelen van meer soorten gegevens, zouden de metadata van de sociale media-inhoud, familieleden, alles wat op afstand relevant is, allemaal een tweesnijdend zwaard zijn.Alle informatie online kan worden gebruikt om personen te identificeren, maar de privacywet is niet ontworpen om na te gaan welke persoonlijke informatie deze moet beschermen en hoe deze moet worden beschermd[7].De rekruteringstool die Amazon sinds 2014 heeft ontwikkeld, zou een van de voorbeelden kunnen zijn.Het programma werd zogenaamd gebruikt om de cv's van sollicitanten te bekijken om te zoeken naar de mensen met de grootste onbekwaamheid.Hoewel het de bedoeling is om een ​​sekseneutraal systeem te creëren, werd het resultaat overweldigend door mannen gedomineerd.De reden hierachter is dat het systeem van Amazon automatisch de cv's met het woord 'vrouwen' in hun sollicitaties heeft gedowngraded.Het bedrijf ontbond het team en kondigde aan dat de tool "nooit door Amazon-recruiters is gebruikt om kandidaten te evalueren. [8,9]" Het is echter moeilijk om hun woorden te bevestigen en zorgen te maken over de mogelijkheid dat bedrijven deze gediscrimineerde gegevens gebruiken bij het werven en aannemen.Dit zou geen uitzondering zijn, andere bedrijven die AI-automatisering gebruiken, zouden met hetzelfde probleem worden geconfronteerd.Ondanks deze zorgen zijn er nog steeds meer bedrijven die hard aan het werk zijn om meer delen van werving en aanwerving te automatiseren.De softwareontwikkelaars van het bedrijf zouden het systeem actief moeten monitoren om ervoor te zorgen dat zoiets niet gebeurt.Over het algemeen werkt AI efficiënter dan het menselijk brein, maar wanneer het systeem enorm is en de software achter een dashboard verborgen beslissingen neemt, bestaat er bezorgdheid over mogelijke ernstige juridische problemen.Hoewel het volgens de wetten van de EEOC (Equal Employment Opportunity Commission) onwettig is om iemand (sollicitant of werknemer) te discrimineren op grond van ras, huidskleur, religie, geslacht (inclusief genderidentiteit, seksuele geaardheid en zwangerschap), nationale afkomst , leeftijd (40 of ouder), handicap of genetische informatie , het is niet illegaal om iemand in dienst te nemenHet is ook onwettig om represailles te nemen tegen een persoon omdat hij of zij heeft geklaagd over discriminatie, een aanklacht wegens discriminatie heeft ingediend of heeft deelgenomen aan een onderzoek naar discriminatie op het werk of een rechtszaak[10].Algoritmen kunnen leiden tot gendervooroordelen. Wanneer de informatie echter onbedoeld wordt opgenomen en beoordeeld door bedrijven, roept dit meerdere vragen op vanwege het verantwoordelijkheidsprobleem. IMPACT VAN ALGORITMENWanneer we zoeken naar "CEO" op Google, levert het overweldigend mannelijke afbeeldingen op, we zeggen tegen onszelf dat Google alleen maar de wereld voor ons weergeeft "een wereld waar discriminatie bestaat".Wij zijn van mening dat de Google-bots die het web doorzoeken kleuren- en genderblind zijn.We vertrouwen op de algoritmen die onze zoekopdrachten objectiever beantwoorden dan mensen.Het is onmogelijk om aan te voeren dat het zoekalgoritme van Google en de bijbehorende platformen voor het weergeven van advertenties inherent bevooroordeeld zijn.Hoewel ze mogelijk zijn ontworpen om vooringenomenheid te verminderen, drijven de meeste wervingsalgoritmen standaard nog steeds in de richting van vooringenomenheid.In een recent onderzoek van Northeastern University en USC werden breed gerichte advertenties op Facebook voor kassafuncties in supermarkten getoond aan een publiek van 85% vrouwen[11].Dit zou een typisch geval kunnen zijn waarin Advances in Social Science, Education and Humanities Research, volume 554859, bias in het systeem introduceert zonder menselijke tussenkomst.Om diversiteit in invoergegevens te waarborgen, zou het verzamelen van meer trainingsgegevens, specifiek met gevoelige groepen, oneerlijkheid helpen voorkomen.Als we het over een ander bedrijf hebben, versterkt Google ook seksuele discriminatie met behulp van het algoritme en het laat zien dat AdFisher, een geautomatiseerde tool die onderzoekt hoe gebruikersgedrag, de advertenties van Google en advertentie-instellingen op elkaar inwerken.AdFisher kan browsergebaseerde experimenten uitvoeren en gegevens analyseren met behulp van machine learning en significantietests.De advertentie-instellingen waren ondoorzichtig over sommige functies van het profiel van een gebruiker, waaronder het bieden van enige keuze voor advertenties.Wanneer u het geslacht op vrouwelijk instelt, krijgt u minder exemplaren van een advertentie met betrekking tot goedbetaalde banen dan wanneer u deze op mannen instelt.Enkele mogelijke redenen kunnen zijn dat Google het systeem expliciet programmeert om de advertentie minder vaak aan vrouwen te laten zien.Mannelijke en vrouwelijke consumenten reageren verschillend op advertenties en het targetingalgoritme van Google reageert op het verschil (Google heeft bijvoorbeeld geleerd dat mannen eerder op deze advertentie klikken dan vrouwen).Meer concurrentie voor advertenties voor vrouwen zorgt ervoor dat de adverteerder minder advertentieruimtes voor vrouwen wint.Sommige derden (bijvoorbeeld een hacker) manipuleren het advertentie-ecosysteem.Een onderzoek gebruikt gegevens van een veldtest van een advertentie die bedoeld was om vacatures en opleidingen in STEM (Science, Technology, Engineering en Math) te promoten.De advertentie was bedoeld om genderneutraal te zijn en was neutraal getarget.Deze advertentie is getest in 191 landen over de hele wereld.Hoe empirisch ook, de advertentie werd echter aan 20% meer mannen dan vrouwen getoond[12].Veel redenen hebben ertoe bijgedragen dat dit resultaatalgoritme probeerde de klikken te maximaliseren, waardoor advertenties meer aan mannen dan aan vrouwen werden getoond, of vrouwen bezoeken minder snel websites met advertenties erop.Alle resultaten wijzen op hetzelfde punt: omdat een woord vrouwen al vrijlaat voor lagere lonen / niet voor STEM-banen, zou de seksuele discriminatie van deze algoritmen een grotere kans creëren om te verhogen in plaats van te verminderen.To ensure diversity in input data, collecting more training data specifically with sensitive groups would help with unfairness.
SUGGESTION
Companies should invest in training and reskilling, provide possible training and apprenticeship programs for women.Also, companies and the government could consider reskilling opportunities for mid career women or women returning to the workforce.Companies should subsidize transition costs, government or corporate reskilling subsidies for targeted occupations and sectors.Community and governments could provide childcare subsidies for parents undergoing reskilling or pursuing higher education.Governments could invest in digital platforms, industry partnerships with massive open online courses.Companies should increase transparency on labour demand trends, contribute to more technical school or university curriculums co-created with industry, invest in informational campaigns targeting women.
Data testing: Put in place AI development standards, testing procedures, controls, and other technical governance elements designed to make sure the data used in training AI applications are thoroughly vetted and certified against a biased perspective before the application goes into production.Output testing: Establish testing requirements and controls around the outputs produced or decisions made by the AI.
Review and challenge these outputs and decisions against a biased perspective to make sure they represent fair and positive outcomes that are in line with expectations and do not adversely and unfairly impact any group of people.Development teams: Make sure AI design and development teams are diverse and include female data scientists, programmers, designers, and other key team members who influence how an AI application is developed.Set targets and put in place training, recruiting, and rotation programs to move toward this target.
CONCLUSION
Since automation is the major trend in the future, companies and the government should be double careful with the use of it.The effect of biased data, algorithms in the workforce could turnover the equality in the workforce.Thus companies must develop and deploy AI applications in a responsible manner that proactively seeks to identify and eliminate existing societal biases so they are not encoded and amplified in the digital world.Toward this goal, these are some future suggestions for companies and the government.It is important to note that, even though the focus of this essay is gender bias, AI applications can and often do suffer from different types of societal biases, for example, around race, ethnicity, and religion.As a result, companies should expand the above efforts and measures to make sure the AI applications they put in place do not hurt any group of people.
AI has the potential to mitigate the corporate gender and leadership gaps by removing bias in recruiting,
Advances in SocialDe impact van AI op banen en seksuele discriminatieINLEIDINGDe definitie van seksuele discriminatie zou een vorm van discriminatie kunnen zijn dat een persoon anders of ongelijk wordt behandeld vanwege zijn geslacht/geslacht.Hoewel volgens de federale wetgeving discriminatie op grond van geslacht op het werk illegaal is, komt dergelijke discriminatie nog steeds voor op het werkveld en is het altijd verborgen gebleven onder de norm.Zo heeft 42% van de vrouwen in de Verenigde Staten tijdens het werk te maken gehad met discriminatie op grond van geslacht[2].Een van de doelen van het creëren van AI is om te helpen met diversiteit, problemen als discriminatie en racisme op te lossen, maar of het werkt zoals mensen voorspelden, is nog steeds een vraagteken.De zorg is dat als AI en automatisering niet op een genderverantwoordelijke manier worden gebruikt, dit de reeds bestaande gendervooroordelen zou kunnen versterken.Vanwege een betere productiviteit en lagere kosten en arbeidskrachten, is het niet moeilijk voor te stellen dat AI-technologie in de toekomst dieper zou worden betrokken bij productie en banen in het algemeen.Automatisering, big data en algoritmen kunnen grote gevolgen hebben voor vrouwen in banen.De bezorgdheid over het vervangen van banen, het geautomatiseerde aanwervingssysteem, het vrijgeven van privacy-informatie aan het publiek, slecht geselecteerde trainingsgegevens, het probleem met het ontwerp van algoritmen en het probleem als gevolg van gegevensongelijkheid zouden allemaal seksuele discriminatie veroorzaken of beïnvloeden.Bedrijven en overheden zouden actie moeten ondernemen om het hoofd te bieden aan veranderingen veroorzaakt door AI om sociale orde, rechtvaardigheid en gelijkheid te waarborgen.2.3.2.2AUTOMATISERING AUTOMEFFECT.EFFECT .EFFHoewel de wereld wordt geconfronteerd met een ongekende groei in zowel banen als economie, heeft automatisering nog steeds een groot potentieel om tal van banen te vervangen en vooral die technologieën zijn repetitief en hebben in vergelijking daarmee weinig menselijke interactie.De automatiseringskosten zouden ook een van de overwegingen zijn.Een meerderheid van de werknemers met voorspelbare taken en activiteiten zou dus een hoog vervangingspercentage hebben.Hoe gaat het zich dan verhouden tot discriminatie op grond van geslacht.Hoewel er een grotere kans is dat het werk van vrouwen vatbaar is voor gedeeltelijke automatisering dan dat het volledig wordt vervangen.Volgens McKinsey's toekomstige voorspelling van vrouwentradities tegen 2030, zouden ongeveer 40 miljoen tot 160 miljoen vrouwen moeten overstappen van beroep en vaardigheden om aan het werk te blijven.Dit aantal bevestigde ook de behoefte aan hoger onderwijs en verschillende vaardigheden voor succes.Het is 7 tot 24 procent van de vrouwen dat momenteel werkt, vergeleken met het bereik van 8 tot 28 procent voor mannen.Als vrouwen profiteren van overgangsmogelijkheden, kunnen ze hun huidige aandeel in de werkgelegenheid behouden.Als ze dat niet kunnen, kan de ongelijkheid tussen mannen en vrouwen op het werk verergeren.Veel vrouwen zouden te maken kunnen krijgen met een steeds groter wordende loonkloof ten opzichte van mannen. Als ze dus niet de noodzakelijke overgang naar de arbeidsmarkt kunnen maken, zullen veel vrouwenSinds we het over automatisering hebben, zou het STEM-veld in de toekomst een grotere kans hebben op arbeidsvereisten.Uit de gegevens van 2019 bleek echter dat vrouwen slechts 27% van de werknemers in STEM-gekwalificeerde sectoren uitmaakten, om nog maar te zwijgen van het feit dat vrouwen gemiddeld 19% minder verdienden dan mannen[4]. Om nog maar te zwijgen van het feit dat 78% van de AI-professionals mannen zijn , worden algoritmen gemaakt met door mannen gedomineerde ervaringen.Dergelijke gendervooroordelen kunnen aanzienlijk nadelig zijn voor vrouwelijke werkgevers of cv's.Hoewel robotisering en automatisering op het werkveld beide geslachten zouden beïnvloeden, is het waarschijnlijk dat gendervooroordelen een rol gaan spelen en vrouwen onevenredig zwaar zullen treffen.Vrouwen die oververtegenwoordigd zijn in bepaalde automatiseringssectoren met een hoog risico zouden meer kunnen lijden.Het gebrek aan mobiliteit en flexibiliteit kan voor bedrijven ook een reden zijn om vrouwen werkloos te maken of onderhandelingsposities in te krimpen[5].De risico's bij automatisering zijn reëel. We moeten ons voorbereidenDe Amerikaanse Equal Employment Opportunity Commission onderzoekt ten minste twee gevallen van algoritmen die kunnen worden gediscrimineerd ten opzichte van bepaalde groepen sollicitanten[6].Om seksuele discriminatie te voorkomen, moet het onderwijssysteem vanaf het begin veranderen om discriminatie te stoppen, meer kansen en ondersteuning te bieden aan STEM-veld en toekomstige baanaanvullingen veroorzaakt door automatisering.3.3.2.3DE IMPACT VAN BIG DATA Big data-analyse en algoritmen zouden ook van invloed zijn op discriminatie in beroepen, het zou het traditionele wervingsproces kunnen omdraaien.Omdat de applicatie is gebaseerd op het verzamelen van big data.Als een AI-toepassing is getraind op biasdata, zijn de algoritmen waarschijnlijk vertekend.Een goed cijfer, school of capaciteiten zijn niet alleen de enige maatstaf.In de inhoud van het verzamelen van meer soorten gegevens, zouden de metadata van de sociale media-inhoud, familieleden, alles wat op afstand relevant is, allemaal een tweesnijdend zwaard zijn.Alle informatie online kan worden gebruikt om personen te identificeren, maar de privacywet is niet ontworpen om na te gaan welke persoonlijke informatie deze moet beschermen en hoe deze moet worden beschermd[7].De rekruteringstool die Amazon sinds 2014 heeft ontwikkeld, zou een van de voorbeelden kunnen zijn.Het programma werd zogenaamd gebruikt om de cv's van sollicitanten te bekijken om te zoeken naar de mensen met de grootste onbekwaamheid.Hoewel het de bedoeling is om een ​​sekseneutraal systeem te creëren, werd het resultaat overweldigend door mannen gedomineerd.De reden hierachter is dat het systeem van Amazon automatisch de cv's met het woord 'vrouwen' in hun sollicitaties heeft gedowngraded.Het bedrijf ontbond het team en kondigde aan dat de tool "nooit door Amazon-recruiters is gebruikt om kandidaten te evalueren. [8,9]" Het is echter moeilijk om hun woorden te bevestigen en zorgen te maken over de mogelijkheid dat bedrijven deze gediscrimineerde gegevens gebruiken bij het werven en aannemen.Dit zou geen uitzondering zijn, andere bedrijven die AI-automatisering gebruiken, zouden met hetzelfde probleem worden geconfronteerd.Ondanks deze zorgen zijn er nog steeds meer bedrijven die hard aan het werk zijn om meer delen van werving en aanwerving te automatiseren.De softwareontwikkelaars van het bedrijf zouden het systeem actief moeten monitoren om ervoor te zorgen dat zoiets niet gebeurt.Over het algemeen werkt AI efficiënter dan het menselijk brein, maar wanneer het systeem enorm is en de software achter een dashboard verborgen beslissingen neemt, bestaat er bezorgdheid over mogelijke ernstige juridische problemen.Hoewel het volgens de wetten van de EEOC (Equal Employment Opportunity Commission) onwettig is om iemand (sollicitant of werknemer) te discrimineren op grond van ras, huidskleur, religie, geslacht (inclusief genderidentiteit, seksuele geaardheid en zwangerschap), nationale afkomst , leeftijd (40 of ouder), handicap of genetische informatie , het is niet illegaal om iemand in dienst te nemenHet is ook onwettig om represailles te nemen tegen een persoon omdat hij of zij heeft geklaagd over discriminatie, een aanklacht wegens discriminatie heeft ingediend of heeft deelgenomen aan een onderzoek naar discriminatie op het werk of een rechtszaak[10].Algoritmen kunnen leiden tot gendervooroordelen. Wanneer de informatie echter onbedoeld wordt opgenomen en beoordeeld door bedrijven, roept dit meerdere vragen op vanwege het verantwoordelijkheidsprobleem. IMPACT VAN ALGORITMENWanneer we zoeken naar "CEO" op Google, levert het overweldigend mannelijke afbeeldingen op, we zeggen tegen onszelf dat Google alleen maar de wereld voor ons weergeeft "een wereld waar discriminatie bestaat".Wij zijn van mening dat de Google-bots die het web doorzoeken kleuren- en genderblind zijn.We vertrouwen op de algoritmen die onze zoekopdrachten objectiever beantwoorden dan mensen.Het is onmogelijk om aan te voeren dat het zoekalgoritme van Google en de bijbehorende platformen voor het weergeven van advertenties inherent bevooroordeeld zijn.Hoewel ze mogelijk zijn ontworpen om vooringenomenheid te verminderen, drijven de meeste wervingsalgoritmen standaard nog steeds in de richting van vooringenomenheid.In een recent onderzoek van Northeastern University en USC werden breed gerichte advertenties op Facebook voor kassafuncties in supermarkten getoond aan een publiek van 85% vrouwen[11].Dit zou een typisch geval kunnen zijn waarin Advances in Social Science, Education and Humanities Research, volume 554859, bias in het systeem introduceert zonder menselijke tussenkomst.Om diversiteit in invoergegevens te waarborgen, zou het verzamelen van meer trainingsgegevens, specifiek met gevoelige groepen, oneerlijkheid helpen voorkomen.Als we het over een ander bedrijf hebben, versterkt Google ook seksuele discriminatie met behulp van het algoritme en het laat zien dat AdFisher, een geautomatiseerde tool die onderzoekt hoe gebruikersgedrag, de advertenties van Google en advertentie-instellingen op elkaar inwerken.AdFisher kan browsergebaseerde experimenten uitvoeren en gegevens analyseren met behulp van machine learning en significantietests.De advertentie-instellingen waren ondoorzichtig over sommige functies van het profiel van een gebruiker, waaronder het bieden van enige keuze voor advertenties.Wanneer u het geslacht op vrouwelijk instelt, krijgt u minder exemplaren van een advertentie met betrekking tot goedbetaalde banen dan wanneer u deze op mannen instelt.Enkele mogelijke redenen kunnen zijn dat Google het systeem expliciet programmeert om de advertentie minder vaak aan vrouwen te laten zien.Mannelijke en vrouwelijke consumenten reageren verschillend op advertenties en het targetingalgoritme van Google reageert op het verschil (Google heeft bijvoorbeeld geleerd dat mannen eerder op deze advertentie klikken dan vrouwen).Meer concurrentie voor advertenties voor vrouwen zorgt ervoor dat de adverteerder minder advertentieruimtes voor vrouwen wint.Sommige derden (bijvoorbeeld een hacker) manipuleren het advertentie-ecosysteem.Een onderzoek gebruikt gegevens van een veldtest van een advertentie die bedoeld was om vacatures en opleidingen in STEM (Science, Technology, Engineering en Math) te promoten.De advertentie was bedoeld om genderneutraal te zijn en was neutraal getarget.Deze advertentie is getest in 191 landen over de hele wereld.Hoe empirisch ook, de advertentie werd echter aan 20% meer mannen dan vrouwen getoond[12].Veel redenen hebben ertoe bijgedragen dat dit resultaatalgoritme probeerde de klikken te maximaliseren, waardoor advertenties meer aan mannen dan aan vrouwen werden getoond, of vrouwen bezoeken minder snel websites met advertenties erop.Alle resultaten wijzen op hetzelfde punt: omdat een woord vrouwen al vrijlaat voor lagere lonen / niet voor STEM-banen, zou de seksuele discriminatie van deze algoritmen een grotere kans creëren om te verhogen in plaats van te verminderen.Om diversiteit in invoergegevens te waarborgen, zou het verzamelen van meer trainingsgegevens, specifiek met gevoelige groepen, oneerlijkheid helpen voorkomen.SUGGESTIEBedrijven zouden moeten investeren in opleiding en omscholing, en mogelijke opleidings- en stageprogramma's voor vrouwen moeten aanbieden.Bedrijven en de overheid zouden ook kunnen overwegen om herscholingsmogelijkheden te overwegen voor vrouwen in het midden van hun carrière of vrouwen die weer aan het werk gaan.Bedrijven moeten transitiekosten, overheids- of bedrijfsomscholingssubsidies subsidiëren voor specifieke beroepen en sectoren.De gemeenschap en de overheid zouden subsidies voor kinderopvang kunnen verstrekken aan ouders die een omscholing volgen of een hogere opleiding volgen.Governments could invest in digital platforms, industry partnerships with massive open online courses.