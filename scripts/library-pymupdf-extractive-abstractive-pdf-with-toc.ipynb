{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF inlezen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import fitz # PyMuPDF\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = fitz.open(\"../verslag\\output\\CluyseDylanBP.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De inhoudstafel ophalen en uitlezen. De uitvoer is een 2D-array met waarden: hoofdstuknummer, titel, de pagina waarop het hoofdstuk / de sectie start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'Lĳst van figuren', 7],\n",
       " [1, 'Inleiding', 9],\n",
       " [2, 'Probleemstelling', 10],\n",
       " [2, 'Onderzoeksvraag', 10],\n",
       " [2, 'Onderzoeksdoelstelling', 11],\n",
       " [2, 'Opzet van deze bachelorproef', 11],\n",
       " [1, 'Stand van zaken', 13],\n",
       " [2, 'Onderzoeken rond dyslexie', 13],\n",
       " [3, 'Centraal zicht op dyslexie', 13],\n",
       " [3, 'Fonologische dyslexie', 14],\n",
       " [3, 'Centraal zicht op de doelgroep', 14],\n",
       " [3, 'Diagnosecriteria', 15],\n",
       " [3, 'Moeilijkheden bij dyslexie', 16],\n",
       " [3, 'Aandachtspunten bij ondersteuning', 18],\n",
       " [3,\n",
       "  'Bewezen voordelen van tekstvereenvoudiging bij scholieren met dyslexie',\n",
       "  18],\n",
       " [2, 'Wetenschappelijke artikelen', 19],\n",
       " [3, 'Wetenschappelijke geletterdheid in Vlaanderen', 20],\n",
       " [3, 'Trends rond wetenschappelijke artikelen', 21],\n",
       " [3, 'Formaat', 23],\n",
       " [3, 'Woordenschat en vakjargon', 24],\n",
       " [3, 'Aanpak voor het lezen van wetenschappelijke artikelen', 24],\n",
       " [3, 'Conclusie', 25],\n",
       " [2, 'Tekstvereenvoudiging', 25],\n",
       " [3, 'Manuele tekstvereenvoudiging', 26],\n",
       " [3, 'Natural Language Processing', 27],\n",
       " [2, 'De verschillende soorten tekstvereenvoudiging', 30],\n",
       " [3, 'Lexicale vereenvoudiging', 31],\n",
       " [3, 'Syntactische vereenvoudiging', 32],\n",
       " [3, 'Conceptuele of semantische vereenvoudiging', 32],\n",
       " [3, 'Overige vormen van vereenvoudiging', 33],\n",
       " [3, 'Tekstvereenvoudiging automatiseren', 33],\n",
       " [3, 'Combineren tot het geheel van tekstvereenvoudiging', 33],\n",
       " [2, 'Samenvatten', 34],\n",
       " [3, 'Extractief samenvatten', 34],\n",
       " [3, 'Abstractief samenvatten', 38],\n",
       " [3, 'Hybride samenvatting', 38],\n",
       " [3, 'Evaluatie', 38],\n",
       " [3, 'Conclusie', 39],\n",
       " [2, 'Valkuilen', 39],\n",
       " [3, 'Taalgerelateerde valkuilen', 39],\n",
       " [3, 'Datasets', 39],\n",
       " [3, 'Paternalisme', 39],\n",
       " [3, 'Evaluatie en interpretatie', 40],\n",
       " [2, 'Beschikbare software voor tekstvereenvoudiging', 40],\n",
       " [3, 'Momenteel ingezet in het onderwijs', 41],\n",
       " [3, 'Proof-of-concepts en online webapplicaties', 41],\n",
       " [3, 'GPT-3', 41],\n",
       " [3, 'Bing AI', 46],\n",
       " [3, 'Google Bard en PaLM', 47],\n",
       " [3, 'Meta LLaMa', 48],\n",
       " [3, 'Samenvattend schema AI NLP-modellen', 48],\n",
       " [3, 'Conclusie', 48],\n",
       " [2, 'Conclusie', 48],\n",
       " [1, 'Methodologie', 49],\n",
       " [1, 'Conclusie', 51],\n",
       " [1, 'Onderzoeksvoorstel', 53],\n",
       " [2, 'Introductie', 53],\n",
       " [2, 'State-of-the-art', 54],\n",
       " [3, 'Tekstvereenvoudiging', 55],\n",
       " [3, 'Noden van scholieren met dyslexie', 55],\n",
       " [3, 'Huidige toepassingen', 57],\n",
       " [3, 'Ontwikkelen met AI', 57],\n",
       " [2, 'Methodologie', 58],\n",
       " [2, 'Verwacht resultaat, conclusie', 60],\n",
       " [1, 'Bibliografie', 61]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.get_toc()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings van de pdf ophalen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.embfile_names()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean die aanwijst of een bestand de pdf-extensie heeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.is_pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean dat aanwijst of een bestand het gepaste pdf-formaat heeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.is_form_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.is_reflowable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean dat aanwijst of een wachtwoord nodig is om de pdf te lezen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.needs_pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata van de pdf ophalen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': 'PDF 1.5',\n",
       " 'title': 'Scholieren met dyslexie van de derde graad middelbaar onderwijs ondersteunen bij het lezen van wetenschappelijke papers via tekstsimplificatie',\n",
       " 'author': 'Dylan Cluyse',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'producer': 'xdvipdfmx (20200315)',\n",
       " 'creationDate': \"D:20230308142407-00'00'\",\n",
       " 'modDate': '',\n",
       " 'trapped': '',\n",
       " 'encryption': None}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scholieren met dyslexie van de derde graad middelbaar onderwijs ondersteunen bij het lezen van wetenschappelijke papers via tekstsimplificatie'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.metadata.get('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.chapter_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functie dat de pagina's per hoofdstuk/sectie opvraagt. Het bereik is ``[start van hoofdstuk, start van volgend hoofdstuk - 1].`` De start wordt op 999 geplaatst, als er van uit wordt gegaan dat er geen pdf wordt geüpload met meer dan 999 pagina's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_per_title(chosen_title):\n",
    "    start = 999\n",
    "    end = pdf.page_count - 1\n",
    "    for title in pdf.get_toc():\n",
    "        if title[1] == chosen_title:\n",
    "            start = title[2]\n",
    "\n",
    "        if title[2] >= start and title[1] != chosen_title:\n",
    "            end = title[2]\n",
    "            break\n",
    "\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 26)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pages_per_title('Tekstvereenvoudiging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 23)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pages_per_title('Trends rond wetenschappelijke artikelen')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inhoud ophalen per bereik ``[Start, einde]``. Alle tekst tussen de tekst bovenaan de startpagina en onderaan de laatste pagina wordt opgenomen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_per_range(start, end):\n",
    "    text = \"\"\n",
    "    for i in range(start, end + 1):\n",
    "        page = pdf.load_page(i)\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voorbeeld:\n",
    "1. Start- en eindpagina van een hoofdstuk opvragen.\n",
    "2. Alle tekstinhoud van dit hoofdstuk opvragen.\n",
    "3. Onnodige tekens en regeleindes verwijderen.\n",
    "4. Eerste 500 tokens uitprinten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Trends rond wetenschappelijke artikelen'\n",
    "start, end = get_pages_per_title(title)\n",
    "text = get_content_per_range(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def text_cleaning(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'\\d+\\.\\d+\\.\\d+\\.', '', text) # 2.2.2 Stand van Zaken verwijderen.\n",
    "    text = text.strip('.')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 2. Stand van zaken kers (Ball, 2017; Jones e.a., 2019; Plavén-Sigray e.a., 2017). Plavén-Sigray e.a. (2017) onderzoekt de verschillende trends waarom wetenschap- pelijke artikelen alsmaar moeilijker te lezen worden. De relatie tussen de leesbaar- heid van een abstract werd vergeleken met het jaar waarin het wetenschappelijk artikel werd gepubliceerd. De Flesch-Reading-Ease of FRE score werd gebruikt om de leesgraad van een wetenschappelijk artikel te beoordelen. Om te bevesti- gen dat de rela\n"
     ]
    }
   ],
   "source": [
    "text = text_cleaning(text)\n",
    "print(text[:500])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taal achterhalen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nl'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language = detect(text)\n",
    "language"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting tokens\n",
    "\n",
    "There are still too many tokens. We need to resort to an in-between method: extractive summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5431"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "fdist = FreqDist(text)\n",
    "fdist.N()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14 2.',\n",
       " 'Stand van zaken kers (Ball, 2017; Jones e.a., 2019; Plavén-Sigray e.a., 2017).',\n",
       " 'Plavén-Sigray e.a.',\n",
       " '(2017) onderzoekt de verschillende trends waarom wetenschap- pelijke artikelen alsmaar moeilijker te lezen worden.',\n",
       " 'De relatie tussen de leesbaar- heid van een abstract werd vergeleken met het jaar waarin het wetenschappelijk artikel werd gepubliceerd.',\n",
       " 'De Flesch-Reading-Ease of FRE score werd gebruikt om de leesgraad van een wetenschappelijk artikel te beoordelen.',\n",
       " 'Om te bevesti- gen dat de relatie tussen de complexiteit van een abstract overeenstemt met die van de volledige tekstinhoud, werden er vergelijkingen gemaakt met zes verschil- lende wetenschappelijke journalen.',\n",
       " 'De overeenkomst tussen de leesgraad van het abstract en de overige tekstinhoud in een wetenschappelijk artikel werd eerder be- vestigd door Dronberger en Kowitz (1975).',\n",
       " 'Dat onderzoek benadrukte dat een ab- stract complexer werd geschreven, vergeleken met de rest van een wetenschappe- lijk artikel.',\n",
       " 'Figuur (2.6) Afbeelding uit Plavén-Sigray e.a.',\n",
       " '(2017).',\n",
       " 'Links wordt de evolutie per FRE-score getoond.',\n",
       " 'Hoe hoger de score, hoe hoger de gemiddelde complexiteit van een tekst.',\n",
       " 'Rechts wordt de evolutie volgens de NDC-score getoond.',\n",
       " 'Hoe hoger de score, hoe lager de gemiddelde complexiteit van een tekst.',\n",
       " 'Het onderzoek schat dat nu een kwart van alle wetenschappelijke artikelen gebruik maken van Engels op het niveau van een masterstudent, ofwel een FRE onder nul.',\n",
       " '2.2.',\n",
       " 'Wetenschappelijke artikelen 15 Figuur (2.7) Afbeelding uit Plavén-Sigray e.a.',\n",
       " '(2017).',\n",
       " 'Horizontaal worden het aantal auteurs per wetenschappelijk artikel aangeduidt.',\n",
       " 'Verticaal wordt de gemiddelde NDC-score weergegeven.',\n",
       " 'HOe hoger de NDC- score, hoe hoger de vereiste leesgraad om de tekst te kunnen lezen.',\n",
       " 'De hoge leesgraad van wetenschappelijke artikelen beperkt volgens Plavén-Sigray e.a.',\n",
       " '(2017) twee aspecten: de toegankelijkheid en de herproduceerbaarheid.',\n",
       " 'Toegankelijkheid Bronnen worden minder toegankelijk tot het algemene publiek.',\n",
       " 'Wetenschappe- lijke artikels worden enkel toegankelijk tot mensen die wetenschappelijk geletterd zijn of een leesgraad daarboven hebben.',\n",
       " 'F en Ennals (2010) zegt dat wetenschap ons de nauwkeurige kennis moet geven, omdat mensen zich zorgen maken dat moderne samenlevingen minder streng worden met feitelijke waarheden en deze vervangen door post-facts die waar lijken te klinken.',\n",
       " 'Wetenschappelijke inhoud moet volgens hem zo toegankelijk mogelijk worden gemaakt, zodat een zo breed mogelijk publiek de kern begrijpt.',\n",
       " 'Reproduceerbaarheid Onbegrijpelijke en ontoegankelijke zinsstructuren hinderen ook vakexperten.',\n",
       " 'Het herschrijven van abstracten vergroot de begrijpbaarheid bij academici volgens Hart- ley (1999) en Snow (2010).',\n",
       " 'De wetenschap bouwt voort op betrouwbare ontdek- kingen en het reproduceren van experimenten is een belangrijke manier voor we- tenschappers om vertrouwen te krijgen in hun besluiten.',\n",
       " 'De inhoud van het we- tenschappelijke artikel moet gecontroleerd kunnen worden.',\n",
       " 'Voor de reproduceer- baarheid van onderzoeken is het volgens McNutt (2014) belangrijk dat de metho- dologie en resultaten begrijpelijk zijn.',\n",
       " 'Een lage leesgraad en duidelijke zinsbouw beperkt het aantal misopvattingen en verwarringen bij onderzoekers.',\n",
       " '16 2.',\n",
       " 'Stand van zaken  Formaat Experimenten uit Hubbard en Dunbar (2017) wijzen erop dat de bevraagde onder- zoekers zowel de methodologie als de resultaten de twee componenten vonden die een hoge leesgraad vergden.',\n",
       " 'Woordenschat en vakjargon Complexe processen, methoden en ideeën worden in wetenschappelijke artikelen verwoord met gebruik van grammatische embeddings, doordachte en abstracte woordenschat en naamwoordstijlen.',\n",
       " 'De kenmerken van academische taal varië- ren afhankelijk van de discipline, het onderwerp en de vorm, maar er zijn gemeen- schappelijke kenmerken die wetenschappelijke taal onderscheiden van taal van een lagere leesgraad.',\n",
       " '(F & Ennals, 2010; Snow, 2010) Wetenschappelijke artikelen dienen volgens Plavén-Sigray e.a.',\n",
       " '(2017) in eerste in- stantie als uitwisseling van kennis tussen vakexperten.',\n",
       " 'Daarnaast moet er rekening worden gehouden met de lengte wat een nadelig effect heeft op de beschikbare uitleg voor deze terminologie.',\n",
       " 'Snow (2010) beklemtoont dat deze zaken in het onderwijs moeten betrokken wor- den.',\n",
       " 'STEM-vakken of vakken waar deze wetenschappelijke artikelen aan bod ko- men, moeten stil staan bij voldoende uitleg over de toegepaste grammatica en woordenschat voorzien tijdens de lessen.',\n",
       " 'Figuur (2.8) Afbeelding van (...) Volgens deze grafiek scoren de wetenschappelijke artikels rond fysica gemiddeld het best op de FRE-score.',\n",
       " 'Al scoren de wetenschappelijke artikels rond microbiologie gemiddeld het zwakst op de FRE-score, ze scoren gemiddeld beter op de FOG-score.',\n",
       " 'Aanpak voor het lezen van wetenschappelijke artikelen Als reactie op een satirisch artikel van Ruben (2016), bracht Pain (2016) het onder- werp bij wetenschappers aan het licht om zo verschillende tactieken te verzamelen om wetenschappelijke artikelen te begrijpen.',\n",
       " 'Sommige wetenschappers zoeken direct onbekende woorden op of raadplegen extra informatiebronnen, terwijl an- dere wetenschappers hoofdstukken overslaan.',\n",
       " 'Het is belangrijk om een balans te vinden tussen het begrijpen van de inhoud en het efficiënt gebruiken van de tijd.',\n",
       " 'Sommige wetenschappers geven toe dat ze het soms opgeven als het te moeilijk wordt of als de literatuur net niet relevant is voor hun onderzoek.',\n",
       " 'Pain2016 bouwt']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.sent_tokenize(text)\n",
    "text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive summarization\n",
    "\n",
    "Note: Both do not currently work in this set-up. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at GroNLP/bert-base-dutch-cased were not used when initializing TFBertModel: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at pdelobelle/robbert-v2-dutch-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/wietsedv/bertje\n",
    "\n",
    "from summarizer import Summarizer\n",
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "from transformers import BertTokenizer, TFBertLMHeadModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\", revision=\"v1\")\n",
    "model = TFAutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "\n",
    "# https://github.com/iPieter/RobBERT\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(40000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='pdelobelle/robbert-v2-dutch-base', vocab_size=40000, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dylan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "sentences = nltk.tokenize.sent_tokenize(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractive summarization with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "summarizer = Summarizer()\n",
    "\n",
    "result = summarizer(\n",
    "    #algorithm=...,\n",
    "    body=' '.join(sentences),\n",
    "    max_length=460,\n",
    "    min_length=60,\n",
    "    num_sentences=4,\n",
    "    #ratio=...,\n",
    "    #return_as_list=...,\n",
    "    #use_first=...,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017) onderzoekt de verschillende trends waarom wetenschap- pelijke artikelen alsmaar moeilijker te lezen worden. Het onderzoek schat dat nu een kwart van alle wetenschappelijke artikelen gebruik maken van Engels op het niveau van een masterstudent, ofwel een FRE onder nul. Wetenschappe- lijke artikels worden enkel toegankelijk tot mensen die wetenschappelijk geletterd zijn of een leesgraad daarboven hebben. Sommige wetenschappers zoeken direct onbekende woorden op of raadplegen extra informatiebronnen, terwijl an- dere wetenschappers hoofdstukken overslaan.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1127"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = FreqDist(' '.join(result))\n",
    "fdist.N()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstractive summarization + text simplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tiktoken\n",
    "import configparser, os\n",
    "\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "openai.api_key = config['openai']['api_key']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of abstractive summarization (no language explicitly stated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5590"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amount_words_sentence = 10\n",
    "amount_sentences = 1\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Vereenvoudig deze tekst met deze parameters:\n",
    "Zin is max {amount_words_sentence} woorden lang\n",
    "Max {amount_sentences} aantal zinnen.\n",
    "Schrijf dit met zo een eenvoudig mogelijke woordenschat.\n",
    "context: \n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "fdist = FreqDist(prompt)\n",
    "fdist.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wetenschappelijke artikelen zijn moeilijk te lezen. Onderzoek toont aan dat een kwart van de artikelen Engels gebruikt op het niveau van een masterstudent. Dit beperkt de toegankelijkheid en reproduceerbaarheid. Onderwijs moet stilstaan bij de woordenschat en grammatica. Wetenschappers gebruiken verschillende tactieken om artikelen te begrijpen.'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of explaining a complex term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_word = \"reproduceerbaarheid\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Wat is {chosen_word} in de context van {title}\n",
    "\"\"\"\n",
    "\n",
    "fdist = FreqDist(prompt)\n",
    "fdist.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reproduceerbaarheid is de mate waarin de resultaten van een wetenschappelijk artikel kunnen worden herhaald door andere onderzoekers. Het is een belangrijk principe in de wetenschap, omdat het de betrouwbaarheid van de resultaten vergroot. Reproduceerbaarheid is een van de trends die momenteel worden gezien in wetenschappelijke artikelen, waarbij onderzoekers worden aangemoedigd om hun methoden en resultaten zo transparant mogelijk te maken, zodat anderen hun werk kunnen herhalen.'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the hard-to-read words with Flesch-Kincaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Flesch-Kincaid Grade level of the text is 11.5, and the Flesch Reading Ease score is 28.5.\n"
     ]
    }
   ],
   "source": [
    "s = 'Wetenschappelijke artikelen zijn moeilijk te lezen. Onderzoek toont aan dat een kwart van de artikelen Engels gebruikt op het niveau van een masterstudent. Dit beperkt de toegankelijkheid en reproduceerbaarheid. Onderwijs moet stilstaan bij de woordenschat en grammatica. Wetenschappers gebruiken verschillende tactieken om artikelen te begrijpen.'\n",
    "\n",
    "# Calculate readability scores\n",
    "fk_grade = textstat.flesch_kincaid_grade(s)\n",
    "fk_reading_ease = textstat.flesch_reading_ease(s)\n",
    "\n",
    "# Format results into a sentence\n",
    "result = \"The Flesch-Kincaid Grade level of the text is {}, and the Flesch Reading Ease score is {}.\".format(fk_grade, fk_reading_ease)\n",
    "\n",
    "# Print result\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive-abstractive summarization for a long document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(extracted_text):\n",
    "    amount_words_sentence = 10\n",
    "    amount_sentences = 3\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Vereenvoudig deze tekst met deze parameters:\n",
    "    Zin is max {amount_words_sentence} woorden lang\n",
    "    Max {amount_sentences} aantal zinnen.\n",
    "    Schrijf dit met zo een eenvoudig mogelijke woordenschat.\n",
    "    context: \n",
    "    {extracted_text}\n",
    "    \"\"\"\n",
    "\n",
    "    return openai.Completion.create(\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=300,\n",
    "        model=COMPLETIONS_MODEL)[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_summarized_doc = []\n",
    "\n",
    "for title in pdf.get_toc()[3:]:\n",
    "    start, end = get_pages_per_title(title[1])\n",
    "    text = get_content_per_range(start, end)\n",
    "    cleaned_text = text_cleaning(text)\n",
    "    \n",
    "    \n",
    "    result = summarizer(\n",
    "        #algorithm=...,\n",
    "        body=text,\n",
    "        max_length=460,\n",
    "        min_length=60,\n",
    "        num_sentences=4,\n",
    "        #ratio=...,\n",
    "        #return_as_list=...,\n",
    "        #use_first=...,\n",
    "    )\n",
    "    \n",
    "    full_summarized_doc.append(ask_gpt(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Onderzoeksvraag\\nDe volgende onderzoeksvraag is opgesteld: ”Hoe kan een wetenschappelijke arti-\\nkel automatisch vereenvoudigd worden, gericht op de unieke noden van scholie-\\nren met dyslexie in de derde graad middelbaar onderwijs?”. • Welke specifieke noden hebben scholieren met dyslexie van de derde graad\\nmiddelbaar onderwijs bij het begrijpen van complexere teksten? • Wat zijn de specifieke kenmerken van wetenschappelijke artikelen? Inleiding\\nIn Hoofdstuk 3 wordt de methodologie toegelicht en w'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_summarized_doc[:500]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89da10480825c8ad24c96d10788e772e9a68ac77e314b3c42d655a8c40ed70a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
