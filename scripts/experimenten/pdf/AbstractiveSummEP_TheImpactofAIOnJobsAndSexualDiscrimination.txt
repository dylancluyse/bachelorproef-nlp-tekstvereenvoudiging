Samenvatting:
Kunstmatige intelligentie wordt steeds meer toegepast in banen door bedrijven en individuen. De voordelen hiervan zijn zowel voorspelbaar als onvoorspelbaar. Seksuele discriminatie in banen is ook een omstreden onderwerp. Het doel van dit artikel is om de onderwerpen AI en seksuele discriminatie te combineren en te bespreken wat hun effecten zullen zijn op de arbeidsmarkt in de toekomst.
Samenvattend: Automatisering is het gebruik van machines en computers om menselijke tussenkomst te verminderen. Big data is een verzameling gegevens uit verschillende bronnen, het is gerelateerd aan AI omdat hoe meer gegevens er worden ingevoerd, hoe beter AI wordt. AI-algoritme neemt de gegevensinvoer en gebruikt wiskunde en logica om de uitvoer te produceren. Dit zijn enkele punten om te ontdekken in het veld van werk.
Gender discriminatie in AI weerspiegelt niet alleen de bestaande vooroordelen in de samenleving, maar kan deze ook versterken door automatisering, aannameprocedures en besluitvorming. Dit artikel is niet volledig tegen het gebruik van AI, maar pleit ervoor dat kunstmatige intelligentie op een meer verantwoorde manier gebruikt wordt om seksuele discriminatie op de arbeidsmarkt te verminderen. Seksuele discriminatie kan een vorm van discriminatie zijn waarbij iemand anders wordt behandeld of ongelijk wordt behandeld vanwege hun geslacht. Hoewel discriminatie op basis van geslacht in de werkomgeving volgens federaal recht verboden is, gebeurt het nog steeds op de arbeidsmarkt en is het altijd verborgen gebleven onder de norm. Bijvoorbeeld, 42% van de vrouwen in de Verenigde Staten heeft te maken gehad met genderdiscriminatie op het werk.
Een van de doelen van het maken van AI is om te helpen met diversiteit, problemen zoals discriminatie en racisme oplossen. Of het werkt zoals voorspeld is echter nog steeds een vraagteken. Er is zorg dat AI en automatisering niet op een gender verantwoorde manier gebruikt worden, waardoor bestaande gender bias versterkt kan worden. Door betere productiviteit en lagere kosten en minder arbeiders is het niet moeilijk om te denken dat AI technologie in de toekomst meer betrokken zal zijn bij productie en banen in het algemeen. Automatisering, big data en algoritmes kunnen grote invloed hebben op vrouwen in banen. De zorgen over vervanging van banen, geautomatiseerde aanname systemen, privacy informatie die openbaar wordt, slecht geselecteerde trainingsdata, problemen met algoritme ontwerp en problemen door data ongelijkheid zullen allemaal seksuele discriminatie veroorzaken of beïnvloeden.
Bedrijven en overheden moeten actie ondernemen om veranderingen door AI tegemoet te treden om sociale orde, rechtvaardigheid en gelijkheid te waarborgen. Automatisering heeft een hoog potentieel om veel banen te vervangen, vooral die technologieën die herhalend zijn en weinig menselijke interactie hebben. De kosten om te automatiseren zouden ook een van de overwegingen zijn. Dus de meerderheid van de werknemers die voorspelbare taken en activiteiten uitvoeren, zou een hoge vervangingsgraad hebben. Hoe gaat dit dan gerelateerd worden aan genderdiscriminatie?
Hoewel er een grotere kans is dat vrouwenbanen gedeeltelijk geautomatiseerd worden dan dat ze volledig vervangen worden, voorspelt McKinsey dat tussen de 40 miljoen en 160 miljoen vrouwen tegen 2030 een overstap naar andere beroepen en vaardigheden nodig hebben om werk te behouden[3]. Dit aantal benadrukt ook de noodzaak van hoger onderwijs en andere vaardigheden voor succes. Momenteel is het aandeel vrouwen dat werkt 7 tot 24 procent, tegenover 8 tot 28 procent voor mannen. Als vrouwen gebruik maken van overstapmogelijkheden, kunnen ze hun huidige aandeel in de werkgelegenheid behouden.
Als ze dat niet kunnen, kan de ongelijkheid tussen mannen en vrouwen op de werkvloer erger worden. Als ze de noodzakelijke overgang niet kunnen maken, zullen veel vrouwen een toenemende loonkloof ten opzichte van mannen ervaren. Door de automatisering zal het STEM-veld meer mogelijkheden bieden voor toekomstige werkgelegenheid. In 2019 bleek echter dat vrouwen slechts 27% van de werknemers in STEM-gekwalificeerde industrieën uitmaakten, laat staan dat ze gemiddeld 19% minder verdienden dan mannen[4]. Bovendien zijn 78% van de AI-professionals mannen, waardoor algoritmes worden gemaakt met mannen gedomineerde ervaringen.
Geslachtsdiscriminatie kan vrouwelijke werkgevers of cv's sterk benadelen. Hoewel robotisering en automatisering in de arbeidsmarkt beide geslachten zullen beïnvloeden, is het waarschijnlijk dat vooroordelen een rol spelen en vrouwen disproportioneel beïnvloeden. Vrouwen die oververtegenwoordigd zijn in bepaalde sectoren met hoog risico op automatisering, kunnen ook te maken krijgen met gebrek aan mobiliteit en flexibiliteit. Dit kan bedrijven ertoe aanzetten vrouwen te ontslaan of hun onderhandelingspositie te verminderen. De risico's van automatisering zijn reëel.
Het Equal Employment Opportunity Commission van de VS onderzoekt ten minste twee gevallen waarbij algoritmes discriminatie kunnen veroorzaken ten opzichte van bepaalde groepen sollicitanten[6]. Om seksuele discriminatie te voorkomen, moet het onderwijssysteem vanaf het begin veranderen om discriminatie te stoppen, meer kansen en ondersteuning te bieden aan STEM-velden en toekomstige baanvervangingen veroorzaakt door automatisering. IMPACT VAN BIG DATA Big data-analyse en algoritme zouden ook invloed hebben op discriminatie in beroepen, het kan de traditionele aannameprocedure omkeren. Aangezien de aanvraag is gebaseerd op de verzameling van grote gegevens. Als een AI-toepassing is getraind op vooringenomen gegevens, zullen de algoritmes waarschijnlijk vooringenomen zijn.
Goede cijfers, school of vaardigheden zouden niet de enige meting zijn. Bij het verzamelen van meer soorten gegevens, de metadata van de sociale media-inhoud, familieleden, alles wat op afstand relevant is, zou allemaal een dubbelzijdige zwaard zijn. Alle informatie online kan worden gebruikt om individuen te identificeren, maar de privacywetgeving was niet ontworpen om te overwegen welke persoonlijke informatie moet worden beschermd en hoe dit te doen. Het rekruteringshulpmiddel dat Amazon sinds 2014 heeft ontwikkeld, kan een voorbeeld zijn. Het programma zou worden gebruikt om cv's van kandidaten te beoordelen om de mensen te zoeken die het beste zijn in vaardigheden.
Hoewel de bedoeling was om een genderneutem systeem te creëren, resulteerde het in een overwegend mannelijk gedomineerd systeem. De reden hiervoor is dat Amazons systeem automatisch de cv's die het woord "vrouwen" in hun aanvragen hadden, degradeerde. Het bedrijf ontbond het team en kondigde aan dat het gereedschap "nooit door Amazon recruiters is gebruikt om kandidaten te evalueren". [8,9] Toch is het moeilijk hun woorden te autoriseren en te vrezen voor de mogelijkheid dat bedrijven deze gediscrimineerde gegevens gebruiken bij het rekruteren en aannemen. Dit zou geen uitzondering zijn, andere bedrijven zouden hetzelfde probleem tegenkomen bij het gebruik van AI-automatisering. Ondanks deze zorgen, duwen meer bedrijven nog steeds hard om meer delen van rekrutering en aanneming te automatiseren.
Het bedrijf moet actief het systeem monitoren om te voorkomen dat er iets dergelijks gebeurt. AI werkt meestal efficiënter dan het menselijk brein, maar als het systeem groot is en de software beslissingen neemt achter een dashboard, zijn er zorgen over mogelijke juridische problemen. Volgens de wetten van de EEOC is het illegaal om iemand (sollicitant of werknemer) te discrimineren op basis van ras, kleur, religie, geslacht (inclusief genderidentiteit, seksuele geaardheid en zwangerschap), nationaliteit, leeftijd (40 jaar of ouder), handicap of genetische informatie. Het is ook verboden om wraak te nemen op iemand die klaagt over discriminatie, een klacht indient of deelneemt aan een onderzoek of rechtszaak. Als de informatie echter onbedoeld wordt meegenomen en beoordeeld door bedrijven, stelt dit vragen over verantwoordelijkheden.
Algoritmen kunnen leiden tot genderbias. Als we op Google zoeken naar 'CEO' krijgen we overwegend mannelijke afbeeldingen. We vertellen onszelf dat Google de wereld aan ons weergeeft, "een wereld waar discriminatie bestaat". We geloven dat de Google-bots die het web crawlen kleur- en genderblind zijn. We vertrouwen erop dat de algoritmen die onze zoekopdrachten beantwoorden objectiever zijn dan mensen. Men kan niet beweren dat Googles zoekalgoritme en de daarmee gerelateerde advertentieplatformen inherent gebiased zijn.
Hoewel ze ontworpen zijn om vooroordelen te verminderen, blijven de meeste aanwervingsalgoritmes standaard naar vooroordelen neigen. In een recent onderzoek van de Northeastern University en de USC werd aangetoond dat er breed gerichte advertenties op Facebook voor kassamedewerkerposities aan een publiek van 85% vrouwen werden getoond [11]. Dit kan een typisch geval zijn waarbij algoritmes zonder menselijke tussenkomst vooroordelen in het systeem introduceren. Om diversiteit in de invoergegevens te garanderen, zou het verzamelen van meer trainingsgegevens specifiek met kwetsbare groepen helpen om onrechtvaardigheid te voorkomen.
Als het gaat over een ander bedrijf, versterkt Google ook seksuele discriminatie met behulp van het algoritme. Dit wordt duidelijk met AdFisher, een geautomatiseerd hulpmiddel dat onderzoekt hoe gebruikersgedrag, Google-advertenties en Ad-instellingen samenwerken. AdFisher kan browsergebaseerde experimenten uitvoeren en gegevens analyseren met behulp van machine learning en significantietests. De Ad-instellingen waren vaag over sommige functies van een gebruikersprofiel, waaronder het bieden van enkele keuzes voor advertenties. Als het geslacht wordt ingesteld op vrouw, resulteert dit in minder voorbeelden van een advertentie met betrekking tot hoogbetaalde banen dan als het wordt ingesteld op man. Mogelijke redenen kunnen zijn dat Google het systeem expliciet programmeert om de advertentie minder vaak aan vrouwen te tonen.
Mannen en vrouwen reageren anders op advertenties en Google's targeting-algoritme reageert op deze verschillen (bijv. Google heeft geleerd dat mannen meer geneigd zijn om op deze advertentie te klikken dan vrouwen). Er is meer concurrentie voor adverteren naar vrouwen, waardoor de adverteerder minder advertentieplekken voor vrouwen wint. Sommige derden (bijv. een hacker) manipuleren het advertentie-ecosysteem. Een onderzoek gebruikt gegevens van een veldtest van een advertentie die bedoeld was om banen en opleidingen in STEM (Wetenschap, Technologie, Ingenieurswetenschappen en Wiskunde) te promoten. De advertentie was bedoeld om genderneutraal te zijn en werd neutraal gericht.
Deze advertentie werd getest in 191 landen over de hele wereld. Empirisch bleek echter dat de advertentie 20% meer aan mannen dan aan vrouwen werd getoond [12]. Veel redenen droegen bij aan dit resultaat: algoritmes die proberen de kliks te maximaliseren door meer advertenties aan mannen dan aan vrouwen te tonen, of vrouwen die minder geneigd zijn om websites met advertenties te bezoeken. Alle resultaten wijzen op hetzelfde punt: omdat een woord al leidt tot lagere lonen / geen STEM-banen voor vrouwen, zou discriminatie door deze algoritmes de kans vergroten om te verhogen in plaats van te verminderen. Om diversiteit in de invoergegevens te garanderen, zou het verzamelen van meer trainingsgegevens specifiek met kwetsbare groepen helpen bij ongelijkheid.
Bedrijven moeten investeren in opleiding en herscholing, mogelijke opleidingen en leerbanen voor vrouwen aanbieden. Ook kunnen bedrijven en de overheid herscholingsmogelijkheden voor vrouwen in het midden van hun carrière of vrouwen die terugkeren naar de arbeidsmarkt overwegen. Bedrijven moeten overgangs- en herscholingskosten subsidiëren, overheids- of bedrijfssubsidies voor bepaalde beroepen en sectoren. Gemeenschappen en overheden kunnen kinderopvangsubsidies aanbieden voor ouders die herscholing volgen of hoger onderwijs volgen. Overheden kunnen investeren in digitale platformen, samenwerkingen met grote open online cursussen.
Bedrijven moeten transparanter worden over arbeidsvraagtrends, bijdragen aan meer technische school- of universiteitscurricula die samen met de industrie zijn gecreëerd, investeren in informatiecampagnes gericht op vrouwen. Data-testen: stel AI-ontwikkelingsstandaarden, testprocedures, controles en andere technische bestuursaspecten op om ervoor te zaken dat de data die wordt gebruikt bij het trainen van AI-applicaties grondig wordt gecontroleerd en gecertificeerd tegen een vooringenomen perspectief voordat de applicatie in productie gaat. Outputtesten: stel testvereisten en controles op rond de uitvoer die door de AI wordt geproduceerd of de beslissingen die worden genomen. Beoordeel en bevraag deze uitvoer en beslissingen tegen een vooringenomen perspectief om ervoor te zorgen dat ze eerlijke en positieve resultaten vertegenwoordigen die in lijn zijn met de verwachtingen en geen nadelige en onrechtvaardige gevolgen hebben voor een bepaalde groep mensen. Ontwikkelteams: zorg ervoor dat AI-ontwerp- en ontwikkelteams divers zijn en vrouwelijke datawetenschappers, programmeurs, ontwerpers en andere sleutelteamleden bevatten die invloed hebben op de manier waarop een AI-applicatie wordt ontwikkeld. Stel doelen en stel opleidingen, wervings- en rotatieprogramma's op om naar dit doel te bewegen.
Conclusie: Automatisering is de toekomstige trend, dus bedrijven en de overheid moeten extra voorzichtig zijn bij het gebruik ervan. De gevolgen van vooringenomen data en algoritmes in de arbeidsmarkt kunnen de gelijkheid in de arbeidsmarkt omkeren. Daarom moeten bedrijven AI-applicaties op een verantwoorde manier ontwikkelen en implementeren die proactief zoeken naar bestaande maatschappelijke vooroordelen om deze niet te coderen en te versterken in de digitale wereld. Om dit doel te bereiken, zijn dit enkele toekomstige suggesties voor bedrijven en de overheid. Het is belangrijk om te vermelden dat, hoewel de focus van dit essay gendervooroordelen is, AI-applicaties kunnen en vaak lijden onder verschillende soorten maatschappelijke vooroordelen, bijvoorbeeld rond ras, etniciteit en religie.
Gevolg hiervan is dat bedrijven hun bovenstaande inspanningen en maatregelen moeten uitbreiden om ervoor te zorgen dat de AI-toepassingen die ze inzetten geen enkele groep mensen schaden. AI heeft het potentieel om de gender- en leiderschapskloof in bedrijven te verminderen door vooroordelen weg te nemen bij het rekruteren, evalueren en bevorderen van werknemers, wat helpt om vrouwelijke werknemers te behouden, en mogelijk door in te grijpen in de dagelijkse interacties die invloed hebben op het gevoel van inclusie van werknemers. Het effect van AI zou meerdere zorgen kunnen veroorzaken, maar betekent niet dat de samenleving zou stoppen met het verkennen van dit veld. Het doel van het creëren van technologie is altijd voor grotere goederen. Maar als AI en automatisering niet volledig ontwikkeld en op een genderverantwoorde manier toegepast worden, zijn ze waarschijnlijk bestaande genderstereotypen te reproduceren en te versterken.
Zo moeten bedrijven en individuen extra voorzichtig zijn en maatregelen nemen om seksediscriminatie tegen te gaan. Daarnaast moet de overheid ook wetgeving en educatie ondersteunen om gelijkheid te bevorderen.
