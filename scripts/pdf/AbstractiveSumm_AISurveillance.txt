Controle op gebruik algoritmische surveillance onder druk? Exploratie door lens relationele ethiek. Na einde 20e eeuw technologische ontwikkelingen nieuwe mogelijkheden data verzamelen en analyseren. Opkomst 'big data' en AI 21e eeuw met interesse omarmd door politie. Gebruik technologieën door politie algoritmische surveillance. Algoritmische systemen.
Gebruik maken van regels om gestructureerde en ongestructureerde gegevens te categoriseren, bewaren, samenvoegen en doorzoeken; vergelijken met andere gegevens en overeenkomsten vinden; machine-lerende algoritmes gebruiken om patronen en bruikbare kennis in grote datasets te voorspellen. Ondanks de strengere wetgeving, die de democratische waarborgen moet garanderen, lijkt het gebruik ervan te worden gestimuleerd. Denk bijvoorbeeld aan de toename van 'intelligent' cameratoezicht in België en andere Europese landen. Is de huidige controle voldoende om alle burgers te beschermen tegen de mogelijke gevolgen van algoritmische surveillance door de politie?
Doel van deze bijdrage is nadenken over vraag of huidige controle en handhaving voor gebruik algoritmische surveillance door politie moeten herdenken. Eerste deel artikel bespreekt drie sociotechnische ontwikkelingen die kader onder druk zetten. Tweede deel bekijkt huidige controle- en handhavingsmechanismen door bril van relationele ethiek om te leren hoe herdenken. Fragmentatie en privatisering politiewerk, veranderende verhouding tussen politie en burgers en veranderende verhouding tussen politie en technologie zetten kader onder druk.
Democratisering van surveillance, toename van collectieve schade en sociale gevolgen. Deze ontwikkelingen zijn verbonden en niet los te zien. Al sinds het einde van de twintigste eeuw is er in het Westen een toename van samenwerking met de private sector en spelen zij een grotere rol in politiewerk. Dit komt door de macht en groei van de private sector en bezuinigingen in de publieke sector.
Technologische vooruitgang in big data en AI aan het begin van de 21e eeuw heeft geleid tot meer macht voor technologiebedrijven door 'surveillance kapitalisme', waarbij gegevensverzameling een economische motor is. Politiewerk wordt steeds meer 'platform policing', waarbij de politie gebruik maakt van digitale platformen en technologie. Dit maakt de politie afhankelijker van technologiebedrijven en verandert de machtsverhoudingen van publiek naar privaat, wat een negatief effect heeft op transparantie. Er is ook een 'democratisering' van surveillance door een verschuiving van gerichte naar grootschalige surveillance, waardoor een groter deel van de bevolking onder controle staat. Politiediensten en technologiebedrijven spelen hierin een steeds grotere rol.
Overweeg bijvoorbeeld in België de grote toename van het gebruik van 'slim' cameratoezicht voor verschillende doeleinden13, wat verder werd aangewakkerd door de coronacrisis.14 Andere voorbeelden zijn de infiltratie van het versleutelde Encrochat-netwerk15, de gezichtsherkenningssoftware van Clearview AI die ook werd getest door de federale politie in België16, of de gegevensverzamelingen van Europol17 die door sommigen worden vergeleken met de surveillancepraktijken van de Amerikaanse NSA.18 Denk ook aan het gebruik van de spionagesoftware Pegasus om gegevens te verzamelen van mobiele telefoons van activisten, politici en journalisten over de hele wereld.19 Ten slotte is er steeds meer sprake van collectieve en sociale schade naast individuele schade. Een belangrijk kenmerk van big data-analyses is dat ze op geaggregeerd niveau plaatsvinden.
Geen persoonsgegevens worden verwerkt. Stratificatie neemt toe, met ongelijke verhoudingen tussen groepen. Big data reproduceert afwijkingen, wat kan leiden tot oneerlijke behandeling. Predictive policing stuurt politie naar dezelfde wijken.
Dit leidt tot overpolicing en stigmatisering van bepaalde wijken en gemeenschappen. Deze risico's op discriminatie door big data-analyses worden bevestigd in de uitspraak over SyRI. Big data-technologie draagt ook bij aan criminalisering van armoede en toename van ongelijkheid. Drie socio-technische ontwikkelingen zetten huidige controlemechanismen onder druk. Of deze mechanismen hiermee om kunnen gaan, reflecteer ik vanuit de lens van relationele ethiek.
Het huidige rechtssysteem Laat deze bijdrage zien dat technologische veranderingen druk zetten op traditionele controle- en handhavingstools. Vraagt zich af of het huidige rechtssysteem voldoende is om hiermee om te gaan en effectieve democratische waarborgen te bieden. Het rechtssysteem wordt vandaag gevormd door de regels voor gegevensbescherming. De controle-instrumenten die momenteel worden gebruikt voor gegevensverwerking met AI, zoals toezichthouders, gegevensbeschermingsfunctionarissen en gegevensbeschermingsimpactevaluaties (Data Protection Impact Assessments of DPIA's), zijn vaak beperkt. De focus ligt voornamelijk op informatiebeveiliging en formele naleving van de wet.
Er wordt onvoldoende aandacht besteed aan de bescherming van basisrechten, met name artikel 8 van het EVRM.25 De werking hiervan in België is ook weinig democratisch, omdat burgers en het middenveld niet betrokken worden. Bovendien is de politie niet verplicht DPIA's openbaar te maken volgens de politie- en justitierichtlijn. Hierdoor is publieke controle moeilijker. Er zijn ook geen normen waaraan DPIA's moeten voldoen.
Er zijn geen standaardprofielen voor gegevensbescherming. Het huidige wetboek bevat alleen regels voor algoritmische controle die persoonlijke informatie verzamelen en verwerken. De EU heeft een AI-wet voorgesteld met twee doelen: het beschermen van de rechten van het individu tegen de schadelijke effecten van AI en het harmoniseren van de regelgeving van de lidstaten. De schadelijke effecten van AI worden gerangschikt van laag naar hoog en de verordening spreekt ook over risico's voor de samenleving.
De verordening maakt onduidelijk welke risico's er zijn. Wat betreft controle en handhaving is de verordening hoopvol. Lidstaten moeten autoriteiten aanwijzen voor toezicht en als contactpunt. Er komt een Europees systeem voor hoog risico AI-toepassingen. Deze moeten voldoen aan voorschriften en een beoordeling. Hoe dit toegepast en gehandhaafd wordt blijft vaag.
Het is onduidelijk hoe de regels eruit zullen zien. Ook mist de verordening democratische betrokkenheid, omdat burgers of het middenveld niet meedoen. Bovendien kunnen burgers geen klacht indienen bij de nationale toezichthouder als de wet niet wordt nageleefd. Reflecteren over wat we kunnen leren uit relationele ethiek, geïnspireerd door Ubuntufilosofie, om anders naar controle in algoritmische politiepraktijk te kijken, rekening houdend met de drie besproken technische ontwikkelingen. Ubuntufilosofie komt uit Afrikaanse filosofie uit landen ten zuiden van de Sahara. In tegenstelling tot rationele ethiek, waarbij mensen waardigheid hebben door autonomie, heeft Ubuntufilosofie mensen waardigheid door hun vermogen tot gemeenschappelijke betrekkingen. Mensenrechtenschendingen richten zich op het schaden van de capaciteit tot identiteit en solidariteit.
Menselijke waardigheid moet gezien worden als het vermogen om zich op een gemeenschappelijke manier tot anderen te verhouden. Computerwetenschappers, geïnspireerd door de Ubuntufilosofie, stellen een fundamentele verandering voor in het denken over algoritmische onrechtvaardigheid en AI-bestuur, van rationele naar relationele ethiek. Volgens Birhane is relationele ethiek "een kader dat ons dwingt om onze basishypothesen opnieuw te onderzoeken, machtsasymmetrieën te onderzoeken en de bredere, contingentie en verbonden achtergrond te overwegen waaruit algoritmische systemen voortkomen". Deze visie stelt dat de schade en onrechtvaardigheid die door algoritmische systemen worden veroorzaakt, niet los kan worden gezien van de filosofische beginselen van de technologie en de economische, politieke en sociale structuren die het vormgeven. Hoe kan deze visie worden verzoend met het verzoek van politie en justitie naar steeds grootschaligere surveillance en samenwerking met de private sector? Dit zou betekenen dat ook politiewerk vanuit dezelfde ethiek zou moeten vertrekken.
Het betekent dat de politieopdracht herdenken moet worden op een verbonden manier, als het bewaren van algemene veiligheid. In het huidige beleid wordt veiligheid echter op een beperkte manier gezien als bescherming tegen misdaad en handhaving van de openbare orde. Vaak gaat het niet meer over veiligheid, maar om politieke motieven, om te laten zien dat er hard optreedt tegen misdaad. Het is een vorm van 'toneelstukken'. Vanuit een gezamenlijke visie op veiligheid die als doel heeft om de veiligheid van alle burgers te waarborgen, moet er meer aandacht besteed worden aan andere oorzaken van onveiligheid. Veiligheid is meer dan alleen bescherming tegen misdaad.
Eet gezond, drink schoon water, heb een huis, krijg een basisinkomen, heb gezondheidszorg, onderwijs en werk, maar ook geen discriminatie, pesterijen, haat, geweld of disproportionele overheidscontrole. Deze sociale en economische rechten worden vaak niet meegenomen in het veiligheidsbeleid. Als we vanuit deze visie vertrekken, is het duidelijk dat encryptie essentieel is om mensenrechten en de meest kwetsbaren te beschermen, omdat achterdeuren in technologie de veiligheid van activisten en journalisten om democratische controle uit te oefenen beperken. Aangezien het onwaarschijnlijk is dat veiligheid als sociale veiligheid wordt gezien, moeten we vragen hoe de gaten in het net verfijnd kunnen worden, zodat controlemechanismen de meest kwetsbaren beschermen. Als we naar controle- en handhavingsmechanismen voor algoritmische surveillance kijken vanuit de relationele ethiek, betekent dit dat het 'rationele' controlekader, gebaseerd op het gegevensbeschermingsparadigma, tekort schiet, vooral in de manier waarop het in de praktijk en nationale politiewetgeving wordt vertaald. Het rationele kader gaat ervan uit dat mondige betrokkenen hun rechten individueel kunnen beschermen door informatieverzoeken, zonder rekening te houden met kwetsbare groepen.
Niet iedereen is gelijk. Ze hebben verschillende standpunten, kennisniveaus, besluitvaardigheid, bereidheid om informatie te delen en kwetsbare eigenschappen. Factoren zoals leeftijd, verstandelijke vermogens, armoede, geletterdheid of geslacht kunnen invloed hebben op het genieten en uitoefenen van individuele rechten op gegevensbescherming. Controle moet dus verder gaan dan alleen technische oplossingen en formele wetgeving, naar een praktijk die rekening houdt met de dynamische historische context en sociale technische praktijken waarin de technologie is ingebed, aandacht heeft voor machtsverhoudingen van de verschillende betrokkenen en waarin de bescherming van de meest kwetsbaren in de samenleving voorop staat. Deze relatieve controle betekent het betrekken van (belangen van) de meest kwetsbaren en hun vertegenwoordigers in het beleid en controlemechanismen die het sociale technische proces van algoritmische surveillance als uitgangspunt nemen. Transparantie is ook cruciaal om te voorkomen dat vooroordelen en fouten leiden tot schendingen van de mensenrechten, zoals het Federaal Instituut voor de Bescherming en Bevordering van de Rechten van de Mens (FIRM) aangeeft. Volgens het FIRM weten mensen in België vaak niet waarvoor de overheid algoritmen gebruikt.
Het is onduidelijk hoe een algoritme persoonsgegevens verwerkt. Er moet nagedacht worden over controlemechanismen om rekening te houden met machtsverschillen en technologiebedrijven. Voorkomen van collectieve en sociale schade is belangrijk. Politie moet een democratische toets doen voor investering in technologie.
Burgers worden betrokken bij besluitvorming. Daarnaast is er aandacht voor de groeiende macht van de staat en private partijen, evenals voor collectieve en sociale schade. Deze toets moet gebaseerd zijn op wetenschappelijke en objectieve analyse. Een instantie als de Nederlandse Onafhankelijke Raad voor Regeringsbeleid (WRR) kan hierbij een rol spelen door samen met universiteiten en het middenveld beleidsgericht onderzoek te doen. Ook kan dit orgaan onderzoek doen naar de collectieve en sociale schade van algoritmische surveillance en naar innovatieve controle- en handhavingsmechanismen.
Er is meer nodig dan alleen denken aan een AI-coördinatiecentrum, zoals voorgesteld in het WRR-rapport. Dit centrum moet politiek verankerd zijn om snel beleid te maken. Bij grootschalige surveillance moet de bevolking betrokken worden. Er is debat nodig over doelen en gebruik van AI. Publieke debatten, raadplegingen, burgerjury's en citizen-science initiatieven kunnen helpen. Door het publiek te betrekken, kan de overheid leren. Kwetsbare groepen moeten een stem krijgen.
Samenvattend: Relationele controle biedt interessante mogelijkheden om bestaande controles te herzien, rekening houdend met de sociale en technische veranderingen. Conclusie: In deze bijdrage heb ik nagedacht over de vraag of de huidige controle- en handhavingsmechanismen voor algoritmische surveillance moeten worden herzien. Eerst heb ik drie sociale en technische veranderingen besproken die de huidige controles onder druk zetten. Daarna heb ik gekeken naar de lessen die we kunnen leren als we controle- en handhavingsmechanismen voor algoritmische surveillance bekijken vanuit de relationele ethiek.
De vraag is of het huidige kader voldoende is voor de drie socio-technische ontwikkelingen. Relationele ethiek suggereert dat 'rationele' controles niet genoeg zijn. Er zijn interessante pistes, maar meer onderzoek is nodig voor een definitief antwoord.
