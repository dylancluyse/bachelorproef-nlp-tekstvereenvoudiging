Een onderzoek naar de relatie-ethiek. Technologische vooruitgang heeft sinds het einde van de twintigste eeuw nieuwe mogelijkheden gecreëerd voor dataverzameling en -analyse. 'Big data' en AI in de 21e eeuw zijn door de politie met veel interesse begroet. Politiegebruik van deze technologieën wordt als algoritmische surveillance beschouwd. Om een antwoord te vinden, zal ik in het eerste deel drie samenhangende technische veranderingen bespreken. Deze veranderingen zijn verbonden en moeten niet als afzonderlijk worden gezien.
Sinds het einde van de twintigste eeuw is er in het Westen meer samenwerking met de private sector en spelen zij een grotere rol in politiewerk. Door feedback loops, veroorzaakt door steekproefbias, worden politieagenten herhaaldelijk naar dezelfde wijken gestuurd, ongeacht het werkelijke misdaadcijfer. Dit leidt tot overpolicing en stigmatisering van bepaalde wijken en gemeenschappen. Deze risico's op discriminatie en stigmatisering door het gebruik van big data-analyses worden bevestigd door een uitspraak in Nederland over het gebruik van SyRI. Daarnaast toont de uitspraak ook aan dat big data-technologie sociale gevolgen heeft, zoals het criminaliseren van armoede en kansarmoede en de toename van ongelijkheid. Er zijn drie socio-technische ontwikkelingen die huidige controlemechanismen onder druk zetten. De politie is niet verplicht DPIA's te publiceren volgens de politie- en justitierichtlijn. Het huidige wettelijke kader betreft alleen toepassingen van algoritmische surveillance die persoonsgegevens verzamelen en verwerken. De EU heeft intussen een voorstel van AI-wet gepubliceerd met als doel de grondrechten van het individu tegen de nadelige gevolgen van AI te beschermen en de regelgeving van lidstaten te harmoniseren.
De gevolgen van AI worden gerangschikt van laag naar hoog risico en er wordt gesproken over risico's voor individuen en de samenleving. De verordening geeft echter geen duidelijkheid over deze risico's. Er wordt een systeem voorgesteld om AI-systemen te registreren en te controleren. Het is echter onduidelijk hoe deze beoordelingen toegepast en gehandhaafd zullen worden. Bovendien worden burgers en het middenveld niet betrokken bij deze mechanismen.
Politieopdracht moet herdacht worden als bescherming van collectieve veiligheid. Huidig beleid interpreteert veiligheid als bescherming tegen criminaliteit. Rationeel kader gaat uit van mensen die hun rechten kunnen beschermen. Verschillende factoren zoals leeftijd, geletterdheid of geslacht kunnen invloed hebben. Controle moet rekening houden met dynamische context en machtsrelaties. Bescherming van meest kwetsbaren staat voorop.
De meest kwetsbaren moeten betrokken worden bij het beleid en controlemechanismen. Transparantie is nodig om mensenrechten te beschermen. Mensen weten vaak niet welke algoritmen de overheid gebruikt. Er moet een democratische toets uitgevoerd worden voor investeringen in technologie. Er zou een AI-coördinatiecentrum kunnen zijn.
Methoden zoals debatten, raadplegingen, jury's en citizen-science kunnen worden gebruikt. Burgers kunnen de overheid helpen door hun expertise. Kwetsbare groepen moeten een stem krijgen. Reflecering over controlemechanismen voor algoritmische surveillance. Drie ontwikkelingen onder druk gezet. Relationele ethiek voor controle en handhaving. Relationele kader biedt interessante pistes.
