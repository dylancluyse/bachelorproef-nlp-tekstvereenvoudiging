{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import fitz\n",
    "import nltk\n",
    "# from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = fitz.open(\"../verslag\\output\\CluyseDylanBP.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'Lĳst van figuren', 7],\n",
       " [1, 'Inleiding', 9],\n",
       " [2, 'Probleemstelling', 10],\n",
       " [2, 'Onderzoeksvraag', 10],\n",
       " [2, 'Onderzoeksdoelstelling', 11],\n",
       " [2, 'Opzet van deze bachelorproef', 11],\n",
       " [1, 'Stand van zaken', 13],\n",
       " [2, 'Onderzoeken rond dyslexie', 13],\n",
       " [3, 'Centraal zicht op dyslexie', 13],\n",
       " [3, 'Fonologische dyslexie', 14],\n",
       " [3, 'Centraal zicht op de doelgroep', 14],\n",
       " [3, 'Diagnosecriteria', 15],\n",
       " [3, 'Moeilijkheden bij dyslexie', 16],\n",
       " [3, 'Aandachtspunten bij ondersteuning', 18],\n",
       " [3,\n",
       "  'Bewezen voordelen van tekstvereenvoudiging bij scholieren met dyslexie',\n",
       "  19],\n",
       " [2, 'Wetenschappelijke artikelen', 20],\n",
       " [3, 'Wetenschappelijke geletterdheid in Vlaanderen', 20],\n",
       " [3, 'Trends rond wetenschappelijke artikelen', 21],\n",
       " [3, 'Formaat', 23],\n",
       " [3, 'Woordenschat en vakjargon', 24],\n",
       " [3, 'Aanpak voor het lezen van wetenschappelijke artikelen', 24],\n",
       " [3, 'Conclusie', 25],\n",
       " [2, 'Tekstvereenvoudiging', 25],\n",
       " [3, 'Manuele tekstvereenvoudiging', 26],\n",
       " [3, 'Natural Language Processing', 27],\n",
       " [2, 'De verschillende soorten tekstvereenvoudiging', 30],\n",
       " [3, 'Lexicale vereenvoudiging', 30],\n",
       " [3, 'Syntactische vereenvoudiging', 31],\n",
       " [3, 'Conceptuele of semantische vereenvoudiging', 32],\n",
       " [3, 'Overige vormen van vereenvoudiging', 32],\n",
       " [3, 'Tekstvereenvoudiging automatiseren', 32],\n",
       " [3, 'Combineren tot het geheel van tekstvereenvoudiging', 33],\n",
       " [2, 'Samenvatten', 33],\n",
       " [3, 'Extractief samenvatten', 34],\n",
       " [3, 'Abstractief samenvatten', 37],\n",
       " [3, 'Hybride samenvatting', 37],\n",
       " [3, 'Evaluatie', 37],\n",
       " [3, 'Conclusie', 38],\n",
       " [2, 'Valkuilen', 38],\n",
       " [3, 'Taalgerelateerde valkuilen', 38],\n",
       " [3, 'Datasets', 39],\n",
       " [3, 'Paternalisme', 39],\n",
       " [3, 'Evaluatie en interpretatie', 40],\n",
       " [2, 'Beschikbare software voor tekstvereenvoudiging', 40],\n",
       " [3, 'Momenteel ingezet in het onderwijs', 40],\n",
       " [3, 'Proof-of-concepts en online webapplicaties', 40],\n",
       " [3, 'GPT-3', 41],\n",
       " [3, 'Bing AI', 44],\n",
       " [3, 'Google Bard en PaLM', 45],\n",
       " [3, 'Meta LLaMa', 45],\n",
       " [2, 'Conclusie', 45],\n",
       " [1, 'Methodologie', 46],\n",
       " [1, 'Conclusie', 48],\n",
       " [1, 'Onderzoeksvoorstel', 50],\n",
       " [2, 'Introductie', 50],\n",
       " [2, 'State-of-the-art', 51],\n",
       " [3, 'Tekstvereenvoudiging', 52],\n",
       " [3, 'Noden van scholieren met dyslexie', 52],\n",
       " [3, 'Huidige toepassingen', 54],\n",
       " [3, 'Ontwikkelen met AI', 54],\n",
       " [2, 'Methodologie', 55],\n",
       " [2, 'Verwacht resultaat, conclusie', 57],\n",
       " [1, 'Bibliografie', 58]]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.get_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.embfile_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.is_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.is_form_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.is_reflowable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.needs_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': 'PDF 1.5',\n",
       " 'title': 'Scholieren met dyslexie van de derde graad middelbaar onderwijs ondersteunen bij het lezen van wetenschappelijke papers via tekstsimplificatie',\n",
       " 'author': 'Dylan Cluyse',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'producer': 'xdvipdfmx (20200315)',\n",
       " 'creationDate': \"D:20230306205512-00'00'\",\n",
       " 'modDate': '',\n",
       " 'trapped': '',\n",
       " 'encryption': None}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.chapter_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_per_title(chosen_title):\n",
    "    start = 999\n",
    "    for title in pdf.get_toc():\n",
    "        if title[1] == chosen_title:\n",
    "            start = title[2]\n",
    "\n",
    "        if title[2] >= start and title[1] != chosen_title:\n",
    "            end = title[2]\n",
    "            break\n",
    "\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 26)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pages_per_title('Tekstvereenvoudiging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 23)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pages_per_title('Trends rond wetenschappelijke artikelen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_per_range(start, end):\n",
    "    text = \"\"\n",
    "    for i in range(start, end + 1):\n",
    "        page = pdf.load_page(i)\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = get_pages_per_title('Trends rond wetenschappelijke artikelen')\n",
    "text = get_content_per_range(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def text_cleaning(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'\\d+\\.\\d+\\.\\d+\\.', '', text) # 2.2.2 Stand van Zaken verwijderen.\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 2. Stand van zaken kers (Ball, 2017; Jones e.a., 2019; Plavén-Sigray e.a., 2017). Plavén-Sigray e.a. (2017) onderzoekt de verschillende trends waarom wetenschap- pelijke artikelen alsmaar moeilijker te lezen worden. De relatie tussen de leesbaar- heid van een abstract werd vergeleken met het jaar waarin het wetenschappelijk artikel werd gepubliceerd. De Flesch-Reading-Ease of FRE score werd gebruikt om de leesgraad van een wetenschappelijk artikel te beoordelen. Om te bevesti- gen dat de relatie tussen de complexiteit van een abstract overeenstemt met die van de volledige tekstinhoud, werden er vergelijkingen gemaakt met zes verschil- lende wetenschappelijke journalen. De overeenkomst tussen de leesgraad van het abstract en de overige tekstinhoud in een wetenschappelijk artikel werd eerder be- vestigd door Dronberger en Kowitz (1975). Dat onderzoek benadrukte dat een ab- stract complexer werd geschreven, vergeleken met de rest van een wetenschappe- lijk artikel. Figuur (2.6) Afbeelding uit Plavén-Sigray e.a. (2017). Links wordt de evolutie per FRE-score getoond. Hoe hoger de score, hoe hoger de gemiddelde complexiteit van een tekst. Rechts wordt de evolutie volgens de NDC-score getoond. Hoe hoger de score, hoe lager de gemiddelde complexiteit van een tekst. Het onderzoek schat dat nu een kwart van alle wetenschappelijke artikelen gebruik maken van Engels op het niveau van een masterstudent, ofwel een FRE onder nul. 2.2. Wetenschappelijke artikelen 15 Figuur (2.7) Afbeelding uit Plavén-Sigray e.a. (2017). Horizontaal worden het aantal auteurs per wetenschappelijk artikel aangeduidt. Verticaal wordt de gemiddelde NDC-score weergegeven. HOe hoger de NDC- score, hoe hoger de vereiste leesgraad om de tekst te kunnen lezen. De hoge leesgraad van wetenschappelijke artikelen beperkt volgens Plavén-Sigray e.a. (2017) twee aspecten: de toegankelijkheid en de herproduceerbaarheid. Toegankelijkheid Bronnen worden minder toegankelijk tot het algemene publiek. Wetenschappe- lijke artikels worden enkel toegankelijk tot mensen die wetenschappelijk geletterd zijn of een leesgraad daarboven hebben. F en Ennals (2010) zegt dat wetenschap ons de nauwkeurige kennis moet geven, omdat mensen zich zorgen maken dat moderne samenlevingen minder streng worden met feitelijke waarheden en deze vervangen door post-facts die waar lijken te klinken. Wetenschappelijke inhoud moet volgens hem zo toegankelijk mogelijk worden gemaakt, zodat een zo breed mogelijk publiek de kern begrijpt. Reproduceerbaarheid Onbegrijpelijke en ontoegankelijke zinsstructuren hinderen ook vakexperten. Het herschrijven van abstracten vergroot de begrijpbaarheid bij academici volgens Hart- ley (1999) en Snow (2010). De wetenschap bouwt voort op betrouwbare ontdek- kingen en het reproduceren van experimenten is een belangrijke manier voor we- tenschappers om vertrouwen te krijgen in hun besluiten. De inhoud van het we- tenschappelijke artikel moet gecontroleerd kunnen worden. Voor de reproduceer- baarheid van onderzoeken is het volgens McNutt (2014) belangrijk dat de metho- dologie en resultaten begrijpelijk zijn. Een lage leesgraad en duidelijke zinsbouw beperkt het aantal misopvattingen en verwarringen bij onderzoekers. 16 2. Stand van zaken  Formaat Experimenten uit Hubbard en Dunbar (2017) wijzen erop dat de bevraagde onder- zoekers zowel de methodologie als de resultaten de twee componenten vonden die een hoge leesgraad vergden.  Woordenschat en vakjargon Complexe processen, methoden en ideeën worden in wetenschappelijke artikelen verwoord met gebruik van grammatische embeddings, doordachte en abstracte woordenschat en naamwoordstijlen. De kenmerken van academische taal varië- ren afhankelijk van de discipline, het onderwerp en de vorm, maar er zijn gemeen- schappelijke kenmerken die wetenschappelijke taal onderscheiden van taal van een lagere leesgraad. (F & Ennals, 2010; Snow, 2010) Wetenschappelijke artikelen dienen volgens Plavén-Sigray e.a. (2017) in eerste in- stantie als uitwisseling van kennis tussen vakexperten. Daarnaast moet er rekening worden gehouden met de lengte wat een nadelig effect heeft op de beschikbare uitleg voor deze terminologie. Snow (2010) beklemtoont dat deze zaken in het onderwijs moeten betrokken wor- den. STEM-vakken of vakken waar deze wetenschappelijke artikelen aan bod ko- men, moeten stil staan bij voldoende uitleg over de toegepaste grammatica en woordenschat voorzien tijdens de lessen. Figuur (2.8) Afbeelding van (...) Volgens deze grafiek scoren de wetenschappelijke artikels rond fysica gemiddeld het best op de FRE-score. Al scoren de wetenschappelijke artikels rond microbiologie gemiddeld het zwakst op de FRE-score, ze scoren gemiddeld beter op de FOG-score.  Aanpak voor het lezen van wetenschappelijke artikelen Als reactie op een satirisch artikel van Ruben (2016), bracht Pain (2016) het onder- werp bij wetenschappers aan het licht om zo verschillende tactieken te verzamelen om wetenschappelijke artikelen te begrijpen. Sommige wetenschappers zoeken direct onbekende woorden op of raadplegen extra informatiebronnen, terwijl an- dere wetenschappers hoofdstukken overslaan. Het is belangrijk om een balans te vinden tussen het begrijpen van de inhoud en het efficiënt gebruiken van de tijd. Sommige wetenschappers geven toe dat ze het soms opgeven als het te moeilijk wordt of als de literatuur net niet relevant is voor hun onderzoek. Pain2016 bouwt \n"
     ]
    }
   ],
   "source": [
    "text = text_cleaning(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nl'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language = detect(text)\n",
    "language"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting tokens\n",
    "\n",
    "There are still too many tokens. We need to resort to an in-between method: extractive summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5431"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "fdist = FreqDist(text)\n",
    "fdist.N()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14 2.',\n",
       " 'Stand van zaken kers (Ball, 2017; Jones e.a., 2019; Plavén-Sigray e.a., 2017).',\n",
       " 'Plavén-Sigray e.a.',\n",
       " '(2017) onderzoekt de verschillende trends waarom wetenschap- pelijke artikelen alsmaar moeilijker te lezen worden.',\n",
       " 'De relatie tussen de leesbaar- heid van een abstract werd vergeleken met het jaar waarin het wetenschappelijk artikel werd gepubliceerd.',\n",
       " 'De Flesch-Reading-Ease of FRE score werd gebruikt om de leesgraad van een wetenschappelijk artikel te beoordelen.',\n",
       " 'Om te bevesti- gen dat de relatie tussen de complexiteit van een abstract overeenstemt met die van de volledige tekstinhoud, werden er vergelijkingen gemaakt met zes verschil- lende wetenschappelijke journalen.',\n",
       " 'De overeenkomst tussen de leesgraad van het abstract en de overige tekstinhoud in een wetenschappelijk artikel werd eerder be- vestigd door Dronberger en Kowitz (1975).',\n",
       " 'Dat onderzoek benadrukte dat een ab- stract complexer werd geschreven, vergeleken met de rest van een wetenschappe- lijk artikel.',\n",
       " 'Figuur (2.6) Afbeelding uit Plavén-Sigray e.a.',\n",
       " '(2017).',\n",
       " 'Links wordt de evolutie per FRE-score getoond.',\n",
       " 'Hoe hoger de score, hoe hoger de gemiddelde complexiteit van een tekst.',\n",
       " 'Rechts wordt de evolutie volgens de NDC-score getoond.',\n",
       " 'Hoe hoger de score, hoe lager de gemiddelde complexiteit van een tekst.',\n",
       " 'Het onderzoek schat dat nu een kwart van alle wetenschappelijke artikelen gebruik maken van Engels op het niveau van een masterstudent, ofwel een FRE onder nul.',\n",
       " '2.2.',\n",
       " 'Wetenschappelijke artikelen 15 Figuur (2.7) Afbeelding uit Plavén-Sigray e.a.',\n",
       " '(2017).',\n",
       " 'Horizontaal worden het aantal auteurs per wetenschappelijk artikel aangeduidt.',\n",
       " 'Verticaal wordt de gemiddelde NDC-score weergegeven.',\n",
       " 'HOe hoger de NDC- score, hoe hoger de vereiste leesgraad om de tekst te kunnen lezen.',\n",
       " 'De hoge leesgraad van wetenschappelijke artikelen beperkt volgens Plavén-Sigray e.a.',\n",
       " '(2017) twee aspecten: de toegankelijkheid en de herproduceerbaarheid.',\n",
       " 'Toegankelijkheid Bronnen worden minder toegankelijk tot het algemene publiek.',\n",
       " 'Wetenschappe- lijke artikels worden enkel toegankelijk tot mensen die wetenschappelijk geletterd zijn of een leesgraad daarboven hebben.',\n",
       " 'F en Ennals (2010) zegt dat wetenschap ons de nauwkeurige kennis moet geven, omdat mensen zich zorgen maken dat moderne samenlevingen minder streng worden met feitelijke waarheden en deze vervangen door post-facts die waar lijken te klinken.',\n",
       " 'Wetenschappelijke inhoud moet volgens hem zo toegankelijk mogelijk worden gemaakt, zodat een zo breed mogelijk publiek de kern begrijpt.',\n",
       " 'Reproduceerbaarheid Onbegrijpelijke en ontoegankelijke zinsstructuren hinderen ook vakexperten.',\n",
       " 'Het herschrijven van abstracten vergroot de begrijpbaarheid bij academici volgens Hart- ley (1999) en Snow (2010).',\n",
       " 'De wetenschap bouwt voort op betrouwbare ontdek- kingen en het reproduceren van experimenten is een belangrijke manier voor we- tenschappers om vertrouwen te krijgen in hun besluiten.',\n",
       " 'De inhoud van het we- tenschappelijke artikel moet gecontroleerd kunnen worden.',\n",
       " 'Voor de reproduceer- baarheid van onderzoeken is het volgens McNutt (2014) belangrijk dat de metho- dologie en resultaten begrijpelijk zijn.',\n",
       " 'Een lage leesgraad en duidelijke zinsbouw beperkt het aantal misopvattingen en verwarringen bij onderzoekers.',\n",
       " '16 2.',\n",
       " 'Stand van zaken  Formaat Experimenten uit Hubbard en Dunbar (2017) wijzen erop dat de bevraagde onder- zoekers zowel de methodologie als de resultaten de twee componenten vonden die een hoge leesgraad vergden.',\n",
       " 'Woordenschat en vakjargon Complexe processen, methoden en ideeën worden in wetenschappelijke artikelen verwoord met gebruik van grammatische embeddings, doordachte en abstracte woordenschat en naamwoordstijlen.',\n",
       " 'De kenmerken van academische taal varië- ren afhankelijk van de discipline, het onderwerp en de vorm, maar er zijn gemeen- schappelijke kenmerken die wetenschappelijke taal onderscheiden van taal van een lagere leesgraad.',\n",
       " '(F & Ennals, 2010; Snow, 2010) Wetenschappelijke artikelen dienen volgens Plavén-Sigray e.a.',\n",
       " '(2017) in eerste in- stantie als uitwisseling van kennis tussen vakexperten.',\n",
       " 'Daarnaast moet er rekening worden gehouden met de lengte wat een nadelig effect heeft op de beschikbare uitleg voor deze terminologie.',\n",
       " 'Snow (2010) beklemtoont dat deze zaken in het onderwijs moeten betrokken wor- den.',\n",
       " 'STEM-vakken of vakken waar deze wetenschappelijke artikelen aan bod ko- men, moeten stil staan bij voldoende uitleg over de toegepaste grammatica en woordenschat voorzien tijdens de lessen.',\n",
       " 'Figuur (2.8) Afbeelding van (...) Volgens deze grafiek scoren de wetenschappelijke artikels rond fysica gemiddeld het best op de FRE-score.',\n",
       " 'Al scoren de wetenschappelijke artikels rond microbiologie gemiddeld het zwakst op de FRE-score, ze scoren gemiddeld beter op de FOG-score.',\n",
       " 'Aanpak voor het lezen van wetenschappelijke artikelen Als reactie op een satirisch artikel van Ruben (2016), bracht Pain (2016) het onder- werp bij wetenschappers aan het licht om zo verschillende tactieken te verzamelen om wetenschappelijke artikelen te begrijpen.',\n",
       " 'Sommige wetenschappers zoeken direct onbekende woorden op of raadplegen extra informatiebronnen, terwijl an- dere wetenschappers hoofdstukken overslaan.',\n",
       " 'Het is belangrijk om een balans te vinden tussen het begrijpen van de inhoud en het efficiënt gebruiken van de tijd.',\n",
       " 'Sommige wetenschappers geven toe dat ze het soms opgeven als het te moeilijk wordt of als de literatuur net niet relevant is voor hun onderzoek.',\n",
       " 'Pain2016 bouwt']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.sent_tokenize(text)\n",
    "text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at GroNLP/bert-base-dutch-cased were not used when initializing TFBertModel: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/wietsedv/bertje\n",
    "\n",
    "from summarizer import Summarizer\n",
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "from transformers import BertTokenizer, TFBertLMHeadModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\", revision=\"v1\") # 2021 version\n",
    "model = TFAutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "\n",
    "# model = TFBertLMHeadModel.from_pretrained('bert-base-cased', return_dict=True)\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.bert.modeling_tf_bert.TFBertModel at 0x1a9b375e590>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='GroNLP/bert-base-dutch-cased', vocab_size=30000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dylan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "sentences = nltk.tokenize.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize\n",
    "length = 0\n",
    "chunk = \"\"\n",
    "chunks = []\n",
    "count = -1\n",
    "for sentence in sentences:\n",
    "  count += 1\n",
    "  combined_length = len(tokenizer.tokenize(sentence)) + length # add the no. of sentence tokens to the length counter\n",
    "\n",
    "  if combined_length  <= tokenizer.max_len_single_sentence: # if it doesn't exceed\n",
    "    chunk += sentence + \" \" # add the sentence to the chunk\n",
    "    length = combined_length # update the length counter\n",
    "\n",
    "    # if it is the last sentence\n",
    "    if count == len(sentences) - 1:\n",
    "      chunks.append(chunk.strip()) # save the chunk\n",
    "    \n",
    "  else: \n",
    "    chunks.append(chunk.strip()) # save the chunk\n",
    "    \n",
    "    # reset \n",
    "    length = 0 \n",
    "    chunk = \"\"\n",
    "\n",
    "    # take care of the overflow sentence\n",
    "    chunk += sentence + \" \"\n",
    "    length = len(tokenizer.tokenize(sentence))\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[404, 484, 492, 443, 510, 447, 364, 451, 473, 460, 133]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(tokenizer.tokenize(c)) for c in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[406, 486, 494, 445, 512, 449, 366, 453, 475, 462, 135]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(tokenizer(c).input_ids) for c in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [tokenizer(chunk, return_tensors=\"pt\") for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The current model class (TFBertModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'TFBertLMHeadModel'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [180], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs:\n\u001b[1;32m----> 2\u001b[0m   output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m)\n\u001b[0;32m      3\u001b[0m   \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39mdecode(\u001b[39m*\u001b[39moutput, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\generation\\tf_utils.py:694\u001b[0m, in \u001b[0;36mTFGenerationMixin.generate\u001b[1;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39mif\u001b[39;00m do_sample \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m num_beams \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    693\u001b[0m     seed \u001b[39m=\u001b[39m model_kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 694\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(\n\u001b[0;32m    695\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m    696\u001b[0m         max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m    697\u001b[0m         max_new_tokens\u001b[39m=\u001b[39mmax_new_tokens,\n\u001b[0;32m    698\u001b[0m         min_length\u001b[39m=\u001b[39mmin_length,\n\u001b[0;32m    699\u001b[0m         do_sample\u001b[39m=\u001b[39mdo_sample,\n\u001b[0;32m    700\u001b[0m         early_stopping\u001b[39m=\u001b[39mearly_stopping,\n\u001b[0;32m    701\u001b[0m         num_beams\u001b[39m=\u001b[39mnum_beams,\n\u001b[0;32m    702\u001b[0m         temperature\u001b[39m=\u001b[39mtemperature,\n\u001b[0;32m    703\u001b[0m         penalty_alpha\u001b[39m=\u001b[39mpenalty_alpha,\n\u001b[0;32m    704\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[0;32m    705\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m    706\u001b[0m         repetition_penalty\u001b[39m=\u001b[39mrepetition_penalty,\n\u001b[0;32m    707\u001b[0m         bad_words_ids\u001b[39m=\u001b[39mbad_words_ids,\n\u001b[0;32m    708\u001b[0m         bos_token_id\u001b[39m=\u001b[39mbos_token_id,\n\u001b[0;32m    709\u001b[0m         pad_token_id\u001b[39m=\u001b[39mpad_token_id,\n\u001b[0;32m    710\u001b[0m         eos_token_id\u001b[39m=\u001b[39meos_token_id,\n\u001b[0;32m    711\u001b[0m         length_penalty\u001b[39m=\u001b[39mlength_penalty,\n\u001b[0;32m    712\u001b[0m         no_repeat_ngram_size\u001b[39m=\u001b[39mno_repeat_ngram_size,\n\u001b[0;32m    713\u001b[0m         num_return_sequences\u001b[39m=\u001b[39mnum_return_sequences,\n\u001b[0;32m    714\u001b[0m         attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m    715\u001b[0m         decoder_start_token_id\u001b[39m=\u001b[39mdecoder_start_token_id,\n\u001b[0;32m    716\u001b[0m         use_cache\u001b[39m=\u001b[39muse_cache,\n\u001b[0;32m    717\u001b[0m         seed\u001b[39m=\u001b[39mseed,\n\u001b[0;32m    718\u001b[0m         output_scores\u001b[39m=\u001b[39moutput_scores,\n\u001b[0;32m    719\u001b[0m         output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[0;32m    720\u001b[0m         output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    721\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m    722\u001b[0m         forced_bos_token_id\u001b[39m=\u001b[39mforced_bos_token_id,\n\u001b[0;32m    723\u001b[0m         forced_eos_token_id\u001b[39m=\u001b[39mforced_eos_token_id,\n\u001b[0;32m    724\u001b[0m         suppress_tokens\u001b[39m=\u001b[39msuppress_tokens,\n\u001b[0;32m    725\u001b[0m         begin_suppress_tokens\u001b[39m=\u001b[39mbegin_suppress_tokens,\n\u001b[0;32m    726\u001b[0m         forced_decoder_ids\u001b[39m=\u001b[39mforced_decoder_ids,\n\u001b[0;32m    727\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    728\u001b[0m     )\n\u001b[0;32m    730\u001b[0m \u001b[39m# We cannot generate if the model does not have a LM head\u001b[39;00m\n\u001b[0;32m    731\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_output_embeddings() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\generation\\tf_utils.py:1683\u001b[0m, in \u001b[0;36mTFGenerationMixin._generate\u001b[1;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, seed, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[39mGenerates sequences of token ids for models with a language modeling head. The method supports the following\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[39mgeneration methods for text-decoder, text-to-text, speech-to-text, and vision-to-text models:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[39moutputs = model.generate(input_ids=input_ids, max_length=100, do_sample=True, bad_words_ids=bad_words_ids)\u001b[39;00m\n\u001b[0;32m   1680\u001b[0m \u001b[39m```\"\"\"\u001b[39;00m\n\u001b[0;32m   1682\u001b[0m \u001b[39m# 0. Validate the `.generate()` call\u001b[39;00m\n\u001b[1;32m-> 1683\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_model_class()\n\u001b[0;32m   1684\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_model_kwargs(model_kwargs\u001b[39m.\u001b[39mcopy())\n\u001b[0;32m   1686\u001b[0m \u001b[39m# 1. Cast input dtypes to tf.int32 unless they're floats (which happens for some image models)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\generation\\tf_utils.py:1437\u001b[0m, in \u001b[0;36mTFGenerationMixin._validate_model_class\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1435\u001b[0m \u001b[39mif\u001b[39;00m generate_compatible_classes:\n\u001b[0;32m   1436\u001b[0m     exception_message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Please use one of the following classes instead: \u001b[39m\u001b[39m{\u001b[39;00mgenerate_compatible_classes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1437\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(exception_message)\n",
      "\u001b[1;31mTypeError\u001b[0m: The current model class (TFBertModel) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'TFBertLMHeadModel'}"
     ]
    }
   ],
   "source": [
    "for input in inputs:\n",
    "  output = model.generate(**input)\n",
    "  print(tokenizer.decode(*output, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TFBertModel' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [86], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m Summarizer(custom_model\u001b[39m=\u001b[39mmodel, custom_tokenizer\u001b[39m=\u001b[39mtokenizer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\summarizer\\bert.py:81\u001b[0m, in \u001b[0;36mSummarizer.__init__\u001b[1;34m(self, model, custom_model, custom_tokenizer, hidden, reduce_option, sentence_handler, random_state, hidden_concat, gpu_id)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     58\u001b[0m     model: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbert-large-uncased\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     gpu_id: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[0;32m     67\u001b[0m ):\n\u001b[0;32m     68\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39m    This is the main Bert Summarizer class.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39m    :param gpu_id: GPU device index if CUDA is available. \u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m     \u001b[39msuper\u001b[39;49m(Summarizer, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     82\u001b[0m         model, custom_model, custom_tokenizer, hidden, reduce_option, sentence_handler, random_state, hidden_concat,\n\u001b[0;32m     83\u001b[0m         gpu_id\n\u001b[0;32m     84\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\summarizer\\bert.py:49\u001b[0m, in \u001b[0;36mBertSummarizer.__init__\u001b[1;34m(self, model, custom_model, custom_tokenizer, hidden, reduce_option, sentence_handler, random_state, hidden_concat, gpu_id)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     24\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     25\u001b[0m     model: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbert-large-uncased\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     gpu_id: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[0;32m     34\u001b[0m ):\n\u001b[0;32m     35\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m    This is the parent Bert Summarizer model. New methods should implement this class.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m    :param gpu_id: GPU device index if CUDA is available.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     model \u001b[39m=\u001b[39m BertEmbedding(model, custom_model, custom_tokenizer, gpu_id)\n\u001b[0;32m     50\u001b[0m     model_func \u001b[39m=\u001b[39m partial(model, hidden\u001b[39m=\u001b[39mhidden, reduce_option\u001b[39m=\u001b[39mreduce_option, hidden_concat\u001b[39m=\u001b[39mhidden_concat)\n\u001b[0;32m     51\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(model_func, sentence_handler, random_state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\summarizer\\transformer_embeddings\\bert_embedding.py:50\u001b[0m, in \u001b[0;36mBertEmbedding.__init__\u001b[1;34m(self, model, custom_model, custom_tokenizer, gpu_id)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda:\u001b[39m\u001b[39m{\u001b[39;00mgpu_id\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[39mif\u001b[39;00m custom_model:\n\u001b[1;32m---> 50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m custom_model\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     51\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m base_model\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     53\u001b[0m         model, output_hidden_states\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TFBertModel' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "model = Summarizer(custom_model=model, custom_tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstractive summarization + text simplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tiktoken\n",
    "import configparser, os\n",
    "\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "openai.api_key = config['openai']['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2365192525.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [181], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    prompt = f\"\"\"\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "amount_words_sentence = 10\n",
    "amount_sentences = 4\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Vereenvoudig deze tekst met deze parameters:\n",
    "Zin is max {amount_words_sentence} woorden lang\n",
    "Max {amount_sentences} aantal zinnen.\n",
    "context: \n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89da10480825c8ad24c96d10788e772e9a68ac77e314b3c42d655a8c40ed70a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
